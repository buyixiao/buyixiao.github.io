<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Instagram 帖子数据采集</title>
      <link href="/blog/instagram-keyword-checkin-post-spider.html"/>
      <url>/blog/instagram-keyword-checkin-post-spider.html</url>
      
        <content type="html"><![CDATA[<p>Instagram 是一款图片分享社交应用，Instagram 签到数据指的是用户分享图片帖子时带上了用户当时所在地，比起普通帖子多了地理位置这一信息，扩展了数据的维度。</p><h3 id="研究意义"><a href="#研究意义" class="headerlink" title="研究意义"></a>研究意义</h3><p><strong>地理签到帖子</strong>的研究具有多方面的重要意义，尤其在社交媒体分析、城市研究、旅游经济等领域中表现突出。</p><h4 id="✅-1-用户行为理解"><a href="#✅-1-用户行为理解" class="headerlink" title="✅ 1. 用户行为理解"></a>✅ 1. <strong>用户行为理解</strong></h4><p>通过分析用户在特定地点发布的帖子，可以洞察用户的行为模式、兴趣偏好、活动时间与地点偏好等，从而帮助平台优化推荐算法和广告投放策略。</p><h4 id="✅-2-城市与区域活跃度分析"><a href="#✅-2-城市与区域活跃度分析" class="headerlink" title="✅ 2. 城市与区域活跃度分析"></a>✅ 2. <strong>城市与区域活跃度分析</strong></h4><p>Geo-tag 数据可以反映城市中哪些地点最受欢迎、人流密度如何变化，有助于<strong>城市规划、商业选址、交通管理</strong>等决策制定。</p><h4 id="✅-3-旅游趋势监测"><a href="#✅-3-旅游趋势监测" class="headerlink" title="✅ 3. 旅游趋势监测"></a>✅ 3. <strong>旅游趋势监测</strong></h4><p>旅游机构和研究者可以利用 Instagram 地理签到数据实时追踪热门旅游景点、游客来源地、旅游季节性等信息，对旅游推广和资源分配具有重要价值。</p><h4 id="✅-4-事件检测与社会感知"><a href="#✅-4-事件检测与社会感知" class="headerlink" title="✅ 4. 事件检测与社会感知"></a>✅ 4. <strong>事件检测与社会感知</strong></h4><p>某地短时间内地理签到帖子激增可能代表<strong>重大事件发生</strong>（如演唱会、抗议、灾害等），可用于<strong>社会感知与应急响应分析</strong>。</p><h4 id="✅-5-文化与情感空间分析"><a href="#✅-5-文化与情感空间分析" class="headerlink" title="✅ 5. 文化与情感空间分析"></a>✅ 5. <strong>文化与情感空间分析</strong></h4><p>结合图像内容和地理标签，可以研究不同地点上传达的情感色彩与文化表达，揭示城市空间与人类情绪之间的联系。</p><h3 id="Instagram-签到数据采集服务"><a href="#Instagram-签到数据采集服务" class="headerlink" title="Instagram 签到数据采集服务"></a>Instagram 签到数据采集服务</h3><p>研发了一套稳定的 instagram 地理签到数据采集系统，可以采集全球任意城市的地理签到帖子，主要字段如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">帖子 <span class="built_in">id</span></span><br><span class="line">帖子链接</span><br><span class="line">帖子发布时间</span><br><span class="line">帖子正文</span><br><span class="line">帖子图片链接</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">帖子作者 <span class="built_in">id</span></span><br><span class="line">帖子作者用户名</span><br><span class="line">帖子作者链接</span><br><span class="line"></span><br><span class="line">帖子评论数</span><br><span class="line">帖子点赞数</span><br><span class="line"></span><br><span class="line">帖子签到城市</span><br><span class="line">帖子签到经度</span><br><span class="line">帖子签到纬度</span><br></pre></td></tr></table></figure><p>个性化定制需求，最终交付数据，支持对公转账，可开发票，</p><p>已服务国内外一些高校实验室老师，</p><p>有相关需求的欢迎博客下方评论，如果回复不及时可前往爱发电平台私聊：</p><blockquote><p><a href="https://afdian.com/a/buyixiao">https://afdian.com/a/buyixiao</a></p></blockquote><p>只服务正规科研论文数据分析、数据支持的行业咨询需求，灰产勿扰！灰产勿扰！灰产勿扰！</p>]]></content>
      
      
      <categories>
          
          <category> Spider </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spider </tag>
            
            <tag> check-in </tag>
            
            <tag> posts </tag>
            
            <tag> keyword </tag>
            
            <tag> instagram </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Facebook 帖子数据采集</title>
      <link href="/blog/facebook-keyword-checkin-post-spider.html"/>
      <url>/blog/facebook-keyword-checkin-post-spider.html</url>
      
        <content type="html"><![CDATA[<p>Facebook 作为世界上最大的社交平台，相比于 twitter，数据种类更加繁多，关系网络愈加复杂。</p><p>下面从<strong>学术研究</strong>和<strong>实际应用</strong>两个角度，简洁阐述一下<strong>采集 Facebook（脸书）关键词、话题与地理签到帖子</strong>的研究意义：</p><hr><h2 id="🎯-一、研究意义概述"><a href="#🎯-一、研究意义概述" class="headerlink" title="🎯 一、研究意义概述"></a>🎯 一、研究意义概述</h2><h3 id="✅-1-社交媒体文本：洞察情绪与舆情"><a href="#✅-1-社交媒体文本：洞察情绪与舆情" class="headerlink" title="✅ 1. 社交媒体文本：洞察情绪与舆情"></a>✅ 1. <strong>社交媒体文本：洞察情绪与舆情</strong></h3><ul><li>脸书用户主动发布的<strong>公开状态、评论和话题</strong>可以反映他们的：<ul><li>情绪变化（如焦虑、愤怒、喜悦）</li><li>观点立场（如选举、社会事件、文化态度）</li><li>兴趣关注（如旅游、美食、品牌）</li></ul></li></ul><p>通过关键词与主题建模（如 LDA），可以深入理解某一时期、某一人群在特定话题上的倾向。</p><hr><h3 id="✅-2-地理签到数据：构建行为画像与区域热度"><a href="#✅-2-地理签到数据：构建行为画像与区域热度" class="headerlink" title="✅ 2. 地理签到数据：构建行为画像与区域热度"></a>✅ 2. <strong>地理签到数据：构建行为画像与区域热度</strong></h3><ul><li>Facebook 的<strong>地理签到（check-in）或带定位的帖子</strong>，使得研究者可以将“语言”与“地点”联系起来：<ul><li>分析人们<strong>在什么地方说什么内容</strong></li><li>绘制<strong>城市情绪热力图</strong></li><li>挖掘特定地点的<strong>打卡行为与活动模式</strong></li></ul></li></ul><p>这在城市研究、旅游规划、疫情监测等方面具有高价值。</p><hr><h3 id="✅-3-社会行为建模与事件预测"><a href="#✅-3-社会行为建模与事件预测" class="headerlink" title="✅ 3. 社会行为建模与事件预测"></a>✅ 3. <strong>社会行为建模与事件预测</strong></h3><ul><li>高频关键词配合时间线，可以反推出事件发展趋势</li><li>某些地点话题突变，可能预示着抗议、活动、灾害等事件爆发</li><li>配合图神经网络，可以进行<strong>社会图谱构建与演化分析</strong></li></ul><hr><h2 id="🧠-二、典型研究-应用方向"><a href="#🧠-二、典型研究-应用方向" class="headerlink" title="🧠 二、典型研究/应用方向"></a>🧠 二、典型研究/应用方向</h2><table><thead><tr><th>研究方向</th><th>示例价值</th></tr></thead><tbody><tr><td>舆情演变分析</td><td>疫情、选举、公共事件中民众态度走向</td></tr><tr><td>城市空间热度分析</td><td>哪些地点打卡频繁？配合文字内容可得“情绪地图”</td></tr><tr><td>品牌传播/市场营销分析</td><td>消费者在哪些场景中谈论某品牌？话题是正面还是负面？</td></tr><tr><td>文化迁移与地理流动研究</td><td>用户从哪里迁移到哪里？在不同文化地标发了什么内容？</td></tr><tr><td>地理语言学研究</td><td>哪些地区的人更偏向使用某些词语或表情？</td></tr></tbody></table><h2 id="🛶-三、Facebook-数据采集服务"><a href="#🛶-三、Facebook-数据采集服务" class="headerlink" title="🛶 三、Facebook 数据采集服务"></a>🛶 三、Facebook 数据采集服务</h2><p>本博主开发了一套完整的 facebook 的帖子数据采集系统，可以采集任意时间段下，任意关键词/任意话题/任意公共主页等的帖子数据和任意地理位置的签到帖子数据，字段主要包括：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">帖子 <span class="built_in">id</span></span><br><span class="line">帖子链接</span><br><span class="line">帖子发布时间</span><br><span class="line">帖子正文</span><br><span class="line">帖子图片链接</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">帖子作者 <span class="built_in">id</span></span><br><span class="line">帖子作者用户名</span><br><span class="line">帖子作者链接</span><br><span class="line"></span><br><span class="line">帖子分享数</span><br><span class="line">帖子评论数</span><br><span class="line">帖子点赞数</span><br></pre></td></tr></table></figure><p>当然，也可以采集指定帖子 id 下面的评论，字段主要有</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">评论 id</span><br><span class="line">评论内容</span><br><span class="line">评论发布时间</span><br><span class="line">评论用户 id</span><br><span class="line">评论用户名</span><br><span class="line">评论回复数</span><br><span class="line">评论点赞数</span><br></pre></td></tr></table></figure><p>这套系统目前已服务不少国内外高校老师，</p><p>个性化定制需求，最终交付数据，支持对公转账，可开发票，</p><p>有相关需求的欢迎博客下方评论，如果回复不及时可前往爱发电平台私聊：</p><blockquote><p><a href="https://afdian.com/a/buyixiao">https://afdian.com/a/buyixiao</a></p></blockquote><p>只服务正规科研论文数据分析、数据支持的行业咨询需求，灰产勿扰！灰产勿扰！灰产勿扰！</p>]]></content>
      
      
      <categories>
          
          <category> Spider </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spider </tag>
            
            <tag> check-in </tag>
            
            <tag> facebook </tag>
            
            <tag> posts </tag>
            
            <tag> keyword </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Twitter/X 推文数据采集</title>
      <link href="/blog/twitter-x-keyword-checkin-spider.html"/>
      <url>/blog/twitter-x-keyword-checkin-spider.html</url>
      
        <content type="html"><![CDATA[<p>在社交媒体蓬勃发展的今天，推特X（原Twitter）作为全球最大的社交平台之一，每天都在产生海量的用户数据。这些数据不仅包含用户的文字表达，还涵盖了丰富的地理信息。</p><p>文本数据不只是冰冷的语言，它也反映了平台用户的情感和偏好，</p><p>而文本附带的签到数据也绝不仅仅只是数字，它还代表着人类行为、迁徙轨迹等等。</p><p>本人开发了一套完整的推特 X 关键词推文、地理签到推文采集系统，经过多年多版本迭代，已日趋成熟稳定，能够根据需求大小弹性伸缩采集能力，保持成本与数据量的协调，在不考虑消耗成本的情况下，单日推文采集量可达千万数量级。</p><p>相对于推特 X 官方的企业版 api 价格起步 42,000 美元，成本非常高昂，我们的采集成本仅为其 1/n。</p><p>而且我们的采集字段非常丰富，可采集多达约 100 个字段信息，部分字段列表如下，不同字段组合需求价格不一，视最终定制需求字段而定。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">推文 <span class="built_in">id</span></span><br><span class="line">推文链接</span><br><span class="line">推文发布时间</span><br><span class="line">推文正文</span><br><span class="line">推文发布来源</span><br><span class="line">推文标签</span><br><span class="line">推文图片链接</span><br><span class="line">推文视频链接</span><br><span class="line">推文提及用户</span><br><span class="line">推文地理签到信息</span><br><span class="line">推文语言</span><br><span class="line">推文浏览量</span><br><span class="line">推文评论数</span><br><span class="line">推文转发数</span><br><span class="line">推文点赞数</span><br><span class="line">推文引用数</span><br><span class="line">推文书签数</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">引用推文 <span class="built_in">id</span></span><br><span class="line">引用推文正文</span><br><span class="line">引用推文链接</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">评论推文 <span class="built_in">id</span></span><br><span class="line">评论推文正文</span><br><span class="line">评论推文链接</span><br><span class="line"></span><br><span class="line">推文作者 <span class="built_in">id</span></span><br><span class="line">推文作者用户名</span><br><span class="line">推文作者昵称</span><br><span class="line">推文作者链接</span><br><span class="line">推文作者简介</span><br><span class="line">推文作者关注数</span><br><span class="line">推文作者粉丝数</span><br><span class="line">推文作者所在地</span><br><span class="line">推文作者注册时间</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>我们的系统目前已服务众多国内外高校老师和学生，以及一些咨询类型企业，</p><p>定制个性化需求，最终交付数据，支持对公转账，可开发票，</p><p>有相关需求的欢迎博客下方评论，如果回复不及时可前往爱发电平台私聊：</p><blockquote><p><a href="https://afdian.com/a/buyixiao">https://afdian.com/a/buyixiao</a></p></blockquote><p>只服务正规科研论文数据分析、数据支持的行业咨询需求，灰产勿扰！灰产勿扰！灰产勿扰！</p><p>以下是本文的英文翻译：</p><p>Below is the English translation version of this article:</p><hr><p>In today’s era of booming social media, <strong>Twitter X</strong> (formerly Twitter), as one of the largest social platforms globally, generates a massive volume of user data every day.<br> This data not only includes users’ textual expressions but also contains rich geographical information.</p><p>Textual data is more than just cold language — it reflects users’ <strong>emotions and preferences</strong> on the platform.<br> Meanwhile, text combined with <strong>location check-in data</strong> represents far more than just numbers; it captures <strong>human behavior, migration patterns</strong>, and much more.</p><p>I have developed a <strong>complete system</strong> for <strong>collecting keyword-based tweets</strong> and <strong>location check-in tweets</strong> on Twitter X.<br> After years of iterative upgrades across multiple versions, the system has become mature and stable.<br> It can <strong>dynamically scale</strong> based on data volume needs, balancing <strong>cost and efficiency</strong>.<br> Without cost constraints, the system can collect <strong>tens of millions of tweets per day</strong>.</p><p>In comparison, the official <strong>Twitter X Enterprise API</strong> starts at <strong>$42,000 USD per month</strong>, making it extremely expensive.<br> Our solution operates at just <strong>1/n</strong> of that cost.</p><p>Furthermore, the fields we collect are highly detailed — we can capture <strong>up to around 100 different attributes</strong> per tweet.<br> Here’s a partial list (the final pricing depends on the specific combination of required fields):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">Tweet ID</span><br><span class="line">Tweet URL</span><br><span class="line">Tweet Publish Time</span><br><span class="line">Tweet Text Content</span><br><span class="line">Tweet Source</span><br><span class="line">Tweet Hashtags</span><br><span class="line">Tweet Image Links</span><br><span class="line">Tweet Video Links</span><br><span class="line">Mentioned Users</span><br><span class="line">Tweet Geo Check-<span class="keyword">in</span> Information</span><br><span class="line">Tweet Language</span><br><span class="line">Tweet View Count</span><br><span class="line">Tweet Comment Count</span><br><span class="line">Tweet Retweet Count</span><br><span class="line">Tweet Like Count</span><br><span class="line">Tweet Quote Count</span><br><span class="line">Tweet Bookmark Count</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">Quoted Tweet ID</span><br><span class="line">Quoted Tweet Text</span><br><span class="line">Quoted Tweet URL</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">Reply Tweet ID</span><br><span class="line">Reply Tweet Text</span><br><span class="line">Reply Tweet URL</span><br><span class="line"></span><br><span class="line">Tweet Author ID</span><br><span class="line">Tweet Author Username</span><br><span class="line">Tweet Author Display Name</span><br><span class="line">Tweet Author Profile Link</span><br><span class="line">Tweet Author Bio</span><br><span class="line">Tweet Author Following Count</span><br><span class="line">Tweet Author Follower Count</span><br><span class="line">Tweet Author Location</span><br><span class="line">Tweet Author Registration Time</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>Our system has already supported <strong>many researchers</strong>, <strong>university professors</strong>, <strong>students</strong>, and <strong>consulting companies</strong> both domestically and internationally.<br> We accept <strong>corporate payments</strong> and can issue <strong>official invoices</strong>.</p><p>If you are interested, feel free to leave a comment below the blog post.<br> If there is no timely reply, you can also contact me privately via the Afdian platform:</p><blockquote><p><a href="https://afdian.com/a/buyixiao">https://afdian.com/a/buyixiao</a></p></blockquote><p><strong>We only provide services for legitimate academic research, data analysis, and industry consulting needs.<br> Illegal/gray market users are strictly not served.</strong></p>]]></content>
      
      
      <categories>
          
          <category> Spider </category>
          
      </categories>
      
      
        <tags>
            
            <tag> x </tag>
            
            <tag> twitter </tag>
            
            <tag> spider </tag>
            
            <tag> Keyword </tag>
            
            <tag> check-in </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>都是哪些人在关注小米 SU7</title>
      <link href="/blog/xiaomi-auto-fans-portrait.html"/>
      <url>/blog/xiaomi-auto-fans-portrait.html</url>
      
        <content type="html"><![CDATA[<p>近来最火热的话题莫过于小米发布的 SU7，无论是 SU7 发布会当天的直播间人气，还是 24 小时 SU7 的大定数目，都让小米汽车吸引了无数关注。</p><p>使用 Python3 爬虫采集了「小米汽车」微博的 50000+ 粉丝，对 profile 的多个维度进行了可视分析，构建简单的用户画像分析如下：</p><blockquote><p>以下分析只针对这 50000+ 粉丝，不能代表整体~</p></blockquote><div class="note default modern"><p>前篇一：<a href="https://buyixiao.github.io/blog/ljq-fans-portrait.html">「李佳琦」微博粉丝画像简析</a></p><p>前篇二：<a href="https://buyixiao.github.io/blog/brother-yang-fans-portrait.html">「疯狂小杨哥」微博粉丝画像简析</a></p></div><ol><li>粉丝性别比为男女 13:4 ，大概就是男 3 女 1 的比例，小米的粉丝群主主要理工男居多，这很合理，不过与李佳琦粉丝男 1 女 2 的比例相比男粉比例翻了一倍多，和小杨哥男 3 女 2 相比也高出 10 多个百分点。</li><li>粉丝大部分（约 93%）是普通用户，约 2.2% 是明星名人，约 4.2% 是其他认证用户，比起前面两位大 V 粉丝中名人达人的比例，小米汽车差不多翻倍。</li><li>阳光信用上信用中上（信用较好及以上）比例 69%，信用中下（信用一般及以下）的占比约 30%，粉丝阳光信用之高可见一斑。</li><li>粉丝 ip 属地省份分布上，集中分布在广东、江苏、浙江、山东、河南等经济或人口大省，广东一骑绝尘占比超过 10%，江苏、浙江、山东均在 5% 上下。</li><li>粉丝就读或毕业学校上，武汉大学遥遥领先稳高居 top1，这很大程度上应该要归结于雷军强大的校友光环，同城双子星的华科则差不多是武大占比一半。</li><li>在粉丝的微博注册时间分布上，注册微博 10 年以上的粉丝居然占比最大，注册 3 年左右的粉丝占比最小。</li><li>去除了 1965 年以前和 2015 年以后的噪声数据，粉丝出生年份整体呈现以 1998 年为均值的正态分布，尤其集中在 1995-2000 年，95 后最粉雷军，00 后比例直接腰斩。</li><li>只有约四成的粉丝的粉丝数小于 10，有 116 个粉丝数超过 10w 的小大 V 关注了他。</li><li>最后是用户粉丝画像的词云图，浓浓的科技风，正是雷军的好友圈和他那理工男拥趸者。</li></ol><p>综上所述，关注小米 SU7 Auto 的粉丝各项指标遥遥领先。</p><p>可视化效果图如下，加载可能较慢，可以交互~</p><iframe width="100%" height="3690" scrolling="auto" frameborder="0" src="../assets/html5/xiaomi_auto_fans_analysis.html"></iframe>]]></content>
      
      
      <categories>
          
          <category> 可视化 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 可视化 </tag>
            
            <tag> 数据分析 </tag>
            
            <tag> echarts </tag>
            
            <tag> 粉丝画像 </tag>
            
            <tag> 小米 SU7 </tag>
            
            <tag> 雷军 </tag>
            
            <tag> 米粉 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>「疯狂小杨哥」微博粉丝画像简析</title>
      <link href="/blog/brother-yang-fans-portrait.html"/>
      <url>/blog/brother-yang-fans-portrait.html</url>
      
        <content type="html"><![CDATA[<p>接上篇，<a href="https://buyixiao.github.io/blog/ljq-fans-portrait.html">李佳琦微博粉丝画像简析</a> 继续使用 Python3 爬虫采集了「疯狂小杨哥」微博的 10000+ 粉丝，对 profile 的多个维度进行了可视分析，构建简单的用户画像对比李佳琦分析如下：</p><blockquote><p>以下分析只针对这 10000+ 粉丝，不能代表整体~</p></blockquote><ol><li>粉丝性别比为男女 7:5 ，大概就是男 3 女 2 的比例，男粉居然比女粉还多，这与微博整体或者李佳琦的用户画像都有些出入。</li><li>粉丝大部分（~98%）是普通用户，0.6% 是明星名人，1.5% 是其他认证用户，普通比例相比于李佳琦较多 1%，认证用户较少 1%。</li><li>阳光信用上信用中上（信用较好及以上）比例 23%，信用中下（信用一般及以下）的占比约 67%，信用较低的粉丝甚至超过了一半，相比于李佳琦粉丝有所反转。</li><li>粉丝 ip 属地省份分布上，集中分布在广东、江苏、浙江、山东、河南等经济或人口大省。</li><li>粉丝就读或毕业学校上，top 3 为清华大学、北京大学、四川大学，top 30 也是清一色的名校，这里面原因应该挺多的，欢迎在评论区畅所欲言。我觉得有一点是名校生更倾向于在自己的社交主页上公开自己的母校。</li><li>差不多一半的粉丝的微博是近一年注册的，不超过十分之一的粉丝注册微博超过了十年。</li><li>去除了 1965 年以前和 2015 年以后的噪声数据，粉丝出生年份整体呈现以 2003 年为均值的正态分布，尤其集中在 1998-2008 年；出生高峰年份整体比李佳琦粉丝晚了 3 年。</li><li>约八成的粉丝的粉丝数小于 10，有 8 个粉丝数超过 10w 的小大 V 关注了他，目测大部分的大 V 是没有采集到的。</li></ol><p>可视化效果图如下，加载可能较慢，可以交互~</p><iframe width="100%" height="3160" scrolling="auto" frameborder="0" src="../assets/html5/brother_yang_fans_analysis.html"></iframe>]]></content>
      
      
      <categories>
          
          <category> 可视化 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 可视化 </tag>
            
            <tag> 数据分析 </tag>
            
            <tag> echarts </tag>
            
            <tag> 粉丝画像 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微博 spammer 账号识别模型</title>
      <link href="/blog/weibo-spammer-account-identify-model.html"/>
      <url>/blog/weibo-spammer-account-identify-model.html</url>
      
        <content type="html"><![CDATA[<p>用过 twitter 的 <strong>botometer</strong> 的同学都知道，botometer 可以通过检测 twitter 帐户的活动评价该账号属于垃圾内容制造者的可能性。</p><blockquote><p>botometer 应该更倾向于社交机器人识别，而笔者在构建微博账号数据集的时候，更倾向于 spammer 识别，即虽然它是一个 bot 账号，但是内容和互动都正常，视为非 spammer 账号标记。</p></blockquote><p>但是据笔者所知（可能笔者孤陋寡闻），weibo 并没有对应的产品或服务。于是我从 2022.12 开始着手训练微博 spammer 账号识别模型：检测微博账号是 spammer 的可能性，一共经历了三个阶段，前面两个阶段如下：</p><ol><li>手动构建初始化数据集，只采用微博账号 profile 页面的粉丝数、关注数、微博数、认证类型、阳光信用等等特征，使用 DNN 神经网络，施以 PCA 降维和 L2 正则化，最终训练的准确率在 85% 左右。</li><li>继续扩充数据集，同时新增关系网络、微博文本采集并抽取相应特征，准确率来到 95%，但是多层关系网络的抓取等比较耗时，一个微博账号的特征信息采集抽取和识别耗时上百秒，无法做到实时识别；所以我舍弃了部分抓取耗时的字段，最终准确率固定在 90% 上下。</li></ol><p>一般来说，提升一个模型的 ACC、ROC、F1，通常具有以下方法</p><ol><li>扩充数据集。</li><li>降维。</li><li>正则化</li></ol><p>正则化我在初代模型就已经用上了，最开始模型甚至不收敛，使用正则化收敛后的最终模型准确率在 85% 左右。</p><p>降维对这个 spammer 模型来说可能只是加快了训练过程，实测准确率并没有显著提升。</p><p>而扩充数据集是一直在做的工作，目前可能还需要一个量变等到质变的时刻。</p><p>对于一个模型能提升准确率的方法都做了，所有我只能换另外一个模型方法来做提升了。</p><p>最终选定 AdaBoost，他是三种集成学习 <strong>Bagging</strong>、<strong>Boosting</strong>、<strong>Stacking</strong> 之一的 Boosting 方法下的一种名为 “Adaptive Boosting”方法（自适应增强）的缩写。</p><p>Boosting 的核心思想是 三个臭皮匠，赛过诸葛亮。一般来说，找到弱学习算法要相对容易一些，然后通过反复学习得到一系列弱分类器，组合这些弱分类器得到一个强分类器。</p><p>AdaBoost 算法的流程不算简单，感兴趣的可以搜索下。</p><p>最终我用 AdaBoost，在和上一篇推送一样，只抓取有限不耗时特征的前提下，准确率从 90% 左右直接稳定到了 95%+，识别一个给定 uid 的微博账号的 spammer 属性，耗时在 5s 以内。</p><p>最后把这个最新模型上线，视作  alpha 版本，上篇推送的模型为一般版本，长期测试 alpha 版本后，最后会覆盖一般版本。</p><p>模型网页测试地址为</p><blockquote><p><a href="https://weibo-crawl-visual.buyixiao.xyz/weibo-spammer-evaluator">https://weibo-crawl-visual.buyixiao.xyz/weibo-spammer-evaluator</a></p></blockquote><p>其中第一个 tab 是一般版本，最后一个 tab 为 alpha 版本。</p><p>同时新增了 API 接口调用，接口地址是：</p><blockquote><p><a href="https://api.buyixiao.xyz/weibo/spammer-account-evaluate">https://api.buyixiao.xyz/weibo/spammer-account-evaluate</a></p></blockquote><p>使用 Python 调用该接口的 demo 代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">test_token = <span class="string">&quot;在此处填入你申请的 token&quot;</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_spammer_evaluate</span>(<span class="params">user_id</span>):</span></span><br><span class="line">    resp = requests.get(url=<span class="string">f&#x27;https://api.buyixiao.xyz/weibo/spammer-account-evaluate&#x27;</span>, params=&#123;</span><br><span class="line">        <span class="string">&#x27;user_id&#x27;</span>: user_id, <span class="comment"># 必选参数，检测的微博账号 id</span></span><br><span class="line">        <span class="string">&#x27;token&#x27;</span>: test_token, <span class="comment"># 必选参数，校验接口</span></span><br><span class="line">        <span class="string">&#x27;alpha&#x27;</span>: true <span class="comment"># 可选参数，是否采用最新的 alpha 内测模型</span></span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(resp.url)</span><br><span class="line">    <span class="built_in">print</span>(resp.json())</span><br><span class="line">test_spammer_evaluate(user_id=<span class="string">&quot;2557129567&quot;</span>)</span><br></pre></td></tr></table></figure><p>网页可以输入单个微博账号的 uid 免费测试，而 token 的申请是按量付费的。</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spammer </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> adaboost </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>再读《湖心亭看雪》</title>
      <link href="/blog/watching-snow-with-middle-lake-pavilion.html"/>
      <url>/blog/watching-snow-with-middle-lake-pavilion.html</url>
      
        <content type="html"><![CDATA[<p>少年时初读到张岱的《湖心亭看雪》，被词中的闲情雅致感染到了，更增加了一份对西湖的向往之情。</p><blockquote><p>崇祯五年十二月，余住西湖。大雪三日，湖中人鸟声俱绝。是日更定矣，余拏一小舟，拥毳衣炉火，独往湖心亭看雪。雾凇沆砀，天与云与山与水，上下一白，湖上影子，惟长堤一痕、湖心亭一点、与余舟一芥、舟中人两三粒而已。(余拏 一作：余挐)　　</p><p>到亭上，有两人铺毡对坐，一童子烧酒炉正沸。见余大喜曰：“湖中焉得更有此人！”拉余同饮。余强饮三大白而别。问其姓氏，是金陵人，客此。及下船，舟子喃喃曰：“莫说相公痴，更有痴似相公者。”——明代·张岱《湖心亭看雪》</p></blockquote><p>第一句就是崇祯五年十二月，那时只知道崇祯是个明朝皇帝，从词中的闲情雅致推测出这应该是个和平年代。</p><p>直到我很多年后读了明末历史，除了知道崇祯皇帝叫朱由检是个急性子，知道了努尔哈赤和皇太极的雄才大略，以及熊廷弼、袁崇焕、孙承宗、录象升悲壮可惜，还知道了崇祯五年后不过十余年，满清的战火就烧到了杭州西湖湖心亭所在的江浙，这天下最柔软的腹部。</p><p>这之后我偶然再读到《湖心亭看雪》，就下意识地搜索了这首词的创作背景，才知道它并不是崇祯年间创作出来的，是明亡张岱后寄托追忆故国所作。</p><blockquote><p>《湖心亭看雪》是《陶庵梦忆》中的一篇，而《陶庵梦忆》成书于明亡后，乾隆四十年（1794年）才出版，是张岱于潦倒中所撰之回忆录。</p></blockquote><p>李叔同有一首词《送别》，</p><blockquote><p>晚风拂柳笛声残，夕阳山外山</p><p>天之涯，地之角，知交半零落</p><p>人生难得是欢聚，唯有别离多</p><p>长亭外，古道边，芳草碧连天</p><p>问君此去几时还，来时莫徘徊</p><p>天之涯，地之角，知交半零落</p><p>一壶浊洒尽余欢，今宵别梦寒</p></blockquote><p>后来被改编成歌谣，有一位文学家席慕容，在她的初中时代常常唱，其中有一句被他父亲听成了：</p><blockquote><p>长城外，古道边，芳草碧连天</p></blockquote><p>直到某一天她纠正父亲的错误，</p><blockquote><p>我把音乐课本拿出来，想要向父亲证明他的错误。可是父亲并不要看，他只是很懊丧地对我说：</p><p>“好可惜！我一直以为是长城外，以为写的是我们老家，所以第一次听这首歌时就特别地感动，并且一直没有忘记，想不到竟然这么多年是听错了，好可惜！”</p><p>父亲一连说了两个好可惜，然后就走开了，留我一个人站在空空的屋子里，不知道如何是好。</p></blockquote><p>我是个明史爱好者，更是一个精明人（精神明朝人），再读《湖心亭看雪》的些许怅然若失的心境，大抵和席慕容父亲有一点点相似。</p>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 湖心亭看雪 </tag>
            
            <tag> 明史 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>老将军，可知天水姜伯约？</title>
      <link href="/blog/jiang-wei-in-three-kingdoms.html"/>
      <url>/blog/jiang-wei-in-three-kingdoms.html</url>
      
        <content type="html"><![CDATA[<p>和三国的故事由来已久，最开始还是免不得那一句俗套，三国演义，四大名著，中小学必读本，小学的时候就拿到过一本文言文版本的三国演义，但是小学生的我对于这个满篇文言文实在提不起太大兴趣，从头读起剧情毫无起伏太乏味，索性浏览目录只看自己感兴趣的章节，什么桃园三结义、放水淹七军、空城计，都是英雄演义的经典篇章，然后就把书扔在一边积灰了。</p><p>再后来准备上初中，偶然看到一句，少不读水浒，老不读三国，于是下决心在这豆蔻年华的时候从头到尾读一遍三国，以后老了就不读了，可惜这决心下得还是不够大，细读完黄巾起义，粗读完白帝城后，又作罢，因为当时我觉得刘备死了三国演义就应该完本了，为什么后面还要写，读书人的情怀还是有那么一点，虽然说不上嚎啕大哭但是依稀记得当时眼角有泪。</p><p>大概上初中的时候，高希希拍了新版三国演义，在当时很火，因为是普通话我也看到很起劲，感觉像是困扰多年的病根被根除了，豁然开朗，一口气看到秋风五丈原，然后又不开朗且又流泪了。</p><p>高中的时候经室友介绍知道了老版三国的存在（因为当时没有网络，电视台不播的话基本不了解），然后又机缘巧合弄到一张碟片，刚开始看到老版本的场景和服饰，我就立刻按下了 DVD 机的弹出按钮，毕竟老三国审美，对于一个正值青春年华，爱鲜衣爱怒马，好华灯好烟火的少年来说，是难以接受的。</p><p>这样的认知一直持续到大学毕业，工作无聊的时候喜欢看点历史，就又看到了老版三国，这次非但没有厌恶服化道，反而出了奇地喜爱，这大概就是王羲之所说的情随事迁。</p><p>一刷的时候，开始（有机会）注意到一个人：姜维，对话赵云那一句，“老将军，可知天水姜伯约？”</p><p>尽显这位天水麒麟儿的少年神采，少年时一次看到刘备死、又看到诸葛亮死，这次看到姜维死，也差不多是全剧终，又流泪了，这是经历了社会敲打的成年人的泪水。</p><mark class="hl-label orange">臣，一心讨贼，以继诸葛丞相之遗志！</mark> <mark class="hl-label green">我有一计，可使汉室，幽而复明！</mark> <mark class="hl-label pink">我计不成，乃天命也！</mark> <p><img src="https://s2.loli.net/2023/10/06/KpAfZSbz9akT7UC.jpg" alt="jiangwei_old.jpg"></p><p>他从未见过先帝，却能为先帝的夙愿奉献一生；他原是魏将，却成季汉最后的大将军；他明知不可为而为之，是个彻彻底底的理想主义者，和刘关张、诸葛亮一样，为匡扶汉室，燃烧了自己所有。</p><p>”周公恐惧流言日，王莽谦恭未篡时”，尚未盖棺定论之前，他恐怕是蜀汉一些人眼中的奸臣，劳民伤财，可零和博弈，搏一搏至少还有机会，躺平最后只能投降。“宁可战死失社稷，绝不拱手让江山”，某种意义上，大将军姜维和北地王刘谌是更合适的君臣搭配，可历史不给机会。</p><p>于是乎，姜维死，大汉亡。类似的剧情发生在约 1400 年后，李定国身死，大明亡。</p><p>“蜀国之灭，绝非将军之罪，实是后主无道而致”，卫瓘这样评价道，然后无数后人点了点赞。</p>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 姜维 </tag>
            
            <tag> 三国演义 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>「李佳琦」微博粉丝画像简析</title>
      <link href="/blog/ljq-fans-portrait.html"/>
      <url>/blog/ljq-fans-portrait.html</url>
      
        <content type="html"><![CDATA[<p>编写 Python3 爬虫采集了李佳琦微博的 10000+ 粉丝，对 profile 的多个维度进行了可视分析，视图构建简单的用户画像如下：</p><ol><li>粉丝性别比为男女 7:13 ，大概就是男 1 女 2 的比例，这和微博整体的用户画像一致，没有因为是美妆博主而女粉占比过多。</li><li>粉丝大部分（~97%）是普通用户，约 1% 是明星名人，2% 是其他认证用户。</li><li>阳光信用上信用中上比例 60%，信用中下的占比约 4  成。</li><li>粉丝 ip 属地省份分布上，集中分布在广东、江苏、浙江、山东、河南等经济或人口大省。</li><li>粉丝就读或毕业学校上，top 3 为清华大学、北京大学、山东大学，top 30 也是清一色的名校，这里面原因应该挺多的，欢迎在评论区畅所欲言。我觉得有一点是名校生更倾向于在自己的社交主页上公开自己的母校。</li><li>约六分之一的粉丝的微博是近一年注册的，有超过十分之一的粉丝注册微博超过了十年。</li><li>去除了 1965 年以前和 2015 年以后的噪声数据，粉丝出生年份整体呈现以 2000 年为均值的正态分布，尤其集中在 1995-2005 年。1970 年是一个小高峰的原因是 1970 年是计算机计时开始时间也是默认时间，至于 1990 年为什么是小高峰有待考量。</li><li>约六成的粉丝的粉丝数小于 10，有 6 个粉丝数超过 10w 的小大 V 关注了他，目测大部分的大 V 是没有采集到的。</li></ol><p>可视化效果图如下，加载可能较慢，可以交互~</p><iframe width="100%" height="3160" scrolling="auto" frameborder="0" src="../assets/html5/ljq_fans_analysis.html"></iframe>]]></content>
      
      
      <categories>
          
          <category> 可视化 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 可视化 </tag>
            
            <tag> 数据分析 </tag>
            
            <tag> echarts </tag>
            
            <tag> 粉丝画像 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pandas 绘制非数值类型饼图</title>
      <link href="/blog/pandas-pie-plot.html"/>
      <url>/blog/pandas-pie-plot.html</url>
      
        <content type="html"><![CDATA[<p>Excel 能够画饼图，但是限于本列数据为数值类型，对于非数值类型 (non-numeric type) 则无能无力，pandas 作为 excel 的代码版本，当然没有这个限制~</p><p>对于数值类型的列，可以直接用下面一行代码完成饼图：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.plot.pie(y=<span class="string">&#x27;col_name&#x27;</span>, figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br></pre></td></tr></table></figure><p>如果 <code>col_name</code> 是非数值列，代码会报以下错误：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TypeError: <span class="string">&#x27;&lt;&#x27;</span> <span class="keyword">not</span> supported between instances of <span class="string">&#x27;str&#x27;</span> <span class="keyword">and</span> <span class="string">&#x27;int&#x27;</span></span><br></pre></td></tr></table></figure><p>下面这个是 Matplotlib 画饼图的 MVP</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置中文字体和负号正常显示</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 指定默认字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 解决保存图像是负号&#x27;-&#x27;显示为方块的问题</span></span><br><span class="line">sns.set_context(<span class="string">&quot;paper&quot;</span>)</span><br><span class="line">sns.set_style(<span class="string">&#x27;whitegrid&#x27;</span>)</span><br><span class="line">sns.<span class="built_in">set</span>(font=<span class="string">&#x27;SimHei&#x27;</span>)  <span class="comment"># 解决Seaborn中文显示问题</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pie_plot</span>(<span class="params">values, labels, title</span>):</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>), dpi=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 正圆</span></span><br><span class="line">    plt.axes(aspect=<span class="string">&#x27;equal&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.pie(values, labels=labels, autopct=<span class="string">&#x27;%.1f%%&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.title(title)</span><br><span class="line"></span><br><span class="line">    plt.legend()</span><br></pre></td></tr></table></figure><p>需要用胶水将 pandas 的指定列和这个函数关联起来，胶水之一是 <code>value_counts</code> ，它可以对一列数据的值做字典统计，另外就是<code>unique()</code>，可以列举出某列的所有非重复值，这两份胶水分别对应这个函数的 <code>values</code> 和 <code>labels</code> 参数~</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pie_plot(df[<span class="string">&#x27;source&#x27;</span>].value_counts().values, df[<span class="string">&#x27;source&#x27;</span>].unique(), <span class="string">&#x27;发布机型&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>但是还有一个隐藏的问题是，<code>value_counts</code> 不会统计 <code>nan</code> ，但是 <code>unique</code> 会统计 <code>nan</code>，如果不去除 <code>nan</code> 会造成 <code>value_counts().values</code> 和 <code>unique</code> 长度不一样~</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 去除 nan 等空值</span></span><br><span class="line">df.dropna(how=<span class="string">&#x27;any&#x27;</span>, subset=[<span class="string">&#x27;source&#x27;</span>], inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">pie_plot(df[<span class="string">&#x27;source&#x27;</span>].value_counts().values, df[<span class="string">&#x27;source&#x27;</span>].unique(), <span class="string">&#x27;发布机型&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>最后还有一个优化的点，为了保证图例标签的连续性，可以先给该列排个序~</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 去除 nan 等空值</span></span><br><span class="line">df.dropna(how=<span class="string">&#x27;any&#x27;</span>, subset=[<span class="string">&#x27;source&#x27;</span>], inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 排序</span></span><br><span class="line">df.sort_values(by=<span class="string">f&#x27;source&#x27;</span>, ascending=<span class="literal">True</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">pie_plot(df[<span class="string">&#x27;source&#x27;</span>].value_counts().values, df[<span class="string">&#x27;source&#x27;</span>].unique(), <span class="string">&#x27;发布机型&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>笔者已经把这个小逻辑做成了一个网页小工具，可以在网页上传 CSV 文件，选择任意列（要求该列的值不超过 50 类，可多选）画饼图，可选 AntV、Echarts、Matplotlib 三种画图引擎，网页地址如下：</p><blockquote><p><a href="https://tools.buyixiao.xyz/pie-ploter">https://tools.buyixiao.xyz/pie-ploter</a></p></blockquote><p>欢迎尝试~</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> matplotlib </tag>
            
            <tag> pandas </tag>
            
            <tag> value_counts </tag>
            
            <tag> chart </tag>
            
            <tag> pie </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>近来敬佩两种人</title>
      <link href="/blog/two-types-of-people-admired.html"/>
      <url>/blog/two-types-of-people-admired.html</url>
      
        <content type="html"><![CDATA[<p>近些日子的所见所闻，带来少许所思所想，让我对两种人的敬佩之情油然而生。</p><p>第一种的代表人物是陈行甲，可能是最近有关他的报道日多，说他如何出淤泥而不染，看到报道正文里富于魔幻现实主义的情节和评论区难得一见的发自内心的各色各样的赞美之词，我是完全相信这个事实的，但最后真正让我震撼的，是我在抖音上刷到了他发的一些视频。</p><p>他最近才开通了抖音账号，记录自己因为做公益而在祖国各地奔走的瞬间，视频看到他的精气神，那是一种浩然正气，只有做事不愧天地的人，才有这种精神面貌，我更加确信古人的一句话，「君子坦荡荡，小人常戚戚」。</p><p>这类人，我在「虽千万人吾往矣」的萧峰身上见过，在「艰难奋长戟，万古用一夫」的郭靖身上也见过；这类人，往往都比较天真，可是天真往往是道德的上限；这类人，我把他们称之为「正气者」，虽不能至，吾心向往。</p><p>第二种的人的代表是老爷子任正非，任正非一直是我偶像，但是最近才听到下面这个桥段，大意是：在百万大军裁撤的时代洪流下，作为团职干部的任正非也没能避免被裹挟，按照当时的惯例，到地方后找个正处的工作没有问题，但是他到的是深圳，只能给副处，任老爷子就不答应了，义正言辞提出正处的要求被拒绝后，一生气就不干了，索性创办了华为。苏秦曰：「使我有洛阳二顷田，焉能配六国相印？」</p><p>我不禁想到了当下这个时局，某种意义上就和当年任老爷子处境一样，大家都被推着走的时候，都在被迫内卷而争取一张在当时看来是豪华邮轮的船票的时候，任老爷子划上了他的独木舟，开始了他的大航海，这类人，我尊之为「破局者」。</p><p>而对于包含我自己在内的绝大部分普通人来说，竟为一船票庸碌小半生，航海家是不会真正上岸的，要么发现新大陆，要么就魂归大海。</p><blockquote><p>其实这篇胡说八道，可以起个另外的标题，「不进体制的两个理由」，</p><p>一个原因是这两类人都是从体制内跳出来的，另一个原因是我的长辈在不遗余力地劝我进体制内。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 悟 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TFBoys 易烊千玺、王源、王俊凯微博粉丝重叠度可视化</title>
      <link href="/blog/tfboys-fans-overlap-visual.html"/>
      <url>/blog/tfboys-fans-overlap-visual.html</url>
      
        <content type="html"><![CDATA[<p>编写了 Python3 爬虫，分别采集了 TF-Boys 的三小只易烊千玺、王源、王俊凯各 11000+ 粉丝累计 33000+ 粉丝，然后进行了粉丝重叠度可视化，同时对粉丝的性别、属地、账号注册时间信息作了对比可视化。</p><p>三小只粉丝重叠度的韦恩图如下：</p><p><img src="https://s2.loli.net/2023/07/21/LcGTZAxjKO1uHmQ.png" alt="tfboys-fans-overlap.png"></p><p>三人共同粉丝在各自的总粉丝中占比五分之一（1999 除以 11000）左右，其中易烊千玺和王俊凯两人的粉丝重叠度达到了惊人的三分之一以上（4277 除以 11000）。</p><p>下面是粉丝性别构成占比、属地分布和账号注册时长对比的可视化，结论如下：</p><ol><li>三小只的男女粉比例大致为 1:2，其中王源的男女粉比例最大，即男粉比例最大，女粉比例最小。顺嘴提一句，从上面的韦恩图看出来王源和其他两人的粉丝重合度也是相对最少的。</li><li>三小只的粉丝属地分布中，东北和西北地区的粉丝明显比东南和西南少，其中山东、河南、广东位于前三甲，有人详细解释下为什么吗?</li><li>三小只中，易烊千玺 的粉丝中注册微博 2 年或者 5 年以上的占比明显比其他两人多，换句话说，易烊千玺粉丝中微博是新号的占比最少。</li></ol><p>可视化效果图如下，加载可能较慢，可以交互~</p><iframe width="100%" height="1580" scrolling="auto" frameborder="0" src="../assets/html5/tfboys_fans_analysis.html"></iframe>]]></content>
      
      
      <categories>
          
          <category> 可视化 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 可视化 </tag>
            
            <tag> 粉丝重叠度 </tag>
            
            <tag> 数据分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>matplotlib 折线图颜色分段显示</title>
      <link href="/blog/matplotlib-segmented-color-graph.html"/>
      <url>/blog/matplotlib-segmented-color-graph.html</url>
      
        <content type="html"><![CDATA[<p>近来需要画一个多段折线图，并且每段颜色都不一样，搜索得知，大部分已有的实现都是基于 <code>matplotlib</code> 的<code>LineCollection</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib.collections <span class="keyword">import</span> LineCollection</span><br></pre></td></tr></table></figure><p>这种方式还要自己组装 segments ，略显晦涩，索性自己实现了。效果如下：</p><p><img src="https://s2.loli.net/2023/05/13/7LDzWrkYbZjK4Gx.png" alt="segmented-color buyixiao blog"></p><p>其中 x，y 序列大致如下，没什么特殊的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x</span><br><span class="line"> [<span class="string">&#x27;2023-02-06 12&#x27;</span>, <span class="string">&#x27;2023-02-06 18&#x27;</span>, <span class="string">&#x27;2023-02-07 00&#x27;</span>, <span class="string">&#x27;2023-02-07 06&#x27;</span>, <span class="string">&#x27;2023-02-07 12&#x27;</span>, <span class="string">&#x27;2023-02-07 18&#x27;</span>, <span class="string">&#x27;2023-02-08 00&#x27;</span>, <span class="string">&#x27;2023-02-08 06&#x27;</span>, <span class="string">&#x27;2023-02-08 12&#x27;</span>, <span class="string">&#x27;2023-02-08 18&#x27;</span>, <span class="string">&#x27;2023-02-09 00&#x27;</span>, <span class="string">&#x27;2023-02-09 06&#x27;</span>, <span class="string">&#x27;2023-02-09 12&#x27;</span>, <span class="string">&#x27;2023-02-09 18&#x27;</span>, <span class="string">&#x27;2023-02-10 00&#x27;</span>, <span class="string">&#x27;2023-02-10 06&#x27;</span>, <span class="string">&#x27;2023-02-10 12&#x27;</span>, <span class="string">&#x27;2023-02-10 18&#x27;</span>, <span class="string">&#x27;2023-02-11 00&#x27;</span>, <span class="string">&#x27;2023-02-11 06&#x27;</span>, <span class="string">&#x27;2023-02-11 12&#x27;</span>, <span class="string">&#x27;2023-02-11 18&#x27;</span>, <span class="string">&#x27;2023-02-12 00&#x27;</span>, <span class="string">&#x27;2023-02-12 06&#x27;</span>, <span class="string">&#x27;2023-02-12 12&#x27;</span>, <span class="string">&#x27;2023-02-12 18&#x27;</span>, <span class="string">&#x27;2023-02-13 00&#x27;</span>, <span class="string">&#x27;2023-02-13 06&#x27;</span>, <span class="string">&#x27;2023-02-13 12&#x27;</span>, <span class="string">&#x27;2023-02-13 18&#x27;</span>, <span class="string">&#x27;2023-02-14 00&#x27;</span>, <span class="string">&#x27;2023-02-14 06&#x27;</span>, <span class="string">&#x27;2023-02-14 12&#x27;</span>, <span class="string">&#x27;2023-02-14 18&#x27;</span>, <span class="string">&#x27;2023-02-15 00&#x27;</span>, <span class="string">&#x27;2023-02-15 06&#x27;</span>, <span class="string">&#x27;2023-02-15 12&#x27;</span>, <span class="string">&#x27;2023-02-15 18&#x27;</span>, <span class="string">&#x27;2023-02-16 00&#x27;</span>, <span class="string">&#x27;2023-02-16 06&#x27;</span>, <span class="string">&#x27;2023-02-16 12&#x27;</span>, <span class="string">&#x27;2023-02-16 18&#x27;</span>, <span class="string">&#x27;2023-02-17 00&#x27;</span>, <span class="string">&#x27;2023-02-17 06&#x27;</span>, ...]</span><br><span class="line"> </span><br><span class="line"> y</span><br><span class="line">  [   <span class="number">1</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">1</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span></span><br><span class="line">    <span class="number">0</span>    <span class="number">0</span>    <span class="number">1</span>    <span class="number">1</span>    <span class="number">3</span>    <span class="number">0</span>    <span class="number">1</span>    <span class="number">2</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span></span><br><span class="line">    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">1</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">1</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span></span><br><span class="line">    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">2</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">1</span></span><br><span class="line">    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">1</span>    <span class="number">4</span>  <span class="number">375</span>   <span class="number">83</span>  <span class="number">145</span>   <span class="number">15</span>  <span class="number">197</span>  <span class="number">264</span></span><br><span class="line">  <span class="number">135</span>   <span class="number">47</span>  <span class="number">164</span>   <span class="number">69</span>  <span class="number">116</span>   <span class="number">39</span>  <span class="number">109</span>   <span class="number">41</span>   <span class="number">54</span>   <span class="number">16</span>   <span class="number">20</span>   <span class="number">13</span>   <span class="number">27</span>   <span class="number">17.</span>..]</span><br></pre></td></tr></table></figure><h3 id="均分多段"><a href="#均分多段" class="headerlink" title="均分多段"></a>均分多段</h3><p>第一种需求是均分多段，即等分折现，其实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># author:           inspurer(月小水长)</span></span><br><span class="line"><span class="comment"># create_time:      2023/5/13 14:31</span></span><br><span class="line"><span class="comment"># 运行环境           Python3.6+</span></span><br><span class="line"><span class="comment"># github            https://github.com/inspurer</span></span><br><span class="line"><span class="comment"># website           https://buyixiao.github.io/</span></span><br><span class="line"><span class="comment"># 微信公众号         月小水长</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> ticker</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 指定默认字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 解决保存图像是负号&#x27;-&#x27;显示为方块的问题</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unique_color</span>():</span></span><br><span class="line">    <span class="keyword">return</span> plt.cm.gist_ncar(np.random.random())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_colored_seg</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        均分多段</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;x\n&#x27;</span>, x)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;y\n&#x27;</span>, y)</span><br><span class="line"></span><br><span class="line">    seg_x_list = []</span><br><span class="line">    seg_y_list = []</span><br><span class="line"></span><br><span class="line">    max_x = <span class="built_in">max</span>(x)</span><br><span class="line">    max_y = <span class="built_in">max</span>(y)</span><br><span class="line"></span><br><span class="line">    seg_cnt = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    seg_label = [<span class="string">f&#x27;the label of <span class="subst">&#123;i&#125;</span>th turning point&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(seg_cnt)]</span><br><span class="line"></span><br><span class="line">    seg_point_cnt = <span class="built_in">len</span>(x) // seg_cnt</span><br><span class="line"></span><br><span class="line">    cur_seg_pointer = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> index, ele <span class="keyword">in</span> <span class="built_in">enumerate</span>(x):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(seg_x_list) &lt; seg_point_cnt <span class="keyword">and</span> index &lt; <span class="built_in">len</span>(x) - <span class="number">1</span>:</span><br><span class="line">            seg_x_list.append(ele)</span><br><span class="line">            seg_y_list.append(y[index])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            cur_color = unique_color()</span><br><span class="line">            plt.plot(seg_x_list, seg_y_list, color=cur_color)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> cur_seg_pointer &lt; seg_cnt:</span><br><span class="line">                plt.axvline(x[index - <span class="number">1</span>], color=cur_color, linestyle=<span class="string">&quot;dashed&quot;</span>)</span><br><span class="line">                plt.text(x[index - <span class="number">1</span>], max_y // <span class="number">1.5</span>, seg_label[cur_seg_pointer], fontsize=<span class="number">12</span>,</span><br><span class="line">                         ha=<span class="string">&#x27;center&#x27;</span>)</span><br><span class="line">            seg_x_list = [x[index - <span class="number">1</span>]]</span><br><span class="line">            seg_y_list = [y[index - <span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line">            cur_seg_pointer += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    plt.gca().xaxis.set_major_locator(ticker.MultipleLocator(<span class="number">50</span>))</span><br><span class="line">    plt.ylim((<span class="number">0</span>, max_y))</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;per 6h&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;period weibo cnt&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># to prepare your own x,y list</span></span><br><span class="line">plot_colored_seg([<span class="built_in">str</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> ts_6h.index.strftime(<span class="string">&#x27;%Y-%m-%d %H&#x27;</span>)], ts_6h.values)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="值分多段"><a href="#值分多段" class="headerlink" title="值分多段"></a>值分多段</h3><p>第二种是值分多段，即按照 x 或者 y 的值划分多段，这种更灵活，可以说是均分多段的超集，其源代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># author:           inspurer(月小水长)</span></span><br><span class="line"><span class="comment"># create_time:      2023/5/13 14:31</span></span><br><span class="line"><span class="comment"># 运行环境           Python3.6+</span></span><br><span class="line"><span class="comment"># github            https://github.com/inspurer</span></span><br><span class="line"><span class="comment"># website           https://buyixiao.github.io/</span></span><br><span class="line"><span class="comment"># 微信公众号         月小水长</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> ticker</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 指定默认字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 解决保存图像是负号&#x27;-&#x27;显示为方块的问题</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unique_color</span>():</span></span><br><span class="line">    <span class="keyword">return</span> plt.cm.gist_ncar(np.random.random())</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_colored_seg_2</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        值分多段</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;x\n&#x27;</span>, x)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;y\n&#x27;</span>, y)</span><br><span class="line"></span><br><span class="line">    seg_x_list = []</span><br><span class="line">    seg_y_list = []</span><br><span class="line"></span><br><span class="line">    max_x = <span class="built_in">max</span>(x)</span><br><span class="line">    max_y = <span class="built_in">max</span>(y)</span><br><span class="line"></span><br><span class="line">    turn_points_x = [<span class="string">&#x27;2023-03-07 06&#x27;</span>, <span class="string">&#x27;2023-03-16 12&#x27;</span>, <span class="string">&#x27;2023-04-08 06&#x27;</span>]</span><br><span class="line">    seg_color_list = [unique_color() <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(turn_points_x))]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> index, ele <span class="keyword">in</span> <span class="built_in">enumerate</span>(x):</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ele <span class="keyword">in</span> turn_points_x:</span><br><span class="line">            turn_index = turn_points_x.index(ele)</span><br><span class="line">            cur_color = seg_color_list[turn_index]</span><br><span class="line">            plt.plot(seg_x_list, seg_y_list, color=cur_color)</span><br><span class="line">            plt.axvline(x[index - <span class="number">1</span>], color=cur_color, linestyle=<span class="string">&quot;dashed&quot;</span>)</span><br><span class="line">            plt.text(x[index - <span class="number">1</span>], max_y // <span class="number">1.5</span>, <span class="string">f&#x27;the label of <span class="subst">&#123;turn_index + <span class="number">1</span>&#125;</span>th turning point&#x27;</span>, fontsize=<span class="number">12</span>,</span><br><span class="line">                     ha=<span class="string">&#x27;center&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            seg_x_list = [x[index - <span class="number">1</span>]]</span><br><span class="line">            seg_y_list = [y[index - <span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            seg_x_list.append(ele)</span><br><span class="line">            seg_y_list.append(y[index])</span><br><span class="line"></span><br><span class="line">    plt.gca().xaxis.set_major_locator(ticker.MultipleLocator(<span class="number">50</span>))</span><br><span class="line">    plt.ylim((<span class="number">0</span>, max_y))</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;per 6h&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;period weibo cnt&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">   </span><br><span class="line"><span class="comment"># to prepare your own x,y list</span></span><br><span class="line">plot_colored_seg_2([<span class="built_in">str</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> ts_6h.index.strftime(<span class="string">&#x27;%Y-%m-%d %H&#x27;</span>)], ts_6h.values)</span><br></pre></td></tr></table></figure><p>转载请注明来源，如有更好的思路，欢迎留言~</p>]]></content>
      
      
      <categories>
          
          <category> 可视化 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> matplotlib </tag>
            
            <tag> segmented-color </tag>
            
            <tag> line-graph </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pandas 将 json 转成 csv</title>
      <link href="/blog/convert-json-to-csv.html"/>
      <url>/blog/convert-json-to-csv.html</url>
      
        <content type="html"><![CDATA[<p>今天分享的是 <a href="https://buyixiao.github.io/tags/pandas/">【月小水长】pandas 三十六计系列</a> 的第八篇 ，一个小工具，将 json 文件转成 csv 文件。</p><p>文件格式是表，文件内容是里，只要里子一样，外表是可以像穿衣一样随便换的，就像在 MySQL 中，可以任意导入导出 SQL、csv、json 等文件一样。</p><p>假设我们有一个这样的 json 文件：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;4893424946515214&quot;</span>: &#123;</span><br><span class="line">    <span class="attr">&quot;mid&quot;</span>: <span class="string">&quot;4893424946515214&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;weibo_link&quot;</span>: <span class="string">&quot;https://weibo.com/2803301701/MDcporkU6&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;text&quot;</span>: <span class="string">&quot;据悉，全城月季花已逐渐进入盛花期。&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;publish_time&quot;</span>: <span class="string">&quot;2023-04-22 20:34:45&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;user_link&quot;</span>: <span class="string">&quot;https://weibo.com/u/2803301701&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;user_name&quot;</span>: <span class="string">&quot;人民日报&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;reposts_count&quot;</span>: <span class="number">55</span>,</span><br><span class="line">    <span class="attr">&quot;comments_count&quot;</span>: <span class="number">92</span>,</span><br><span class="line">    <span class="attr">&quot;attitudes_count&quot;</span>: <span class="number">298</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">&quot;4893416880346795&quot;</span>: &#123;</span><br><span class="line">    <span class="attr">&quot;mid&quot;</span>: <span class="string">&quot;4893416880346795&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;weibo_link&quot;</span>: <span class="string">&quot;https://weibo.com/2803301701/MDcco1sdt&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;text&quot;</span>: <span class="string">&quot;4月22日，陕西西安。游客发视频... &quot;</span>,</span><br><span class="line">    <span class="attr">&quot;publish_time&quot;</span>: <span class="string">&quot;2023-04-22 20:02:42&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;user_link&quot;</span>: <span class="string">&quot;https://weibo.com/u/2803301701&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;user_name&quot;</span>: <span class="string">&quot;人民日报&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;reposts_count&quot;</span>: <span class="number">119</span>,</span><br><span class="line">    <span class="attr">&quot;comments_count&quot;</span>: <span class="number">249</span>,</span><br><span class="line">    <span class="attr">&quot;attitudes_count&quot;</span>: <span class="number">785</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">&quot;4893410513127118&quot;</span>: &#123;</span><br><span class="line">    <span class="attr">&quot;mid&quot;</span>: <span class="string">&quot;4893410513127118&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;weibo_link&quot;</span>: <span class="string">&quot;https://weibo.com/2803301701/MDc27d7vo&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;text&quot;</span>: <span class="string">&quot;第54个世界地球日，江豚回家路还有多远...&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;publish_time&quot;</span>: <span class="string">&quot;2023-04-22 19:37:24&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;user_link&quot;</span>: <span class="string">&quot;https://weibo.com/u/2803301701&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;user_name&quot;</span>: <span class="string">&quot;人民日报&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;reposts_count&quot;</span>: <span class="number">119</span>,</span><br><span class="line">    <span class="attr">&quot;comments_count&quot;</span>: <span class="number">145</span>,</span><br><span class="line">    <span class="attr">&quot;attitudes_count&quot;</span>: <span class="number">463</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在要转成下面这样的 csv：</p><table><thead><tr><th>mid</th><th>weibo_link</th><th>text</th><th>publish_time</th><th>user_link</th><th>user_name</th><th>reposts_count</th><th>comments_count</th><th>attitudes_count</th></tr></thead><tbody><tr><td>4893424946515214</td><td><a href="https://weibo.com/2803301701/MDcporkU6">https://weibo.com/2803301701/MDcporkU6</a></td><td>据悉，全城月季花已逐渐进入盛花期。</td><td>2023-04-22 20:34:45</td><td><a href="https://weibo.com/u/2803301701">https://weibo.com/u/2803301701</a></td><td>人民日报</td><td>55</td><td>92</td><td>298</td></tr><tr><td>4893416880346795</td><td><a href="https://weibo.com/2803301701/MDcco1sdt">https://weibo.com/2803301701/MDcco1sdt</a></td><td>4月22日，陕西西安。游客发视频…</td><td>2023-04-22 20:02:42</td><td><a href="https://weibo.com/u/2803301701">https://weibo.com/u/2803301701</a></td><td>人民日报</td><td>119</td><td>249</td><td>785</td></tr><tr><td>4893410513127118</td><td><a href="https://weibo.com/2803301701/MDc27d7vo">https://weibo.com/2803301701/MDc27d7vo</a></td><td>第54个世界地球日，江豚回家路还有多远…</td><td>2023-04-22 19:37:24</td><td><a href="https://weibo.com/u/2803301701">https://weibo.com/u/2803301701</a></td><td>人民日报</td><td>119</td><td>145</td><td>463</td></tr></tbody></table><p>只需要运行下面这份代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># author:           inspurer(月小水长)</span></span><br><span class="line"><span class="comment"># create_time:      2023/4/22 20:49</span></span><br><span class="line"><span class="comment"># 运行环境           Python3.6+</span></span><br><span class="line"><span class="comment"># github            https://github.com/inspurer</span></span><br><span class="line"><span class="comment"># website           https://buyixiao.github.io/</span></span><br><span class="line"><span class="comment"># 微信公众号         月小水长</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_json_to_csv</span>(<span class="params">input_json_path, output_csv_path</span>):</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(input_json_path, mode=<span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8-sig&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        input_json = json.loads(f.read())</span><br><span class="line"></span><br><span class="line">    data_list = []</span><br><span class="line"></span><br><span class="line">    data_cols = input_json[<span class="built_in">list</span>(input_json.keys())[<span class="number">0</span>]].keys()</span><br><span class="line">    <span class="keyword">for</span> a_weibo <span class="keyword">in</span> input_json.values():</span><br><span class="line">        data_list.append(<span class="built_in">list</span>(a_weibo.values()))</span><br><span class="line">    df = pd.DataFrame(data_list, columns=data_cols)</span><br><span class="line"></span><br><span class="line">    df.to_csv(output_csv_path, index=<span class="literal">False</span>, encoding=<span class="string">&#x27;utf-8-sig&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">convert_json_to_csv(<span class="string">&#x27;./data/2803301701.json&#x27;</span>, <span class="string">&#x27;./data/2803301701.csv&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>代码中没有指定 csv 的任何列名，自动从 json 文件中获取，具有一定的普适性。</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pandas </tag>
            
            <tag> json </tag>
            
            <tag> csv </tag>
            
            <tag> 文件转换 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pandas 缺失值的识别和处理</title>
      <link href="/blog/pandas-na-tricks.html"/>
      <url>/blog/pandas-na-tricks.html</url>
      
        <content type="html"><![CDATA[<p> dataframe 中的缺失值非常常见，很有必要掌握精准识别和处理确实值的技巧。</p><h3 id="识别缺失值"><a href="#识别缺失值" class="headerlink" title="识别缺失值"></a>识别缺失值</h3><p>pandas 会将诸如 <code>NaN</code>、<code>null</code>、<code>None</code>、<code>NA</code> 等值视为缺失值，但是在实践中，类似 <code>init</code> 、<code>暂无</code>、<code>缺失</code> 等这样的值，我们也视为缺失值，怎么把这个认知喂给 pandas 呢，有两个办法。</p><p>第一种方法是在读取文件时，比如 <code>read_csv()</code>，有一个参数 <code>na_values</code>，它接受一个 list 列表，里面的每一个值就是我们要新增的缺失值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">&#x27;demo.csv&#x27;</span>,na_values=[<span class="string">&#x27;init&#x27;</span>,<span class="string">&#x27;暂无&#x27;</span>])</span><br></pre></td></tr></table></figure><p>第二个方法是读取文件后，使用 replace，如果有很多个，不可避免要使用 for 循环</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.replace(<span class="string">&#x27;init&#x27;</span>, np.nan, inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h3 id="处理缺失值"><a href="#处理缺失值" class="headerlink" title="处理缺失值"></a>处理缺失值</h3><p>两种思路，一种是去除缺失值、另外一种是填充缺失值。</p><h4 id="去除缺失值"><a href="#去除缺失值" class="headerlink" title="去除缺失值"></a>去除缺失值</h4><p>dataframe 内置了这个方法 <code>dropna()</code> ，第一个参数 axis 是老生常谈的了，会经常遇到，简单来说 axis =0 （默认值）就是一行一行的处理，axis=1 就是一列一列的处理；第二个参数 inplace 更加常见，取值 False（默认值） 时返回修改后的 dataframe，取值 True 意即原地修改，也就没有返回值。最后一个参数 how 取值为 <code>all</code>、<code>any</code> 之一，前一个意思为如果这一行所有的 item 都是缺失值才去除，后者条件更加宽松：只有某一行有一个 item 是缺失值就去除。</p><h4 id="填充缺失值"><a href="#填充缺失值" class="headerlink" title="填充缺失值"></a>填充缺失值</h4><p>常见的填充方式也有两种，第一种是使用同列的平均值、或者中位数填充。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># price 列的缺失值用均值代替</span></span><br><span class="line">df.fillna(&#123;<span class="string">&#x27;price&#x27;</span>: df[<span class="string">&#x27;price&#x27;</span>].mean()&#125;)</span><br></pre></td></tr></table></figure><p>另外一种是在该列使用插值，此种方式更为优雅。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;price&#x27;</span>] = df[<span class="string">&#x27;price&#x27;</span>].interpolate(method=<span class="string">&#x27;linear&#x27;</span>)</span><br></pre></td></tr></table></figure><p>method 可以取值为：</p><ul><li><code>slinear</code>、<code>linear</code>：线性插值</li><li><code>nearest</code>：最邻近插值法</li><li>更多取值的可以参考官方文档</li></ul>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pandas </tag>
            
            <tag> NA </tag>
            
            <tag> interpolate </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CBDB 历史人物关系和足迹可视化</title>
      <link href="/blog/historical-figure-visual.html"/>
      <url>/blog/historical-figure-visual.html</url>
      
        <content type="html"><![CDATA[<p>中国历代人物传记资料库（CBDB）是在社会学科领域有着鼎鼎大名，它系统性地收入了中国历史上所有重要的传记资料，其项目主页地址如下：</p><p><a href="https://projects.iq.harvard.edu/chinesecbdb">https://projects.iq.harvard.edu/chinesecbdb</a></p><p>我最开始接触到这个数据库还是我大二时候，然后那时我一无所能，面对这么庞大的数据库无从下手。等到后面学了数据库基本原理和技术，以及一点数据分析可视化技巧后，才陆陆续续有了一些可以实现的 idea，于是上周日完成了一些可能相对古早的 idea，一并部署上线，页面地址为：</p><p><a href="https://tools.buyixiao.xyz/historical-figure-query">https://tools.buyixiao.xyz/historical-figure-query</a></p><p>页面长这样，非常简洁。</p><p><img src="https://s2.loli.net/2023/03/14/9wuKHqrjS3ngibY.png"></p><p>页面功能概括如下：只需要输入一个历史人物名（CBDB 共收录 52w 余人），就能生成该人物的社会关系图、亲属关系图以及此人在华夏大地留下的足迹图。</p><p>人海浮沉几万里，此心安处是吾乡，苏东坡的一生，几乎都是在漂泊中度过的。下文将用今天分享的工具，从一个小角度看见大才子。</p><p>在页面上输入苏轼并回车，可得：</p><p><img src="https://s2.loli.net/2023/03/14/7wod2tv3h5xIe9z.png"></p><p>​        苏轼，男，宋朝人，生于公元 1036 年，卒于公元 1101 年，享年 66 岁。</p><p><img src="https://s2.loli.net/2023/03/14/bjIDNFRzM58rum7.png"></p><p>苏轼的社会关系（包括敌人、朋友等等）非常复杂，大部分是诗文雅趣之事，也有惨遭小人攻讦之难。</p><p><img src="https://s2.loli.net/2023/03/14/eN7PkOy3MgxpujE.png"></p><p>相比较之下，苏轼的亲属关系就显得简单许多，这大概和传记对其家人（可能苏洵、苏辙除外）记载并不多。</p><p><img src="https://s2.loli.net/2023/03/14/guAbIxZ5SVw6cz9.png"></p><p>苏轼是四川眉山人，出生于 1036 年，在 1056 年以前，也就是他人生的前二十年，几乎都是在巴山夜雨中度过的，然后前往北宋都城开封应试，遇见伯乐欧阳修，就在他名动京师之时，母亲去世，苏轼携本家一大一小二苏回川奔丧，守丧期满后至凤翔府做官。（如果前往网页，上面的地图可放大缩小，这些旅程可以看得很清）</p><p>因和主持变法的王安石政见不和，自请出任杭州通判，江南风月好哇，于是就有了欲把西湖比西子，有了苏堤春晓、三潭映月，还有那令人垂涎三尺的东坡肉。（按史实考，实际上修浚西湖是他再任杭州时的政绩）</p><p>苏轼说，”古之成大事者，不唯有超世之才，亦必有坚韧不拔之志“，诚不我欺，乌台诗案给予了苏轼沉重打击，被迫下放黄州团练副使，楚水本是凄凉地，触景伤情，可是苏东坡是谁哇，在赤壁古战场，他惊叹，”此非曹孟德之诗乎？西望夏口，东望武昌，山川相缪，郁乎苍苍“；”酾酒临江，横槊赋诗，固一世之雄也，而今安在哉？“，他豁然；”寄蜉蝣于天地，渺沧海之一粟。哀吾生之须臾，羡长江之无穷。挟飞仙以遨游，抱明月而长终。知不可乎骤得，托遗响于悲风“，他哀伤。当然，他也自嘲，“但少闲人如吾两人耳。”</p><p>毛色日益衰，志气日益微呐，五十九岁的大才子还要被连贬至惠州，岭南何许地也，屈原笔下的莽荒之地，可是此心安处即是他苏东坡的乡，“日啖荔枝三百颗，不辞长作岭南人。”大快朵颐，岂不美哉？值得一提是，苏轼同样给惠州人民带了一个西湖，同为 5A 景区，世人只知杭州西湖，却不知惠州西湖。</p><p>心似浮萍，台海波摇呐，花甲老人被再贬至更偏僻的儋州，孤岛夜月，何其凄怆？可他是筚路蓝缕人。</p><blockquote><p>摘自百度百科：苏轼把儋州当成了自己的第二故乡，“我本儋耳氏，寄生西蜀州”。他在这里办学堂，介学风，以致许多人不远千里，追至儋州，从苏轼学。在宋代一百多年里，海南从没有人进士及第。但苏轼北归不久，这里的姜唐佐就举乡贡。为此苏轼题诗：“沧海何曾断地脉，珠崖从此破天荒。”人们一直把苏轼看作是儋州文化的开拓者、播种人，对他怀有深深的崇敬。</p></blockquote><p>宋徽宗大赦天下，苏轼北归，途经廉州、永州，于 公元1101 年病逝于常州，上述地图中北归旅程清晰可见。</p><p>好的，走远了，这其实是一篇野生的技术文。本文只是以苏轼为例，可以在页面上输入任何历史名人，欢迎大家访问工具页面，复制下述地址到浏览器打开或者点击<a href="https://tools.buyixiao.xyz/historical-figure-query">阅读原文</a>（如果访问不了那就是服务器过载了，稍等就好）</p><p><a href="https://tools.buyixiao.xyz/historical-figure-query">https://tools.buyixiao.xyz/historical-figure-query</a></p>]]></content>
      
      
      <categories>
          
          <category> 可视化 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 可视化 </tag>
            
            <tag> CBDB </tag>
            
            <tag> 历史人物 </tag>
            
            <tag> 关系网络 </tag>
            
            <tag> 生平足迹 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pandas 拆分具有相同结构的 csv</title>
      <link href="/blog/split-csv-with-same-columns.html"/>
      <url>/blog/split-csv-with-same-columns.html</url>
      
        <content type="html"><![CDATA[<p>在教程 <a href="https://buyixiao.github.io/blog/merge-csv-with-same-columns.html">pandas 合并具有相同结构的 csv</a> 中，我们分享了如何将一个文件夹下很多具有相同结构的 csv 文件合并为一个总的 csv 文件的代码，今天分享的是如何从这个总的 csv 文件还原成原来的一堆子文件，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># author:           inspurer(月小水长)</span></span><br><span class="line"><span class="comment"># create_time:      2022/8/16 14:07</span></span><br><span class="line"><span class="comment"># 运行环境           Python3.6+</span></span><br><span class="line"><span class="comment"># github            https://github.com/inspurer</span></span><br><span class="line"><span class="comment"># website           https://buyixiao.github.io/</span></span><br><span class="line"><span class="comment"># 微信公众号         月小水长</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">input_file = <span class="string">&#x27;all.csv&#x27;</span></span><br><span class="line"></span><br><span class="line">output_folder = <span class="string">&#x27;result&#x27;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(output_folder):</span><br><span class="line">    os.mkdir(output_folder)</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(input_file, float_precision=<span class="string">&#x27;round-trip&#x27;</span>)</span><br><span class="line">groups = df.groupby(df[<span class="string">&#x27;origin_file_name&#x27;</span>])</span><br><span class="line"><span class="keyword">for</span> group <span class="keyword">in</span> groups:</span><br><span class="line">    group[<span class="number">1</span>].drop(<span class="string">&#x27;origin_file_name&#x27;</span>, axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    group[<span class="number">1</span>].to_csv(os.path.join(output_folder, <span class="string">&#x27;&#123;&#125;.csv&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(group[<span class="number">0</span>]))), index=<span class="literal">False</span>,</span><br><span class="line">                    encoding=<span class="string">&#x27;utf-8-sig&#x27;</span>)</span><br></pre></td></tr></table></figure><p>如有错误欢迎指正，如有更优解决方案请赐教~</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pandas </tag>
            
            <tag> csv 拆分 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【动态规划】刷题记录</title>
      <link href="/blog/dynamic-programming-notes.html"/>
      <url>/blog/dynamic-programming-notes.html</url>
      
        <content type="html"><![CDATA[<h3 id="什么是动态规划"><a href="#什么是动态规划" class="headerlink" title="什么是动态规划"></a>什么是动态规划</h3><p>百度百科解释如下：</p><blockquote><p>动态规划算法是通过拆分问题，定义问题状态和状态之间的关系，使得问题能够以递推（或者说分治）的方式去解决。<br>动态规划算法的基本思想与分治法类似，也是将待求解的问题分解为若干个子问题（阶段），按顺序求解子阶段，前一子问题的解，为后一子问题的求解提供了有用的信息。在求解任一子问题时，列出各种可能的局部解，通过决策保留那些有可能达到最优的局部解，丢弃其他局部解。依次解决各子问题，最后一个子问题就是初始问题的解。<br>基本思想与策略编辑:<br>由于动态规划解决的问题多数有重叠子问题这个特点，为减少重复计算，对每一个子问题只解一次，将其不同阶段的不同状态保存在一个二维数组中。</p></blockquote><p>一篇动态规划 <a href="https://blog.csdn.net/ailaojie/article/details/83014821">博客</a> 阐述如下：</p><blockquote><p>首先是拆分问题，根据问题的可能性把问题划分成一步一步，这样就可以通过递推或者递归来实现.<br>关键就是这个步骤，动态规划有一类问题就是从后往前推到，有时候我们很容易知道:如果只有一种情况时，最佳的选择应该怎么做。然后根据这个最佳选择往前一步推导，得到前一步的最佳选择<br>然后就是定义问题状态和状态之间的关系，我的理解是前面拆分的步骤之间的关系，用一种量化的形式表现出来，类似于高中学的推导公式,因为这种式子很容易用程序写出来，也可以说对程序比较亲和(也就是最后所说的状态转移方程式)<br>我们再来看定义的下面的两段，我的理解是比如我们找到最优解,我们应该讲最优解保存下来，为了往前推导时能够使用前一步的最优解,在这个过程中难免有一些相比于最优解差的解，此时我们应该放弃，只保存最优解，这样我们每一次都把最优解保存了下来，大大降低了时间复杂度。</p></blockquote><p>动态规划与分治法的区别在于划分的子问题是有重叠的，解过程中对于重叠的部分只要求解一次，记录下结果，减少了重复计算过程。<br>另外，DP在求解一个问题最优解时，不是固定的计算合并某些子问题的解，而是根据各子问题的解的情况选择其中最优的。<br>动态规划求解具有以下性质：<br>最优子结构性质：最优解包含了其子问题的最优解，不是合并所有子问题的解，而是找最优的一条解线路，选择部分子最优解来达到最终的最优解。<br>子问题重叠性质：先计算子问题的解，再由子问题的解去构造问题的解（由于子问题存在重叠，把子问题解记录下来为下一步使用，这样就可以从备忘录中读取）。其中备忘录先记录初始状态。</p><h3 id="刷题记录"><a href="#刷题记录" class="headerlink" title="刷题记录"></a>刷题记录</h3><h4 id="最长递增子序列"><a href="#最长递增子序列" class="headerlink" title="最长递增子序列"></a>最长递增子序列</h4><h5 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h5><p>给你一个整数数组 nums ，找到其中最长严格递增子序列的长度。</p><p>子序列 是由数组派生而来的序列，删除（或不删除）数组中的元素而不改变其余元素的顺序。例如，[3,6,2,7] 是数组 [0,3,1,6,2,2,7] 的子序列。</p><p>示例 1：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入：nums = [10,9,2,5,3,7,101,18]</span><br><span class="line">输出：4</span><br><span class="line">解释：最长递增子序列是 [2,3,7,101]，因此长度为 4 。</span><br></pre></td></tr></table></figure><p>LeetCode 链接：<a href="https://leetcode.cn/problems/longest-increasing-subsequence">https://leetcode.cn/problems/longest-increasing-subsequence</a></p><h5 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h5><p>令状态 dp[i] 表示以 nums[i] 作为末尾的最长递增子序列的长度，考虑边界情况，dp[0] = 1，状态转移方程  <code>dp[i] = max(dp[j]) +1，其中 0&lt;=j&lt;i 且 num[j]&lt;num[i]</code> ，考虑在 j = 0…i-1 取一个最大子序列长度时，因为要求 num[i]  结尾，序列要求递增，则必须 num[i] &gt; num[j]。</p><p>最后，整个数组的最长上升子序列即 dp 数组的最大值。</p><h5 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">lengthOfLIS</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        vector&lt;<span class="keyword">int</span>&gt; dp;</span><br><span class="line">        dp.<span class="built_in">push_back</span>(<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">int</span> dp_max = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; nums.<span class="built_in">size</span>(); i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> temp = <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; i; j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(nums[i] &gt; nums[j])&#123;</span><br><span class="line">                    temp = <span class="built_in">max</span>(temp, dp[j]+<span class="number">1</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            dp.<span class="built_in">push_back</span>(temp);</span><br><span class="line">            dp_max = <span class="built_in">max</span>(dp_max, temp);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp_max;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h4 id="最大连续子序列和"><a href="#最大连续子序列和" class="headerlink" title="最大连续子序列和"></a>最大连续子序列和</h4><h5 id="描述-1"><a href="#描述-1" class="headerlink" title="描述"></a>描述</h5><p>给你一个整数数组 <code>nums</code> ，请你找出一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。</p><p>示例：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入：nums = [-2,1,-3,4,-1,2,1,-5,4]</span><br><span class="line">输出：6</span><br><span class="line">解释：连续子数组 [4,-1,2,1] 的和最大，为 6 。</span><br></pre></td></tr></table></figure><p>LeetCode 链接：<a href="https://leetcode.cn/problems/maximum-subarray/">https://leetcode.cn/problems/maximum-subarray/</a></p><h5 id="思路-1"><a href="#思路-1" class="headerlink" title="思路"></a>思路</h5><p>令状态 dp[i] 表示以 nums[i] 作为末尾的连续序列的最大和，考虑边界情况，dp[0] = nums[0]，状态转移方程  dp[i] = max(nums[i], dp[i-1] + nums[i])，因为是以 nums[i] 结尾，max 的作用其实就是取舍上一个状态，如果上一个状态小于等于 0，dp[i] = nums[i]。</p><p>求 dp[i] 的同时可以做比较，避免二次循环。</p><h5 id="题解-1"><a href="#题解-1" class="headerlink" title="题解"></a>题解</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">maxSubArray</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        vector&lt;<span class="keyword">int</span>&gt; dp;</span><br><span class="line">        dp.<span class="built_in">push_back</span>(nums[<span class="number">0</span>]);</span><br><span class="line">        <span class="keyword">int</span> dp_max = nums[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; nums.<span class="built_in">size</span>(); i++)&#123;</span><br><span class="line">            dp.<span class="built_in">push_back</span>(<span class="built_in">max</span>(nums[i], nums[i]+ dp[i<span class="number">-1</span>]));</span><br><span class="line">            <span class="keyword">if</span>(dp_max &lt; dp[i])&#123;</span><br><span class="line">                dp_max = dp[i];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp_max;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h4 id="买卖股票的最佳时机"><a href="#买卖股票的最佳时机" class="headerlink" title="买卖股票的最佳时机"></a>买卖股票的最佳时机</h4><h5 id="描述-2"><a href="#描述-2" class="headerlink" title="描述"></a>描述</h5><p>给定一个数组 prices ，它的第 i 个元素 prices[i] 表示一支给定股票第 i 天的价格。</p><p>你只能选择 某一天 买入这只股票，并选择在 未来的某一个不同的日子 卖出该股票。设计一个算法来计算你所能获取的最大利润。</p><p>返回你可以从这笔交易中获取的最大利润。如果你不能获取任何利润，返回 0 。</p><p>LeetCode 链接：<a href="https://leetcode.cn/problems/best-time-to-buy-and-sell-stock">https://leetcode.cn/problems/best-time-to-buy-and-sell-stock</a></p><h5 id="思路-2"><a href="#思路-2" class="headerlink" title="思路"></a>思路</h5><p>如果我们真的在买卖股票，我们肯定会想：如果我是在历史最低点买的股票就好了！太好了，在题目中，我们只要用一个变量记录一个历史最低价格 minprice，我们就可以假设自己的股票是在那天买的。那么我们在第 i 天卖出股票能得到的利润就是 prices[i] - minprice。</p><p>因此，我们只需要遍历价格数组一遍，记录历史最低点，然后在每一天考虑这么一个问题：如果我是在历史最低点买进的，那么我今天卖出能赚多少钱？当考虑完所有天数之时，我们就得到了最好的答案。</p><p>LeetCode-Solution 链接：<a href="https://leetcode.cn/problems/best-time-to-buy-and-sell-stock/solution/121-mai-mai-gu-piao-de-zui-jia-shi-ji-by-leetcode-/">https://leetcode.cn/problems/best-time-to-buy-and-sell-stock/solution/121-mai-mai-gu-piao-de-zui-jia-shi-ji-by-leetcode-/</a></p><h5 id="题解-2"><a href="#题解-2" class="headerlink" title="题解"></a>题解</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">maxProfit</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt;&amp; prices)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(prices.<span class="built_in">size</span>() &lt;= <span class="number">1</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> min_v = prices[<span class="number">0</span>], max_b = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; prices.<span class="built_in">size</span>(); i++)&#123;</span><br><span class="line">            max_b = <span class="built_in">max</span>(max_b, prices[i] - min_v);</span><br><span class="line">            min_v = <span class="built_in">min</span>(min_v, prices[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> max_b;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h4 id="卖股票的最佳时机-II"><a href="#卖股票的最佳时机-II" class="headerlink" title="卖股票的最佳时机 II"></a>卖股票的最佳时机 II</h4><p>直接参考：<a href="https://leetcode.cn/problems/best-time-to-buy-and-sell-stock-ii/solution/mai-mai-gu-piao-de-zui-jia-shi-ji-ii-by-leetcode-s/">https://leetcode.cn/problems/best-time-to-buy-and-sell-stock-ii/solution/mai-mai-gu-piao-de-zui-jia-shi-ji-ii-by-leetcode-s/</a></p><h4 id="UVA-12034-Race"><a href="#UVA-12034-Race" class="headerlink" title="UVA 12034 Race"></a>UVA 12034 Race</h4><h5 id="描述-3"><a href="#描述-3" class="headerlink" title="描述"></a>描述</h5><p>n 匹马，共有多少种排名情况（可以并列）</p><p>UVA 链接：<a href="https://vjudge.net/problem/UVA-12034">https://vjudge.net/problem/UVA-12034</a></p><h5 id="思路-3"><a href="#思路-3" class="headerlink" title="思路"></a>思路</h5><p>参考链接：<a href="https://blog.csdn.net/qq_39479426/article/details/81229724">https://blog.csdn.net/qq_39479426/article/details/81229724</a></p><p><code>dp[i][j]</code> 表示 i 匹马占有 j 个名次的组合情况</p><p>然后考虑 i 匹马和 i-1 匹马的转移关系，多了一匹马要放在哪个位置，有下面两种情况</p><p>第 i 匹马和前 i-1 匹马中至少一匹马的成绩相同（j 个名次就有 j 种情况）<br>这匹马独占了一个成绩（可以放入 j 个位置，注意这里不是 j+1）<br>所以可以得到递推式：<code>dp[i][j] = dp[i-1][j] * j + dp[i-1][j-1] * j</code></p><h5 id="题解-3"><a href="#题解-3" class="headerlink" title="题解"></a>题解</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">long</span> <span class="keyword">long</span> dp[<span class="number">1050</span>][<span class="number">1050</span>];   <span class="comment">//dp[i][j]表示i只马占有j个名次(i&gt;=j)</span></span><br><span class="line"><span class="keyword">long</span> <span class="keyword">long</span> fac[<span class="number">1000</span>];</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">solve</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    fac[<span class="number">0</span>] = <span class="number">1</span>; fac[<span class="number">1</span>] = <span class="number">1</span>;</span><br><span class="line">    # 求阶乘，i == j = A 时，组合情况就是 A！</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">2</span>; i &lt;= <span class="number">1000</span>; i++)</span><br><span class="line">        fac[i] = (i * fac[i - <span class="number">1</span>]) % <span class="number">10056</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="built_in">memset</span>(dp, <span class="number">0</span>, <span class="built_in"><span class="keyword">sizeof</span></span>(dp));</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= <span class="number">1000</span>; i++)</span><br><span class="line">        dp[i][<span class="number">1</span>] = <span class="number">1</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">2</span>; i &lt;= <span class="number">1000</span>; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">2</span>; j &lt;= i; j++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (i - <span class="number">1</span> &gt;= j)</span><br><span class="line">            <span class="comment">//前i-1只马用完了j个名次,最后一只马有j种选择; 前面i-1只马用了j-1个名次,(j-1)最后一只马独占一个名次,同样有j种选择</span></span><br><span class="line">                dp[i][j] = (dp[i - <span class="number">1</span>][j] * j + dp[i - <span class="number">1</span>][j - <span class="number">1</span>] * j) % <span class="number">10056</span>;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (i == j)</span><br><span class="line">                dp[i][j] = fac[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">solve</span>();</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">int</span> T;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;T);</span><br><span class="line">    <span class="keyword">int</span> k = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (T--)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">int</span> n;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;n);</span><br><span class="line">        <span class="keyword">long</span> <span class="keyword">long</span> sum = <span class="number">0L</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= n; i++)</span><br><span class="line">            sum = (sum + dp[n][i]) % <span class="number">10056</span>;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Case %d: %lld\n&quot;</span>, k++, sum);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="0-1-背包问题"><a href="#0-1-背包问题" class="headerlink" title="0/1 背包问题"></a>0/1 背包问题</h4><h5 id="描述-4"><a href="#描述-4" class="headerlink" title="描述"></a>描述</h5><p>给定 n 种物品和一个容量为 C 的背包，物品 i 的重量是 wi，其价值为 vi。问：应该如何选择装入背包的物品，使得装入背包中的物品的总价值最大？</p><h5 id="题解-4"><a href="#题解-4" class="headerlink" title="题解"></a>题解</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span> </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="comment">//记忆性数组动态规划解法 </span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">packageSolution</span><span class="params">(<span class="keyword">int</span> n, <span class="keyword">int</span> pc, <span class="keyword">int</span> gvol[], <span class="keyword">int</span> gval[])</span></span>&#123;</span><br><span class="line"><span class="comment">//用 dp[i][j] 表示，取前 i 种物品，总体积不超过 j 的所能取得的最大价值总量 </span></span><br><span class="line"><span class="keyword">int</span> dp[n+<span class="number">1</span>][pc+<span class="number">1</span>];</span><br><span class="line"><span class="comment">// 初始化边界条件，也就是第一行，取前 1 种物品，总体积不超过 j 的最大价值总量 </span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt;= pc; j++)&#123;</span><br><span class="line"><span class="keyword">if</span>(gvol[<span class="number">1</span>]&lt;=j) &#123;</span><br><span class="line">dp[<span class="number">1</span>][j] = gval[<span class="number">1</span>];</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">dp[<span class="number">1</span>][j] = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">2</span>; i &lt;= n; i++)&#123;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span> ;j &lt;= pc; j++)&#123;</span><br><span class="line"><span class="comment">// dp[i-1][j] 表示不取第 i 种物品的最大价值</span></span><br><span class="line"><span class="comment">// dp[i-1][j-gvol[i]] + gval[i] 表示取第 i 种物品的最大价值，认真想一下 dp[i][j] i、j 分别表示啥意思，就知道为啥需要 dp[i][j-gvol[i]] 了，体会状态转化的思想</span></span><br><span class="line"><span class="comment">// 只有  (j - gvol[i])&gt;=0 才能取第 i 种 </span></span><br><span class="line"><span class="keyword">if</span>((j - gvol[i])&gt;=<span class="number">0</span>)&#123;</span><br><span class="line">dp[i][j] = <span class="built_in">max</span>(dp[i<span class="number">-1</span>][j], dp[i<span class="number">-1</span>][j-gvol[i]] + gval[i]);</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">dp[i][j] = dp[i<span class="number">-1</span>][j];</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> dp[n][pc];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="comment">//物品个数，背包容量 </span></span><br><span class="line"><span class="keyword">int</span> n, package_capacity;</span><br><span class="line"><span class="comment">//输入一行，两个数字以空格间隔 </span></span><br><span class="line">cin&gt;&gt;n&gt;&gt;package_capacity;</span><br><span class="line"></span><br><span class="line"><span class="comment">//物品体积数组、物品价值数组 </span></span><br><span class="line"><span class="keyword">int</span> goods_volumn[n+<span class="number">1</span>], goods_value[n+<span class="number">1</span>];</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= n; i++)&#123;</span><br><span class="line"><span class="comment">//输入 n 行，每行两个数字以空格间隔 </span></span><br><span class="line">cin&gt;&gt;goods_volumn[i]&gt;&gt;goods_value[i];</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 以 3 个物体，背包容量为 5 为例</span></span><br><span class="line"><span class="comment">//三个物体的体积、价值依次是</span></span><br><span class="line"><span class="comment">//1 3 </span></span><br><span class="line"><span class="comment">//2 1</span></span><br><span class="line"><span class="comment">//3 2 </span></span><br><span class="line"><span class="comment">// 那么会选择第一个和第三个物品，最大价值和为 3+2=5 </span></span><br><span class="line">cout&lt;&lt;<span class="string">&quot;the max total value: &quot;</span>&lt;&lt;<span class="built_in">packageSolution</span>(n, package_capacity, goods_volumn, goods_value);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="参考材料"><a href="#参考材料" class="headerlink" title="参考材料"></a>参考材料</h3><p>1、北京大学郭炜 MOOC 慕课：<a href="https://www.icourse163.org/learn/PKU-1001894005">https://www.icourse163.org/learn/PKU-1001894005</a></p>]]></content>
      
      
      <categories>
          
          <category> 算法笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 动态规划 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>塞缪尔·厄尔曼：青春</title>
      <link href="/blog/youth-by-samuel-ullman.html"/>
      <url>/blog/youth-by-samuel-ullman.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>《青春》作者是德裔美国作家塞缪尔·厄尔曼。</p></blockquote><h2 id="中文译文"><a href="#中文译文" class="headerlink" title="中文译文"></a>中文译文</h2><p>青春不是年华，而是心境；青春不是桃面、丹唇、柔膝，而是深沉的意志、恢宏的想象、炽热的感情；青春是生命的深泉在涌流。</p><p>青春气贯长虹，勇锐盖过怯弱，进取压倒苟安。如此锐气，二十后生有之，六旬男子则更多见。年岁有加，并非垂老；理想丢弃，方堕暮年。岁月悠悠，衰微只及肌肤；热忱抛却，颓唐必致灵魂。忧烦，惶恐，丧失自信，定使心灵扭曲，意气如灰。</p><p>无论年届花甲，抑或二八芳龄，心中皆有生命之欢乐，奇迹之诱惑，孩童般天真久盛不衰。</p><p>人人心中皆有一台天线，只要你从天上人间接受美好、希望、欢乐、勇气和力量的信号，你无不青春永驻、风华长存。</p><p>一旦天线降下，锐气便被冰雪覆盖，玩世不恭、自暴自弃油然而生，即便年方二十，实已垂垂老矣；然则只要竖起天线，捕捉乐观信号，你就有望在八十高龄告别尘寰时仍觉年轻。</p><h2 id="英文原文"><a href="#英文原文" class="headerlink" title="英文原文"></a>英文原文</h2><p>《YOUTH 》 by Samuel Ullman</p><p>Youth is not a time of life; it is a state of mind; it is not a matter of rosy cheeks, red lips and supple knees; it is a matter of the will, a quality of the imagination, a vigor of the emotions; it is the freshness of the deep springs of life.</p><p>Youth means a temperamental predominance of courage over timidity of the appetite, for adventure over the love of ease. This often exists in a man of sixty more than a boy of twenty. Nobody grows old merely by a number of years. We grow old by deserting our ideals.</p><p>Years may wrinkle the skin, but to give up enthusiasm wrinkles the soul. Worry, fear, self-distrust bows the heart and turns the spirit back to dust.</p><p>Whether sixty or sixteen, there is in every human being’s heart the lure of wonder, the unfailing child-like appetite of what’s next, and the joy of the game of living. In the center of your heart and my heart there is a wireless station; so long as it receives messages of beauty, hope, cheer, courage and power from men and from the infinite, so long are you young.</p><p>When the aerials are down, and your spirit is covered with snows of cynicism and the ice of pessimism, then you are grown old, even at twenty, but as long as your aerials are up, to catch the waves of optimism, there is hope you may die young at eighty.</p>]]></content>
      
      
      <categories>
          
          <category> 励志 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 青春 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>crontab 定时执行 Python 脚本踩坑记录</title>
      <link href="/blog/crontab-python.html"/>
      <url>/blog/crontab-python.html</url>
      
        <content type="html"><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>换过几个云服务器，每次都要在 crontab 这折腾一会儿，这次索性把问题记录下来，力求详尽。</p><p>笔者的云服务器：腾讯云 2C4G；</p><p>Linux 系统： Ubuntu 20.04 LTS 64bit。</p><blockquote><p>crontab 是 Linux 下周期性执行的指令，常常在后台运行，每一分钟检查是否有预定的作业需要执行。这类作业一般称为 cron jobs。(摘自百度百科)</p></blockquote><h3 id="必备知识"><a href="#必备知识" class="headerlink" title="必备知识"></a>必备知识</h3><p>1、cron 的配置文件可在三个地方存放</p><ul><li><code>/var/spool/cron/crontabs/root</code></li><li><code>/etc/crontab</code></li><li><code>/etc/cron.d/</code></li></ul><p>​      一般情况下，通过 crontab -e 命令编辑的是第一个路径下的配置文件，在这里的命令不需要指定用户为 root；后两个则需要，比如命令 <code> 0 3 * * 1 root python test.py</code>，其中的 root 不可少。</p><p>需要注意的是，如果使用 crontab -e 编辑，修改后使用 Ctrl+X，提示：<code>save modified buffer ...?</code>    ，选择 ：yes，又提示：<code>file name to write</code> ，选择：Ctrl+T，在最后一个界面使用左右箭头切换至 crontab。</p><p>2、虽然说编辑完 crontab 文件后不需要重启 cron 服务，但是包括重启在内的一些命令最好还是了解下。</p><ul><li>重启，各种资料都说是 service crond restart，在笔者的环境上实测是 service cron restart；在 centos 上是 systemctl restart crond，笔者暂未考证。</li><li>状态，笔者亲测为 service cron start；其他环境同上。</li></ul><h3 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h3><p>使用命令定时执行 python 脚本，每个小时的第 15 分钟运行一次，无任何反应。命令如下：</p><p><code>15 * * * * /mypath/venv/bin/python3 /mypath/monitor.py &gt;&gt; /mypath/execute.log 2&gt;&amp;1</code></p><p>python 脚本输出的 execute.log 亦无输出。</p><h3 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h3><p>第一步想着查看 crontab 的日志，才知道默认是不打开的需要手动配置。命令如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/rsyslog.d/50-default.conf</span><br><span class="line">cron.*  /var/log/cron.log #将cron前面的注释符去掉</span><br><span class="line"><span class="meta">#</span><span class="bash">重启rsyslog</span></span><br><span class="line">sudo service rsyslog restart</span><br><span class="line">sudo service cron restart</span><br></pre></td></tr></table></figure><p>然后 <code>vi /var/log/cron.log</code> 查看日志，能够发现脚本确实运行了，除此之外没有任何有用信息，看其他博主（参考文末链接2）说是需要安装 postfix，正安装着不知道怎么配置邮件服务器的域名，又看到如果 python 脚本输出配置了重定向日志，不用配这个也行。遂作罢。</p><p>排除了 crontab 的问题，那只有是 python 脚本的问题了，偶然间发现（参考文末链接 3）：python 脚本中涉及到读写文件的动作，一般定时任务都不会执行.；脚本在执行时，由于是通过 crontab 去执行的，它的执行目录会变成当前用户的根目录，如果是root，就会在/root/下执行。</p><p>但是我们读写的文件路径在 root 下吗，大概率不是，一种解决办法是将 python 脚本中的文件路径全部换成服务器绝对路径，但是这样可移植性差；更好的办法是使用 shell 脚本，shell 脚本第一行使用命令 cd 到我们的目的路径，然后第二行修改我们原来的命令（py 脚本的绝对路径也可以简化成相对路径），如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">！/usr/bin/bash</span></span><br><span class="line">cd /mypath</span><br><span class="line">/mypath/venv/bin/python3 /monitor.py </span><br></pre></td></tr></table></figure><p>使用 <code>chmod a+x test.sh</code> 赋予执行权限，然后在 crontab 配置定时运行这个 shell 脚本，</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">15 * * * * /bin/sh /mypath/test.sh &gt;&gt; /mypath/execute.log 2&gt;&amp;1</span><br></pre></td></tr></table></figure><p>最后可能还有一个坑，查看 execute.log，发现无法 cd 到 mypath，这是因为这个 test.sh 是通过 rz 上传的，不是在服务器上通过 touch 创建的，无法识别，解决办法就在原因中，touch 创建再复制命令就行。</p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>1、<a href="https://blog.tankywoo.com/2014/10/05/the-holes-of-crontab.html">一个 crontab 的坑</a></p><p>2、<a href="https://my.oschina.net/leejun2005/blog/1788342">迷之 crontab 异常：不运行、不报错、无日志</a></p><p>3、<a href="https://blog.csdn.net/xys2333/article/details/112469461">crontab运行python脚本不生效问题</a></p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> crontab </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pandas groupby filter 函数妙用</title>
      <link href="/blog/pandas-groupby-filter.html"/>
      <url>/blog/pandas-groupby-filter.html</url>
      
        <content type="html"><![CDATA[<p>假设有一个狂人日记的 dataframe 如下：</p><table><thead><tr><th align="center">user_name</th><th align="center">publish_time</th><th align="center">content</th></tr></thead><tbody><tr><td align="center">小明</td><td align="center">2022-12-30 15:10:00</td><td align="center">今天是 2022 年最后一天，我在广东</td></tr><tr><td align="center">小刚</td><td align="center">2022-01-01 12:23:33</td><td align="center">今天是 2022 年第一天，我在加勒比</td></tr><tr><td align="center">小王</td><td align="center">2022-01-01 12:33:00</td><td align="center">今天是 2022 年第一天，我在小刚身边</td></tr><tr><td align="center">小刚</td><td align="center">2023-01-01 02:15:45</td><td align="center">今天是 2023 年第一天，我在百慕大</td></tr><tr><td align="center">小明</td><td align="center">2023-01-01 00:05:20</td><td align="center">今天是 2023 年第一天，我还在广东</td></tr></tbody></table><p>现在我们要统计狂人日记里面，同一作者第一次和最后一次发布时间差大于 30 天的行。</p><p>乍一看，首先必须统计同一作者至少发布两次的行，也就是上一篇<a href="https://buyixiao.github.io/blog/pandas-value-counts.html">value counts</a> 的内容。</p><p>然后再使用 groupby 分组 + filter 过滤实现，这个 filter 相当于 mysql 语句中 groupby 后的 having 语句，是在分组上做筛选的。</p><p>所以在上一篇的基础上，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># author:           inspurer(月小水长)</span></span><br><span class="line"><span class="comment"># create_time:      2023/1/7 8:58</span></span><br><span class="line"><span class="comment"># 运行环境           Python3.6+</span></span><br><span class="line"><span class="comment"># github            https://github.com/inspurer</span></span><br><span class="line"><span class="comment"># website           https://buyixiao.github.io/</span></span><br><span class="line"><span class="comment"># 微信公众号         月小水长</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">input_file = <span class="string">&#x27;./狂人日记 2022.csv&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">remove_show_count_below_n</span>(<span class="params">input_file, col, n=<span class="number">2</span></span>):</span></span><br><span class="line">    df = pd.read_csv(input_file)</span><br><span class="line">    <span class="comment"># 第一步，筛选 user_name 出现大于等于 2 次的行</span></span><br><span class="line">    count_df = pd.DataFrame(df[col].value_counts())</span><br><span class="line">    count_df.columns = [<span class="string">&#x27;count&#x27;</span>]</span><br><span class="line">    not_below_n_index = count_df[count_df[<span class="string">&#x27;count&#x27;</span>] &gt;= n].index</span><br><span class="line">    df = df[df[col].isin(not_below_n_index)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 比上一篇新加的內容</span></span><br><span class="line">    df[<span class="string">&#x27;publish_date&#x27;</span>] = pd.to_datetime(df[<span class="string">&#x27;publish_time&#x27;</span>]).dt.date</span><br><span class="line">    df = df.groupby(col).<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: (x[<span class="string">&#x27;publish_date&#x27;</span>].<span class="built_in">max</span>() - x[<span class="string">&#x27;publish_date&#x27;</span>].<span class="built_in">min</span>()).days &gt; <span class="number">30</span>)</span><br><span class="line"></span><br><span class="line">    df.to_csv(<span class="string">&#x27;result.csv&#x27;</span>, index=<span class="literal">False</span>, encoding=<span class="string">&#x27;utf-8-sig&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">remove_show_count_below_n(input_file, col=<span class="string">&#x27;user_name&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>仔细想想，第一步真的有必要吗？如果只出现一次，在第二步 publish_date 相减的时候差值为 0，直接就过滤掉了，所以第一步在这个任务是多此一举。简化代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">time_interval_filter</span>(<span class="params">input_file, col, days</span>):</span></span><br><span class="line">    df = pd.read_csv(input_file)</span><br><span class="line">    df[<span class="string">&#x27;publish_date&#x27;</span>] = pd.to_datetime(df[<span class="string">&#x27;publish_time&#x27;</span>]).dt.date</span><br><span class="line">    df = df.groupby(col).<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: (x[<span class="string">&#x27;publish_date&#x27;</span>].<span class="built_in">max</span>() - x[<span class="string">&#x27;publish_date&#x27;</span>].<span class="built_in">min</span>()).days &gt; days)</span><br><span class="line">    df.to_csv(<span class="string">&#x27;result.csv&#x27;</span>, index=<span class="literal">False</span>, encoding=<span class="string">&#x27;utf-8-sig&#x27;</span>)</span><br><span class="line"></span><br><span class="line">time_interval_filter(input_file, col=<span class="string">&#x27;user_name&#x27;</span>, days=<span class="number">30</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> filter </tag>
            
            <tag> groupby </tag>
            
            <tag> pandas </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pandas 筛选某列值出现至少 N 次的行</title>
      <link href="/blog/pandas-value-counts.html"/>
      <url>/blog/pandas-value-counts.html</url>
      
        <content type="html"><![CDATA[<p>假设有一个 dataframe 如下：</p><table><thead><tr><th align="center">user_name</th><th align="center">publish_time</th><th align="center">content</th></tr></thead><tbody><tr><td align="center">小明</td><td align="center">2022-12-30 15:10:00</td><td align="center">今天是 2022 年最后一天，我在广东</td></tr><tr><td align="center">小刚</td><td align="center">2022-01-01 12:23:33</td><td align="center">今天是 2022 年第一天，我在加勒比</td></tr><tr><td align="center">小王</td><td align="center">2022-01-01 12:33:00</td><td align="center">今天是 2022 年第一天，我在小刚身边</td></tr><tr><td align="center">小刚</td><td align="center">2023-01-01 02:15:45</td><td align="center">今天是 2023 年第一天，我在百慕大</td></tr><tr><td align="center">小明</td><td align="center">2023-01-01 00:05:20</td><td align="center">今天是 2023 年第一天，我还在广东</td></tr></tbody></table><p>现在我们要统计 user_name 中出现两次及以上的行。肉眼可以看出就是小明、小刚各自两行共四行。</p><p>最开始我的思路是使用 drop_duplicated 按照 user_name 为 key 去重，将去重后的 dataframe 和原来的 dataframe 按照所有列为 key 合并后再去重，这样一来就只剩下 user_name 出现两次及以上的行了，但是这种思路扩展性不好，假如是出现  3 次及以上呢？计算量就更大了。</p><p>改进后的思路是：主要使用 pandas 的 value_counts 函数统计次数，isin 函数实现筛选，其代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># author:           inspurer(月小水长)</span></span><br><span class="line"><span class="comment"># create_time:      2023/1/7 8:58</span></span><br><span class="line"><span class="comment"># 运行环境           Python3.6+</span></span><br><span class="line"><span class="comment"># github            https://github.com/inspurer</span></span><br><span class="line"><span class="comment"># website           https://buyixiao.github.io/</span></span><br><span class="line"><span class="comment"># 微信公众号         月小水长</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">input_file = <span class="string">&#x27;./狂人日记 2022.csv&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">remove_show_count_below_n</span>(<span class="params">input_file, col, n=<span class="number">2</span></span>):</span></span><br><span class="line">    df = pd.read_csv(input_file)</span><br><span class="line"></span><br><span class="line">    count_df = pd.DataFrame(df[col].value_counts())</span><br><span class="line">    count_df.columns = [<span class="string">&#x27;count&#x27;</span>]</span><br><span class="line">    not_below_n_index = count_df[count_df[<span class="string">&#x27;count&#x27;</span>] &gt;= n].index</span><br><span class="line">    df = df[df[col].isin(not_below_n_index)]</span><br><span class="line"></span><br><span class="line">    df.to_csv(<span class="string">&#x27;result.csv&#x27;</span>, index=<span class="literal">False</span>, encoding=<span class="string">&#x27;utf-8-sig&#x27;</span>)</span><br><span class="line"></span><br><span class="line">remove_show_count_below_n(input_file, col=<span class="string">&#x27;user_name&#x27;</span>)</span><br></pre></td></tr></table></figure><p>如有更优雅的方式（肯定有），请批评指正～</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pandas </tag>
            
            <tag> frequency </tag>
            
            <tag> value_counts </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>android camera2 实战经验汇总</title>
      <link href="/blog/android-camera2.html"/>
      <url>/blog/android-camera2.html</url>
      
        <content type="html"><![CDATA[<h3 id="android-camera2-简单介绍"><a href="#android-camera2-简单介绍" class="headerlink" title="android camera2 简单介绍"></a>android camera2 简单介绍</h3><p>从 Android 5.0 开始，Google 引入了一套全新的相机框架 Camera2 api，它相比较 Camera1 有以下优势：</p><p>1、可以获取更多的帧(预览/拍照)信息以及手动控制每一帧的参数<br>2、对Camera的控制更加完全(比如支持调整focus distance, 剪裁预览/拍照图片)<br>3、支持更多图片格式(yuv/raw)以及高速连拍<br>4、…</p><p>现在是 2022 年了，可以说 99% 以上的安卓手机都在 5.0 系统，因此完全不用担心兼容问题。本文只是记录在自定义 camera2 实现连拍过程的坑，具体有关 camera2 的介绍可以参考 Google 的文档。</p><blockquote><p><a href="https://developer.android.com/training/camera2">https://developer.android.com/training/camera2</a></p></blockquote><h3 id="camera2-实现连拍并保存"><a href="#camera2-实现连拍并保存" class="headerlink" title="camera2 实现连拍并保存"></a>camera2 实现连拍并保存</h3><p>理论上 camera2 连拍可以达到 30fps，笔者需要的速度是 20s 拍 100 张并保存，实测无压力。主要是使用 CountDownTimer 定时 build CaptureRequest，然后在 CaptureResult 中使用 RxJava 线程调度，即在 IO 线程保存照片，在 UI 线程更新。</p><h3 id="遇到的一些问题"><a href="#遇到的一些问题" class="headerlink" title="遇到的一些问题"></a>遇到的一些问题</h3><h4 id="预览正常，保存的照片旋转了-90-度"><a href="#预览正常，保存的照片旋转了-90-度" class="headerlink" title="预览正常，保存的照片旋转了 90 度"></a>预览正常，保存的照片旋转了 90 度</h4><p>解决办法有两个，第一个就在在 CaptureRequest 中构建 bitmap，然后强行使这个 bitmap 旋转到原来的位置。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Bitmap <span class="title">adjustPhotoRotation</span><span class="params">(Bitmap bm, <span class="keyword">final</span> <span class="keyword">int</span> orientationDegree)</span> </span>&#123;</span><br><span class="line">Matrix m = <span class="keyword">new</span> Matrix();</span><br><span class="line">       m.setRotate(orientationDegree, (<span class="keyword">float</span>) bm.getWidth() / <span class="number">2</span>, (<span class="keyword">float</span>) bm.getHeight() / <span class="number">2</span>);</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">           <span class="keyword">return</span> Bitmap.createBitmap(bm, <span class="number">0</span>, <span class="number">0</span>, bm.getWidth(), bm.getHeight(), m, <span class="keyword">true</span>);</span><br><span class="line">       &#125; <span class="keyword">catch</span> (OutOfMemoryError ex) &#123;</span><br><span class="line">           ex.fillInStackTrace();</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> bm;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Bitmap bitmapImage = BitmapFactory.decodeByteArray(data, <span class="number">0</span>, data.length, <span class="keyword">null</span>);</span><br><span class="line"><span class="comment">// 这个 90 度太唐突了，但是能解决问题</span></span><br><span class="line">Bitmap newBitmap = adjustPhotoRotation(bitmapImage, <span class="number">90</span>);</span><br></pre></td></tr></table></figure><p>第二个是 requestBuilder 设置 JPEG_ORIENTATION，这种才是解决根本</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getDisplayRotation</span><span class="params">(Activity activity)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (activity == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> rotation = activity.getWindowManager().getDefaultDisplay()</span><br><span class="line">                .getRotation();</span><br><span class="line">        <span class="keyword">switch</span> (rotation) &#123;</span><br><span class="line">            <span class="keyword">case</span> Surface.ROTATION_0:</span><br><span class="line">                <span class="keyword">return</span> <span class="number">90</span>;</span><br><span class="line">            <span class="keyword">case</span> Surface.ROTATION_90:</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">case</span> Surface.ROTATION_180:</span><br><span class="line">                <span class="keyword">return</span> <span class="number">270</span>;</span><br><span class="line">            <span class="keyword">case</span> Surface.ROTATION_270:</span><br><span class="line">                <span class="keyword">return</span> <span class="number">180</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 构建 requestBuilder 的时候设置</span></span><br><span class="line">mCaptureReqBuilder.set(CaptureRequest.JPEG_ORIENTATION, getDisplayRotation(activity));</span><br></pre></td></tr></table></figure><h4 id="CaptureRequest-Builder-NPE"><a href="#CaptureRequest-Builder-NPE" class="headerlink" title="CaptureRequest$Builder NPE"></a>CaptureRequest$Builder NPE</h4><p>完整报错信息是：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Caused by: java.lang.NullPointerException: Attempt to invoke virtual method <span class="string">&#x27;android.hardware.camera2.CaptureRequest$Builder android.hardware.camera2.CameraDevice.createCaptureRequest(int)&#x27;</span> on a <span class="keyword">null</span> object reference</span><br></pre></td></tr></table></figure><p>这是因为，相机驱动相关初始化后要延迟 1s 左右才能 buildCaptureRequest，post 一个延时 1s 的 runnable 即可</p><h4 id="部分机型上界面拉伸，保存正常"><a href="#部分机型上界面拉伸，保存正常" class="headerlink" title="部分机型上界面拉伸，保存正常"></a>部分机型上界面拉伸，保存正常</h4><p>试了很多，暂无解，待填</p>]]></content>
      
      
      <categories>
          
          <category> Android </category>
          
      </categories>
      
      
        <tags>
            
            <tag> camera2 </tag>
            
            <tag> android </tag>
            
            <tag> 连拍 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pandas 分组频率统计</title>
      <link href="/blog/pandas-groupby-frequency-statistics.html"/>
      <url>/blog/pandas-groupby-frequency-statistics.html</url>
      
        <content type="html"><![CDATA[<p>假设有一个 dataframe 如下：</p><table><thead><tr><th align="center">country_name</th><th align="center">date</th><th align="center">标题</th></tr></thead><tbody><tr><td align="center">中国</td><td align="center">20030101</td><td align="center">今天是 2003 年第一天，我在中国</td></tr><tr><td align="center">安提瓜和巴布达</td><td align="center">20030101</td><td align="center">今天是 2003 年第一天，我在安提瓜和巴布达</td></tr><tr><td align="center">中国</td><td align="center">20030102</td><td align="center">今天是 2003 年第二天，我在中国</td></tr><tr><td align="center">蒙古</td><td align="center">20030102</td><td align="center">今天是 2003 年第二天，我在蒙古</td></tr></tbody></table><p>现在要统计每天每个国家在当天出现的频率，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># author:           inspurer(月小水长)</span></span><br><span class="line"><span class="comment"># create_time:      2022/5/28 20:10</span></span><br><span class="line"><span class="comment"># 运行环境           Python3.6+</span></span><br><span class="line"><span class="comment"># github            https://github.com/inspurer</span></span><br><span class="line"><span class="comment"># website           https://buyixiao.github.io/</span></span><br><span class="line"><span class="comment"># 微信公众号         月小水长</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">input_file = <span class="string">&#x27;all_country.csv&#x27;</span></span><br><span class="line"></span><br><span class="line">df = pd.read_csv(input_file)</span><br><span class="line"></span><br><span class="line">res_df = df.groupby([<span class="string">&#x27;date&#x27;</span>, <span class="string">&#x27;country_name&#x27;</span>]).count().reset_index()</span><br><span class="line"></span><br><span class="line">res_df = res_df[res_df.columns[:<span class="number">3</span>]]</span><br><span class="line"></span><br><span class="line">res_df.rename(columns=&#123;<span class="string">&#x27;标题&#x27;</span>: <span class="string">&#x27;daily_cnt&#x27;</span>&#125;, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(res_df, res_df.columns)</span><br><span class="line"></span><br><span class="line">res_df[<span class="string">&#x27;daily_frq&#x27;</span>] = [<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(res_df.shape[<span class="number">0</span>])]</span><br><span class="line"><span class="keyword">for</span> index, row <span class="keyword">in</span> res_df.iterrows():</span><br><span class="line">    res_df.loc[index, <span class="string">&#x27;daily_frq&#x27;</span>] = <span class="built_in">round</span>(row[<span class="string">&#x27;daily_cnt&#x27;</span>] / df[df[<span class="string">&#x27;date&#x27;</span>] == row[<span class="string">&#x27;date&#x27;</span>]].shape[<span class="number">0</span>], <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">res_df.to_csv(<span class="string">&quot;res_&quot;</span> + input_file, index=<span class="literal">False</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>如有更优雅的方式（肯定有），请批评指正~</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> groupby </tag>
            
            <tag> pandas </tag>
            
            <tag> frequency </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【持续更新|2022最新】68w 高质量新闻数据集</title>
      <link href="/blog/qualitative-news-dataset.html"/>
      <url>/blog/qualitative-news-dataset.html</url>
      
        <content type="html"><![CDATA[<p>租用服务器，累计半年有余对新浪，腾讯，澎湃三个国内主流新闻站点进行抓取，共计保存 68 w 数据，约 1.8G，导出到本地 csv 花了 5 个小时。</p><p>csv 一共 11 列，分别是：新闻抓取时间，标题，来源，头图，发布时间，链接，分类，关键词（逗号分隔），标签，描述，内容。</p><p>数据收集和整理获取花费大量时间和精力，故收取一定费用。下载地址：</p><p><a href="https://afdian.net/p/67bcb002d38f11ecad6152540025c377">https://afdian.net/p/67bcb002d38f11ecad6152540025c377</a></p><p>数据集不定期增量更新到上述下载地址~</p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 新闻 </tag>
            
            <tag> 数据集 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>话『雨』</title>
      <link href="/blog/something-about-rain.html"/>
      <url>/blog/something-about-rain.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>原载于博主大学期间的一篇空间日志。</p></blockquote><p>今晚自习走出世主楼，不觉已是沉沉的黑夜，还有一点小雨，雨滴滴答答地下，又湿又黑，此情此景，我没有汪国真“寒风冷雨”的感慨，倒是想起一些我和“雨”的那些陈年往事。</p><p>记忆中，我第一次见到对“雨”的文学性描述，大概是一首“大雨淅沥沥，小雨哗啦啦”的儿歌，活泼可爱的曲风，大概奠定了我一直以来对雨的好感。</p><p>一说到下雨，我向来是不喜欢打伞的，原因之一呢，是我太喜欢雨打在脸庞的那种感觉了，虽然意象不同，我这里还是想引用一句“吹面不寒杨柳风”来描绘，那种感觉呐，就像全身心地在和大自然交谈，窃窃私语，不可与人说；还有一个比较现实的原因就是，因为每次打伞，一般都是去参加某种公共活动，比如上学或者聚会，然后玩得欢欣了，一般就会把它遗忘在某个角落，再想起来时它已不在原地等我了，还有一次，那是上小学的时候，有一天放学，阴风怒号，我一个人穿过一段山路回家，在经过一个比较阴沉的水塘的时候，突然风大了起来，把我的伞给吹翻了，然后就飞到水塘里去了，雨很大，水塘很深，而我的手又短，真的是很绝望了。所以每次雨天回家，我妈总是质问我，伞哪去了，后面就懒得问了，只是拿干毛巾擦我的头，怕着凉。当然，如果雨是下的很大，倾盆大雨那种，或者是恰如“一桥清雨一伞开”这种妙不可言可遇不可求的意境，我是很乐意打伞的。 </p><p>下面就要把“雨”和我的吃货属性结合在一起了。 </p><p>梅雨季节，雨就一直下个不停，雨一停，我爸就带上我，以及一个捞鱼的网兜，去那些水渠与河流汇合的地方，用网兜一抄，必有各种野生的鲫鱼鲤鱼鲢鱼…，后来我上了高中，觉得可以用“下雨天新鲜的雨水含氧量太少，而这些汇合处因为和水流动性强结合氧气可能性大”之类的阐述来解释它，也算是学以致用吧。只是不知道为什么，这种时候捕的野生鱼，味道非常鲜美，我爸负责杀鱼，我负责去菜园里采青辣椒和大蒜，然后就是非常幸福的吃货时光了。</p><p> 如果这种时候我爸不带我玩的话，我通常会一个人去后山，它有个确切的名字叫［白鹭山］，说实话我倒没怎么见过白鹭，大小和白鹭相近，颜色和白鹭相似的一种湘南常见的菌类我倒见过不少(学名叫什么我现在也没查到，下次一定要用［形色］去辨一辨)，特别是下雨后，在马尾松的树根处、针丝叶铺得很厚的地方，一定有这种菌类的痕迹，每次拨开厚厚的叶子发现它，有两种思绪在我心中起伏，它这么可爱，又是一个新生的生命，你怎么舍得下手，但我终究只是凡夫俗子，到底垂涎它的美味，说到这，禁不住唾液的浸润了。 </p><p>许久未写一些无用的文字了，笔墨有些生疏，我的作文本也快一年没有动过了，是时候重新捡起来了。除了计算机，文学艺术确实是我生平另一大爱好，一来我这个俗人喜欢附庸风雅，二来用来打发时间，在物欲横流，利益至上的当今，还有什么比看这些无用书写无用字更舒服的呢，不为无用之事，何以遣有生之涯？</p>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 雨 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pandas 合并具有相同结构的 csv</title>
      <link href="/blog/merge-csv-with-same-columns.html"/>
      <url>/blog/merge-csv-with-same-columns.html</url>
      
        <content type="html"><![CDATA[<p>只要某文件夹下所有的 csv 文件结构相同，在文件夹路径运行以下代码就能自动合并，输出结果在 all.csv ，结果 csv 在原有的 csv 结构上新增一列 origin_file_name，值为原来的 csv 文件名，保证了没有信息的衰减。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># author:           inspurer(月小水长)</span></span><br><span class="line"><span class="comment"># create_time:      2022/4/13 10:33</span></span><br><span class="line"><span class="comment"># 运行环境           Python3.6+</span></span><br><span class="line"><span class="comment"># github            https://github.com/inspurer</span></span><br><span class="line"><span class="comment"># website           https://buyixiao.github.io/</span></span><br><span class="line"><span class="comment"># 微信公众号         月小水长</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">result_csv = <span class="string">&#x27;all.csv&#x27;</span></span><br><span class="line">all_cols = []</span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> os.listdir(<span class="string">&#x27;.&#x27;</span>):</span><br><span class="line">    <span class="keyword">if</span> file.endswith(<span class="string">&#x27;.csv&#x27;</span>) <span class="keyword">and</span> <span class="keyword">not</span> file == result_csv:</span><br><span class="line">        df = pd.read_csv(file)</span><br><span class="line">        all_cols = df.columns.values.tolist()</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(all_cols) == <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">raise</span> Exception(<span class="string">&quot;当前目录下没有要合并的 csv 文件&quot;</span>)</span><br><span class="line">all_cols.insert(<span class="number">0</span>, <span class="string">&#x27;origin_file_name&#x27;</span>)</span><br><span class="line">all_df = pd.DataFrame(&#123;col: [] <span class="keyword">for</span> col <span class="keyword">in</span> all_cols&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> os.listdir(<span class="string">&#x27;.&#x27;</span>):</span><br><span class="line">    <span class="keyword">if</span> file.endswith(<span class="string">&#x27;.csv&#x27;</span>) <span class="keyword">and</span> <span class="keyword">not</span> file == result_csv:</span><br><span class="line">        df = pd.read_csv(file)</span><br><span class="line">        df.insert(<span class="number">0</span>, <span class="string">&#x27;origin_file_name&#x27;</span>, [file <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(df.shape[<span class="number">0</span>])])</span><br><span class="line">        all_df = all_df.append(df, ignore_index=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">all_df.to_csv(result_csv, index=<span class="literal">False</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br></pre></td></tr></table></figure><p>2023.10.30 日更新，如果上面代码耗时较多，可尝试使用以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># author:           inspurer(月小水长)</span></span><br><span class="line"><span class="comment"># create_time:      2023/10/30 15:23</span></span><br><span class="line"><span class="comment"># 运行环境           Python3.6+</span></span><br><span class="line"><span class="comment"># github            https://github.com/inspurer</span></span><br><span class="line"><span class="comment"># website           https://buyixiao.github.io/</span></span><br><span class="line"><span class="comment"># 微信公众号         月小水长</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">do_merge</span>(<span class="params">input_folder, output_file=<span class="string">&#x27;all.csv&#x27;</span>, append_file_name_col=<span class="literal">True</span>, file_name_col=<span class="string">&#x27;origin_file_name&#x27;</span></span>):</span></span><br><span class="line">    result_csv = output_file</span><br><span class="line">    all_cols = []</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(input_folder):</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">f&quot;目录 <span class="subst">&#123;input_folder&#125;</span> 不存在&quot;</span>)</span><br><span class="line"></span><br><span class="line">    file_cnt = <span class="built_in">len</span>(os.listdir(input_folder))</span><br><span class="line">    <span class="keyword">for</span> file <span class="keyword">in</span> os.listdir(input_folder):</span><br><span class="line">        <span class="keyword">if</span> file.endswith(<span class="string">&#x27;.csv&#x27;</span>) <span class="keyword">and</span> <span class="keyword">not</span> file == result_csv:</span><br><span class="line">            df = pd.read_csv(os.path.join(input_folder, file))</span><br><span class="line">            all_cols = df.columns.values.tolist()</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(all_cols) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">f&quot;当前目录 <span class="subst">&#123;os.path.abspath(input_folder)&#125;</span>下没有要合并的 csv 文件&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> append_file_name_col:</span><br><span class="line">        all_cols.insert(<span class="number">0</span>, file_name_col)</span><br><span class="line">        </span><br><span class="line">    save_cols = all_cols</span><br><span class="line">    df_list = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> index, file <span class="keyword">in</span> <span class="built_in">enumerate</span>(os.listdir(input_folder)):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;index + <span class="number">1</span>&#125;</span>/ <span class="subst">&#123;file_cnt&#125;</span> <span class="subst">&#123;file&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> file.endswith(<span class="string">&#x27;.csv&#x27;</span>) <span class="keyword">and</span> <span class="keyword">not</span> file == result_csv:</span><br><span class="line">            file_name = file[:file.rindex(<span class="string">&#x27;.&#x27;</span>)]</span><br><span class="line">            df = pd.read_csv(os.path.join(input_folder, file), float_precision=<span class="string">&#x27;high&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> append_file_name_col:</span><br><span class="line">                df.insert(<span class="number">0</span>, file_name_col, [file_name <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(df.shape[<span class="number">0</span>])])</span><br><span class="line"></span><br><span class="line">            df = df[save_cols]</span><br><span class="line"></span><br><span class="line">            df_list.append(df)</span><br><span class="line"></span><br><span class="line">    all_df = pd.concat(df_list, ignore_index=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(all_df.shape[<span class="number">0</span>])</span><br><span class="line">    <span class="comment"># subset_ = [&#x27;unique col name of your dataframe&#x27;]</span></span><br><span class="line">    subset_ = []</span><br><span class="line">    <span class="keyword">if</span> append_file_name_col:</span><br><span class="line">        subset_.append(file_name_col)</span><br><span class="line">    all_df.drop_duplicates(subset=subset_, inplace=<span class="literal">True</span>, keep=<span class="string">&#x27;first&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(all_df.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    all_df.to_csv(result_csv, index=<span class="literal">False</span>, encoding=<span class="string">&#x27;utf-8-sig&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    do_merge(input_folder=<span class="string">&#x27;./&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pandas </tag>
            
            <tag> csv 合并 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pandas 分层抽样</title>
      <link href="/blog/pandas-stratified-sampling.html"/>
      <url>/blog/pandas-stratified-sampling.html</url>
      
        <content type="html"><![CDATA[<p>dataframe 里面要有 created_at 一列，格式 %Y-%m-%d %H:%M:%S，首先提取出小时，然后分层（组）抽样，保存到 csv 中，话不多说，上代码～</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># author:           inspurer(月小水长)</span></span><br><span class="line"><span class="comment"># create_time:      2022/4/2 22:58</span></span><br><span class="line"><span class="comment"># 运行环境           Python3.6+</span></span><br><span class="line"><span class="comment"># github            https://github.com/inspurer</span></span><br><span class="line"><span class="comment"># 微信公众号         月小水长</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">input_file = <span class="string">&#x27;RussiaUkraine1.csv&#x27;</span></span><br><span class="line">output_file = <span class="string">&#x27;RussiaUkraine2.csv&#x27;</span></span><br><span class="line"></span><br><span class="line">df = pd.read_csv(input_file)</span><br><span class="line"><span class="comment"># 新增一列 hour</span></span><br><span class="line">df[<span class="string">&#x27;hour&#x27;</span>] = pd.to_datetime(df[<span class="string">&#x27;created_at&#x27;</span>]).dt.hour  <span class="comment"># 时间</span></span><br><span class="line"><span class="comment"># 抽样比例 1%</span></span><br><span class="line">res_df = df.groupby(df[<span class="string">&#x27;hour&#x27;</span>]).apply(<span class="keyword">lambda</span> x: x.sample(frac=<span class="number">0.01</span>))</span><br><span class="line">res_df.to_csv(output_file, index=<span class="literal">False</span>, encoding=<span class="string">&#x27;utf-8-sig&#x27;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pandas </tag>
            
            <tag> 分层抽样 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ip 访问正常，解析到此 ip 的域名却指向了 nginx 默认首页</title>
      <link href="/blog/domainname-to-nginx-default-but-ip-to-ours.html"/>
      <url>/blog/domainname-to-nginx-default-but-ip-to-ours.html</url>
      
        <content type="html"><![CDATA[<h3 id="背景环境"><a href="#背景环境" class="headerlink" title="背景环境"></a>背景环境</h3><p>硬件：阿里云 2 核 4 G 轻量应用级服务器</p><p>操作系统：Ubuntu 18.04.6 LTS</p><p> nginx version：nginx/1.14.0 (Ubuntu)</p><h3 id="故障表现"><a href="#故障表现" class="headerlink" title="故障表现"></a>故障表现</h3><p>域名成功解析到了 ip，此 ip 访问自己的应用正常，但是域名访问却指向了 nginx 的 index page。</p><h3 id="原因剖析"><a href="#原因剖析" class="headerlink" title="原因剖析"></a>原因剖析</h3><p>首先必须了解该问题涉及到的 nginx 的相关知识。</p><table><thead><tr><th align="center">nginx 相关配置</th><th align="center">路径</th></tr></thead><tbody><tr><td align="center">总配置文件</td><td align="center">/etc/nginx/nginx.conf</td></tr><tr><td align="center">nginx 配置的默认 server 配置文件</td><td align="center">/etc/nginx/sites-enabled/default</td></tr><tr><td align="center">我们自定义的 server 配置文件</td><td align="center">/etc/nginx/conf.d 下所有以 .conf 后缀的文件</td></tr></tbody></table><p>后面两个路径可以在总配置文件中找到：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">include</span> /etc/nginx/conf.d/<span class="regexp">*.conf</span>;</span><br><span class="line"><span class="attribute">include</span> /etc/nginx/sites-enabled/*;</span><br></pre></td></tr></table></figure><blockquote><p>注意第二个路径是 sites-enabled 而不是 sites-available，这两者区别可自行 google，相关知识和本文问题无关。</p></blockquote><p>nginx 默认的 server 配置文件如下：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">        <span class="attribute">listen</span> <span class="number">80</span> default_server;</span><br><span class="line">        <span class="attribute">listen</span> [::]:<span class="number">80</span> default_server;</span><br><span class="line"></span><br><span class="line">        <span class="attribute">root</span> /var/www/html;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Add index.php to the list if you are using PHP</span></span><br><span class="line">        <span class="attribute">index</span> index.html index.htm index.nginx-debian.html;</span><br><span class="line"></span><br><span class="line">        <span class="attribute">server_name</span> _;</span><br><span class="line"></span><br><span class="line">        <span class="attribute">location</span> / &#123;</span><br><span class="line">                <span class="comment"># First attempt to serve request as file, then</span></span><br><span class="line">                <span class="comment"># as directory, then fall back to displaying a 404.</span></span><br><span class="line">                <span class="attribute">try_files</span> $uri $uri/ =<span class="number">404</span>;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>而当前的 ip 与之对应的自定义 server 配置如下：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="attribute">upstream</span> django &#123;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">127.0.0.1:9595</span>;  <span class="comment"># uwsgi 配置的ip和端口</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">    <span class="attribute">listen</span> <span class="number">80</span>;  <span class="comment"># 监听80端口</span></span><br><span class="line">    <span class="attribute">server_name</span> <span class="number">120.77.233.137</span>;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">location</span> / &#123;</span><br><span class="line">        <span class="comment"># 请求转发到 uwsgi 服务器</span></span><br><span class="line">        <span class="attribute">proxy_pass</span> http://django;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 设置请求头，并将头信息传递给服务器端</span></span><br><span class="line">        <span class="attribute">proxy_set_header</span> Host $host;</span><br><span class="line">        <span class="attribute">proxy_set_header</span> X-Real-IP $remote_addr;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>可以自定义的 server_name 为 120.77.233.137，域名 kcool.top 访问时不会匹配到这个 server，就会交给 nginx 的 default_server 处理，也就到了 nginx 的 index page。</p><p>解决办法已经呼之欲出了。</p><h3 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h3><p>最好的解决办法是将域名 kcool.top 也加入我们自定义的 server_name 中，和现有的 ip 以空格分隔，即 :</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">server_name</span> kcool.top <span class="number">120.77.233.137</span></span><br></pre></td></tr></table></figure><p>不得不说很多教程说多个 server_name 以逗号分隔实在是太坑了。</p><p>还有一种办法是将总配置文件的下面这行注释掉：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">include</span> /etc/nginx/sites-enabled/*;</span><br></pre></td></tr></table></figure><p>讲道理会 404 的，我也不知道为什么可行，有空再琢磨~</p>]]></content>
      
      
      <categories>
          
          <category> nginx </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nginx </tag>
            
            <tag> default_server </tag>
            
            <tag> 域名解析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一站式微博可视化平台</title>
      <link href="/blog/one-stop-weibo-visualization.html"/>
      <url>/blog/one-stop-weibo-visualization.html</url>
      
        <content type="html"><![CDATA[<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>抽空写了一个微博可视化的网站，前端基于 sb-admin-2，后端基于 django3，微博相关数据则来源于本站维护的 <a href="https://buyixiao.github.io/blog/weibo-super-spider.html">微博超级爬虫系列</a>。</p><p>网站旨在成为一站式微博可视化分析平台，可以选择按照话题/关键词、位置、用户等维度聚合微博进行总体可视分析，也可以选择某一条微博，对它的转发、评论和点赞数据进行透视分析。以及满足个性化的可视化需求。</p><h3 id="访问地址"><a href="#访问地址" class="headerlink" title="访问地址"></a>访问地址</h3><p>域名访问：<a href="http://weibo.buyixiao.xyz/">http://weibo.buyixiao.xyz</a><br>备用访问：<a href="http://8.142.38.214:9920/">http://8.142.38.214:9920</a></p><h3 id="更新日志"><a href="#更新日志" class="headerlink" title="更新日志"></a>更新日志</h3><h4 id="2022-02-08"><a href="#2022-02-08" class="headerlink" title="2022/02/08"></a>2022/02/08</h4><p>网站上线，只完成了对用户/话题微博的时间分布、地理分布、转评赞榜、情感分析，词云等可视分析，可以直观看到用户/话题的数据表；以及一个简易的评论多级转发可视化。</p><p>不能自动抓取微博话题，需要抓取分析的话题请在文末留言，将定期查看留言话题进行抓取分析，并将话题数据导入网站，可视分析结果可直接在网页下载，下载按钮就在每一个图表的右上角。</p><h4 id="2022-02-28"><a href="#2022-02-28" class="headerlink" title="2022/02/28"></a>2022/02/28</h4><p>新上线接口 <a href="http://weibo.buyixiao.xyz/custom-vis/topics-daily-sentiment-compare-visual/">/custom-vis/topics-daily-sentiment-compare-visual/</a>；读者可以自行上传多个话题爬虫的 csv 文件进行对比情感分析可视化。</p><h4 id="2022-03-03"><a href="#2022-03-03" class="headerlink" title="2022/03/03"></a>2022/03/03</h4><p>新上线 location 栏目；收录北京一众高等院校和鸟巢、奥森、鼓楼、景山公园、三里屯等 50 个地标近 5w 条最新微博。</p><h4 id="2022-03-05"><a href="#2022-03-05" class="headerlink" title="2022/03/05"></a>2022/03/05</h4><p>新上线李文亮先生 <a href="https://weibo.com/1139098205/Is9M7taaY">最后一条微博</a> 的评论 LDA 分析，抓取数万条评论，计算确定最优主题困惑度为 5。分析结果地址：<a href="http://weibo.buyixiao.xyz/comment/liwenliang">/comment/liwenliang</a> 。</p><h4 id="2022-04-22"><a href="#2022-04-22" class="headerlink" title="2022/04/22"></a>2022/04/22</h4><p>新上线接口 <a href="http://weibo.buyixiao.xyz/custom-vis/topic-user-co-occurrence-visual/">/custom-vis/topic-user-co-occurrence-visual/</a> ；读者可自行上传话题 csv 文件提取文本中的相互艾特好友的人物共现网络。</p>]]></content>
      
      
      <categories>
          
          <category> 可视化 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 可视化 </tag>
            
            <tag> echarts </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>开源|微博备份助手</title>
      <link href="/blog/weibo-user-backup.html"/>
      <url>/blog/weibo-user-backup.html</url>
      
        <content type="html"><![CDATA[<h3 id="扩展介绍"><a href="#扩展介绍" class="headerlink" title="扩展介绍"></a>扩展介绍</h3><p>得空写了个微博用户备份助手。</p><p>它的作用是备份用户自己或者任意微博用户的微博数据，并将结果保存到本地的 xlsx 文件。</p><p><img src="https://s2.loli.net/2022/02/16/TKsNObdBpVhultv.png" alt="weibo_backup_show_zip.png"></p><h3 id="使用指南"><a href="#使用指南" class="headerlink" title="使用指南"></a>使用指南</h3><p>1、确保在浏览器登录了 weibo.cn</p><p>2、在 weibo.cn 或者 weibo.com 站点内的微博用户主页上点击扩展图标，会显示如上图，自动解析数字 uid，然后点击开始抓取按钮即可；如果自动解析失败，可手动输入然后抓取；如果自定义微博主页用户的数字 uid 获取方式为：在它的主页上任意一条微博上的用户名右键在新标签页打开，浏览器地址栏就能看到数字 uid 了。</p><p>3、抓取时请勿离开页面或者关闭扩展，抓取结束会自动保存 lxsx，每 增量 200 条也会全部保存一次到 lxsx，因此抓取过程中会有多个 lxsx 文件生成，以最后的文件为准。</p><h3 id="安装地址"><a href="#安装地址" class="headerlink" title="安装地址"></a>安装地址</h3><p>上线了 google 商城，可一在线安装。</p><blockquote><p><a href="https://chrome.google.com/webstore/detail/%E5%BE%AE%E5%8D%9A%E5%A4%87%E4%BB%BD%E5%8A%A9%E6%89%8B/kbgjdcobjobchmhfddlfjnnlaaoiejla?hl=zh-CN">https://chrome.google.com/webstore/detail/%E5%BE%AE%E5%8D%9A%E5%A4%87%E4%BB%BD%E5%8A%A9%E6%89%8B/kbgjdcobjobchmhfddlfjnnlaaoiejla?hl=zh-CN</a></p></blockquote><p>代码开源在 github，也可通过源码安装。</p><blockquote><p><a href="https://github.com/Python3Spiders/WeiboBackupExtension">https://github.com/Python3Spiders/WeiboBackupExtension</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Chrome Extension </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 微博用户爬虫 </tag>
            
            <tag> 微博备份 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>flask 获取被 nginx 反向代理的客户端真实 ip</title>
      <link href="/blog/client-real-ip-proxy-by-nginx.html"/>
      <url>/blog/client-real-ip-proxy-by-nginx.html</url>
      
        <content type="html"><![CDATA[<p>服务端为了防爬虫或其他用途，需要获取客户端真实 ip，在 flask 中获取客户端 ip 的方法如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip = request.remote_addr <span class="comment">#写在 view 中</span></span><br></pre></td></tr></table></figure><p>但是通过 nginx 反向代理后，获取的 ip 全部变成了 127.0.0.1。</p><p>可以在 nginx 中的配置文件中 location 下块添加一行：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置请求头，并将头信息传递给服务器端</span></span><br><span class="line"><span class="attribute">proxy_set_header</span> X-Real-IP $remote_addr;</span><br></pre></td></tr></table></figure><p>然后在 flask 中通过以下代码就能获取真实 ip 了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip = request.headers[<span class="string">&#x27;X-Real-IP&#x27;</span>]</span><br></pre></td></tr></table></figure><p>很多类似的教程坑在，只给出一个类似 <code>ip = request.headers[&#39;X-Forwarded-For&#39;] </code>根本不告诉你 headers 的这个 key 是在 nginx 中配置的。</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> flask </tag>
            
            <tag> nginx </tag>
            
            <tag> ip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>开源|一个微博去广告、屏蔽关键词的扩展</title>
      <link href="/blog/weibo-ads-filter-keyword-blocker.html"/>
      <url>/blog/weibo-ads-filter-keyword-blocker.html</url>
      
        <content type="html"><![CDATA[<h3 id="功能介绍"><a href="#功能介绍" class="headerlink" title="功能介绍"></a>功能介绍</h3><p>针对 weibo.com 这个站点开发了一款名为微博清理大师的插件，其主要功能如下：</p><p>1、永久去广告。</p><p>2、可添加自定义关键词，你刷到的微博和热搜榜将永远看不到这些关键词，除非你手动删除关键词。</p><p>3、可添加微博用户，你再也刷不到 ta 的微博，也可删除。</p><p>4、微博目前是乱序，插件组织微博按照从新到旧的时间线排列，方便阅读。</p><h3 id="操作介绍"><a href="#操作介绍" class="headerlink" title="操作介绍"></a>操作介绍</h3><p>UI 简单，操作方便。</p><p><img src="https://s2.loli.net/2022/01/27/5A6KUd4p1rwtsVQ.png" alt="配置.png"></p><p>点击上方的 1 处可以增删关键词，2 处可以拉黑、解除拉黑用户。</p><p><img src="https://s2.loli.net/2022/01/27/vSQWJzyrKm3kVPF.png" alt="右键菜单.png"></p><p>也可以选中文字右键添加。</p><h3 id="原理介绍"><a href="#原理介绍" class="headerlink" title="原理介绍"></a>原理介绍</h3><p>原理很简单，就是拦截 weibo.com 相关接口的请求，并修改响应，去掉广告和屏蔽词，并使之按照时间正序排列，然后就是工程实现了。</p><p>相关接口指的是全部微博、特别关注、最新微博、好友圈和热搜榜相关的接口。</p><p>代码已经全部开源在 github 上，感兴趣的同学可以去看看。</p><blockquote><p><a href="https://github.com/Python3Spiders/WeiboFilterExtension">https://github.com/Python3Spiders/WeiboFilterExtension</a></p></blockquote><h3 id="安装使用"><a href="#安装使用" class="headerlink" title="安装使用"></a>安装使用</h3><p>这个 project 差不多是 2022 年元旦完成的，一直拖到最近才想到上线 Google Chrome 网上应用商店，但是自从 2022 年 1 月 17 起，这个商店就升级了，从技术手段上阻止了很多拦截广告的扩展，这就直接导致了我的插件无法上线 chrome 商店，就算上线了也不会 work。还有一点是，到 2023 年，几乎 chrome 商店里所有拦截广告的扩展都会失效。这波真是 49 年入国军。</p><p>所以目前来看， chrome 使用这个插件并且 work 的话，只能离线安装 crx 文件，crx 文件地址就是上面那个仓库的根目录下的 WeiboFilterExtension.crx 文件。</p><p>下载 crx 文件后，在 chrome 浏览器输入  <code>chrome://extensions/</code> 进入到 chrome 扩展管理页面，然后打开右上方的开发者模式，把这个 crx 文件拖到这个界面即可。</p><p>或者选择源码安装，clone github 地址，选择左上方加载已解压的 扩展程序，选择代码文件夹即可。</p>]]></content>
      
      
      <categories>
          
          <category> Chrome Extension </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 微博 </tag>
            
            <tag> chrome 扩展 </tag>
            
            <tag> 去广告 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>聚源新闻爬虫及网站介绍</title>
      <link href="/blog/all-news-spider.html"/>
      <url>/blog/all-news-spider.html</url>
      
        <content type="html"><![CDATA[<h3 id="项目介绍"><a href="#项目介绍" class="headerlink" title="项目介绍"></a>项目介绍</h3><div class="note primary simple"><p>针对泰晤士报，纽约时报，BBC News 等国外主流媒体进行关键词抓取，针对澎湃新闻，新浪新闻，腾讯新闻等国内主流媒体进行分类抓取。</p></div><div class="note primary simple"><p>短期目前旨在爬取所有新闻门户网站的新闻，每个门户网站爬虫开箱即用，并自动保存到同目录下的 csv/excel 文件中。</p></div><div class="note primary simple"><p>长期目标是打造一个信息流聚合平台，或者进行更高层面的比如社会舆情、新闻地理可视化等的处理。</p></div><h3 id="github-地址"><a href="#github-地址" class="headerlink" title="github 地址"></a>github 地址</h3><p>具体使用可以参考 github 上的 demo 和 wiki：</p><p><a href="https://github.com/Python3Spiders/AllNewsSpider">https://github.com/Python3Spiders/AllNewsSpider</a></p><h3 id="网站地址"><a href="#网站地址" class="headerlink" title="网站地址"></a>网站地址</h3><p>新闻数据展示网站：</p><p><a href="http://buyixiao.xyz/">http://buyixiao.xyz/</a></p><p>上面失效了话，使用如下备用地址访问：</p><p><a href="http://8.142.38.214/">http://8.142.38.214/</a></p><p><img src="https://s2.loli.net/2022/01/22/ofuOjMwS9Q6G43V.png" alt="聚源新闻网站_zip.png"></p><p><font size=4 color="red">服务器性能有限，新开了其他网站，暂时关闭此网站，2022/05/31 记录。</font></p><h3 id="项目赞助"><a href="#项目赞助" class="headerlink" title="项目赞助"></a>项目赞助</h3><p>博主维护着不少的开源项目，见于 <a href="https://github.com/inspurer">https://github.com/inspurer</a> ，耗费着大量的时间和精力，如果项目帮助到了你，可以点击下方赞赏，助力项目长期发展。</p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> bbcnews </tag>
            
            <tag> nytimes </tag>
            
            <tag> thetimes </tag>
            
            <tag> pengpai </tag>
            
            <tag> sina </tag>
            
            <tag> tencent </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>罗素：我为什么而活</title>
      <link href="/blog/what-i-have-lived-for-by-russell.html"/>
      <url>/blog/what-i-have-lived-for-by-russell.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>全文摘自《我为什么而活着》，《我为什么而活着》是《罗素自传》的序言，作者是伯特兰·罗素。</p></blockquote><h2 id="中文译文"><a href="#中文译文" class="headerlink" title="中文译文"></a>中文译文</h2><p>对爱情的渴望，对知识的追求，对人类苦难不可遏制的同情心，这三种纯洁而无比强烈的激情支配着我的一生。这三种激情，就像飓风一样，在深深的苦海上，肆意地把我吹来吹去，吹到濒临绝望的边缘。</p><p>我寻求爱情，首先因为爱情给我带来狂喜，它如此强烈以致我经常愿意为了几小时的欢愉而牺牲生命中的其他一切。我寻求爱情，其次是因为爱情可以解除孤寂一—那是一颗震颤的心，在世界的边缘，俯瞰那冰冷死寂、深不可测的深渊。我寻求爱情，最后是因为在爱情的结合中，我看到圣徒和诗人们所想像的天堂景象的神秘缩影。这就是我所寻求的，虽然它对人生似乎过于美好，然而最终我还是得到了它。</p><p>我以同样的热情寻求知识，我渴望了解人的心灵。我渴望知道星星为什么闪闪发光，我试图理解毕达哥拉斯的思想威力，即数字支配着万物流转。这方面我获得一些成就，然而并不多。</p><p>爱情和知识，尽其可能地把我引上天堂，但是同情心总把我带回尘世。痛苦的呼唤经常在我心中回荡，饥饿的儿童，被压迫被折磨者，被儿女视为负担的无助的老人以及充满孤寂、贫穷和痛苦的整个世界，都是对人类应有生活的嘲讽。我渴望减轻这些不幸，但是我无能为力，而且我自己也深受其害。</p><p>这就是我的一生，我觉得值得为它活着。如果有机会的话，我还乐意再活一次。</p><h2 id="英文原文"><a href="#英文原文" class="headerlink" title="英文原文"></a>英文原文</h2><p>《What I Have Lived For》 by Bertrand Russell</p><p>Three passions, simple but overwhelmingly strong, have governed my life: the longing for love, the search for knowledge, and unbearable pity for the suffering of mankind. These passions, like great winds, have blown me hither and thither, in a wayward course, over a great ocean of anguish, reaching to the very verge of despair.</p><p>I have sought love, first, because it brings ecstasy - ecstasy so great that I would often have sacrificed all the rest of life for a few hours of this joy. I have sought it, next, because it relieves loneliness–that terrible loneliness in which one shivering consciousness looks over the rim of the world into the cold unfathomable lifeless abyss. I have sought it finally, because in the union of love I have seen, in a mystic miniature, the prefiguring vision of the heaven that saints and poets have imagined. This is what I sought, and though it might seem too good for human life, this is what–at last–I have found.</p><p>With equal passion I have sought knowledge. I have wished to understand the hearts of men. I have wished to know why the stars shine. And I have tried to apprehend the Pythagorean power by which number holds sway above the flux. A little of this, but not much, I have achieved.</p><p>Love and knowledge, so far as they were possible, led upward toward the heavens. But always pity brought me back to earth. Echoes of cries of pain reverberate in my heart. Children in famine, victims tortured by oppressors, helpless old people a burden to their sons, and the whole world of loneliness, poverty, and pain make a mockery of what human life should be. I long to alleviate this evil, but I cannot, and I too suffer.</p><p>This has been my life. I have found it worth living, and would gladly live it again if the chance were offered me.</p>]]></content>
      
      
      <categories>
          
          <category> 励志 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 罗素 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>李开复：追随我心</title>
      <link href="/blog/follow-your-heart-by-likaifu.html"/>
      <url>/blog/follow-your-heart-by-likaifu.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>全文摘自李开复相关传记，《追随我心》，作者不详。</p></blockquote><p>并不很久的以前，也就在 1979 年到 1980 年间，在哥伦比亚大学，两个政治科学系大一的新生，在课堂上总是没精打采。其中一个是来自台湾的华裔，喜欢窝在教室左后方的一隅，听得无趣，索性呼呼大睡。这个男孩叫李开复，此君并非厌学，而是对政治科学越来越不感兴趣。蹉跎到大二下学期，他终于决定快刀斩乱麻——转系，改学自己感兴趣的计算机。</p><p>兴趣是什么？兴趣就意味着天赋。李开复在计算机系如鱼得水，左右逢源，两年后毕业，成绩居全系之首。这样的学生用不着按部就班。在教授的推荐下，李开复进入在计算机领域独领风骚的卡内基•梅隆大学，直接攻读博士。计算机学院的院长找他谈话，劈头就问：“读博士的目的是什么？”李开复大声答：“我从大学带走的将是一篇改变世界的、顶尖的博士论文。”院长予以纠正，说：“你从这儿带走的最有价值的东西，不是一篇论文，而是你分析、思考的能力，研究、发现真理的经验，以及科学家的胸怀。这样，当你有一天改变研究方向，依然可以在任何一个新的领域出类拔萃。”李开复选定语音识别为攻读方向，经过一年“热恋”，他发现专家系统其冷如冰，远不如统计学有情有义。李开复决心“移情别恋”。他担心导师发怒，谁知得到的回答竟是：“开复，你对专家系统和统计的观点，我是不赞同的，但我可以支持你用统计的方法去做，因为我相信科学没有绝对的对错，我们都是平等的。而且，我更相信一个富有激情的人可以找到更好的解决方案。”李开复从导师的大度悟到科学的真谛，他全力以赴，放手一搏。３年过去了，李开复的研究成果及博士论文，引发了那年语音世界最大的冲击波。26 岁的李开复功成名就，成为卡内基•梅隆大学最年轻的副教授。天之骄子，有尊严，有地位，有课题，有经费，出任大公司顾问，飞赴各地讲学，包括去他的祖籍之邦、魂之所系的祖国大陆。</p><p>“让世界因你而不同！”这是李开复埋在心底多年的梦想。1990 年，苹果公司的一个邀请电话让李开复开始审视自己：“开复，你是想一辈子写一堆像废纸一样的学术论文，还是想真正地改变世界？”面对苹果公司的召唤，李开复旋即做出回应，走出象牙塔，加盟“改变世界”的大军。在苹果公司，李开复感受到了从纸上谈兵转入实战的无穷乐趣。1995 年，33 岁的李开复出任苹果公司的副总裁。</p><p>但是他仍然不满足，依然要跳槽，因为硅谷的另一家公司 SGI 发出了更有诱惑力的邀请——“你想做什么，然后我们根据你的兴趣对公司进行改组。”不是他们缺什么人才，让你去填补，而是诚恳地询问你需要什么平台，以便为你量身搭建。这样的机遇，李开复岂能错过！双方一拍即合，　1996 年７月，李开复跳槽去了 SGI 。李开复奉行“自己设计自己”的人生信条，怎奈 SGI 是一家硬件公司，开复的长处却在软件开发，这就等于在篮球场上跑马，任是赤兔、骅骝，也撒不开四蹄。日复一日，李开复萌生去意。对于下一个选择，他立下两条标准：一是做软件，二是去中国。</p><p>机会来了。其实机会无处不在，就看你有没有做好准备。彼时，比尔•盖茨创立的微软王国要把触角伸向中国，李开复成为它的不二人选。时间：1998 年金秋；职务：微软中国研究院院长。李开复在中国市场的开拓，值得写部书来描述，那是一种完全不同的创新理念、绝对领先的科学技术在神州大地生根发芽。微软只是起用了一个人，就开拓了中国市场；李开复只是“追随我心”，就一跃成为微软王国的副总裁。在你我想来，这该是李开复的最后一站。在微软占据高位，与比尔•盖茨亲密共事，坐拥财富和风光，“花迎喜气皆知笑，鸟识欢心亦解歌”。人生至此，夫复何求？李开复不这么想，他后来回忆：“我如同一部庞大机器上的零件，在中规中矩、没有任何发挥空间的环境下运行着。这是一个随时随地都可以被替换的光鲜零件。那种价值的缺失感以及精神上的落寞占据了我的内心。”微软既然已无成长空间，那就走吧！到哪儿去？他相中了 Google。但他清醒地意识到，管理更多的人马，不是自己的所爱，他渴望从无到有的创新，而不是经营一个巨无霸。于是，在2009 年９月，李开复又一次选择潇洒地离去。向总部递交辞呈之际，Google 高管艾伦•尤斯塔斯试图用更优厚的条件予以挽留。李开复真诚地说：“我的人生还有一个缺憾没有实现，现在得去弥补。我可能创办一家‘创新工场’，和中国青年一起创造新的技术奇迹。”</p><p>如今，李开复正在按照他本人的意愿，在神州大地进行“创新工场”试验。他会成功吗？我想这是毫无疑问的，也是次要又次要的，那么，最主要的一点是什么呢？诚如他自己所言：“人生在世时间非常短，如果你总是不敢做想做的事情，那么一生过去了，你留下来的只有悔恨，只有懊恼。”“我步入丛林，因为我希望生活得有意义，我希望活得深刻，并汲取生命中所有的精华，然后从中学习，以免让我在生命终结时，才发现自己从来没有活过。”</p>]]></content>
      
      
      <categories>
          
          <category> 励志 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 李开复 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>新微博通知 chrome 扩展使用介绍</title>
      <link href="/blog/new-weibo-notify-chrome-extension.html"/>
      <url>/blog/new-weibo-notify-chrome-extension.html</url>
      
        <content type="html"><![CDATA[<h2 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h2><p>博主开发的新微博通知助手，已上架谷歌扩展商城：<a href="https://chrome.google.com/webstore/detail/%E5%BE%AE%E5%8D%9A%E9%80%9A%E7%9F%A5%E5%8A%A9%E6%89%8B/cpmlmjdimlnhgnakcjfmbmfglhkaoago?hl=zh-CN">点击前往商城免费安装</a>。</p><p>它的作用是接收指定微博用户的最新微博通知（不包括置顶微博）。</p><p>它的特色是不需要 Cookie，不需要登录无状态即可收到桌面通知。</p><p>它的操作也特别简单，自动解析 uid，点击保存即可。</p><p><img src="https://s2.loli.net/2022/01/20/ygVbRSAwGJXvO7Y.png" alt="chrome_extension_zip.png"></p><p>然后插件就会定时 20s 去轮询这个人的微博状态，一有它的最新微博就会有系统级的桌面通知。</p><h2 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h2><p>1、注意解析的地址栏，必须是微博数字 uid，微博用户自定义域名的 id 不行。比如谢娜的微博主页自定义成 xiena，但是每一个微博用户都有数字 uid 的，怎么找呢，秘诀就是在这个微博用户任意一条的微博的用户名上右键在新 tab 打开链接，然后地址栏就有数字 uid 了。</p><p>这样自动解析成功，点击保存就能接受新微博通知了。</p><p>无论自动解析成否，也可以手动输入数字 uid；可以在上图 2 处输入框输入，也可以在上图 3 处 add uid 输入。保存的 uid 实时显示在 3 处浅绿色标签，一个 uid 对应一个标签。可以点击标签上的 X 删除 uid。</p><p>2、明明保存了配置，显示添加成功，也有新微博了，就是收不到通知？</p><p>可能在电脑的设置里关闭了 Chrome 的桌面通知权限？打开即可。</p><p>浏览器在后台或前台运行的话，能实时通知，如果关闭了，下次打开也能收到最新通知。</p><p>如果没网络那就肯定收不到通知了。</p><p>3、轮询时间不可设置</p><p>轮询时间也不能设置，固定 20s。何哉？因为本插件的定位是非常克制的，没有 cookie，登录，无状态。如果想同时接收很多人的通知，建议直接在浏览器打开 weibo.com。本插件的最佳食用方式是少量的 uid，uid 对应的博主不频繁发微博这种。</p>]]></content>
      
      
      <categories>
          
          <category> Chrome Extension </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 微博 </tag>
            
            <tag> chrome 扩展 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浅谈微博评论水军和异常流量</title>
      <link href="/blog/weibo-comment-robot-analysis.html"/>
      <url>/blog/weibo-comment-robot-analysis.html</url>
      
        <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>近年来，微博评论区的异常评论流量现象甚嚣尘上，背后是大量的营销账号的扰乱视听以及作为他们的傀儡的水军账号的推波助澜，本篇利用微博评论爬虫采集的公开数据，简单分析了这些现象的一些表征和原因。</p><h3 id="数说"><a href="#数说" class="headerlink" title="数说"></a>数说</h3><p>以人民日报发表的关于 <strong>#吴亦凡被批捕#</strong> 这条微博及其评论数据为例子。</p><p><img src="https://s2.loli.net/2022/01/20/AXRmgYvsIUJOHdb.png" alt="人民日报.png"></p><p>网页显示有近 18w 条微博，实际抓取去重后有 10w 稍有余的数据，包括根评论和回复，后文分析评论时，仅针对分析发博一天内的评论。抓取保存的评论字段信息如下</p><table><thead><tr><th align="center">字段名</th><th align="center">含义</th></tr></thead><tbody><tr><td align="center">parent_cid</td><td align="center">该回复所属的根评论 id，只有回复评论有值，根评论为空</td></tr><tr><td align="center">cid</td><td align="center">评论 id</td></tr><tr><td align="center">time</td><td align="center">评论发表时间</td></tr><tr><td align="center">text</td><td align="center">评论内容</td></tr><tr><td align="center">like_count</td><td align="center">评论点赞数</td></tr><tr><td align="center">reply_count</td><td align="center">该根评论有多少条回复评论，只有根评论有值，回复评论为0</td></tr><tr><td align="center">uid</td><td align="center">评论者 id</td></tr><tr><td align="center">username</td><td align="center">评论者用户名</td></tr><tr><td align="center">following</td><td align="center">评论者关注数</td></tr><tr><td align="center">followed</td><td align="center">评论者粉丝数</td></tr><tr><td align="center">gender</td><td align="center">评论者性别</td></tr></tbody></table><p>第一步，可视化该条微博发布后一天内每分钟新发评论数量时间线。</p><p><img src="https://s2.loli.net/2022/01/20/dIz632LbKUP7e1C.png" alt="发博后每分钟评论数.png"></p><p>每分钟评论数在短时间内指数型急剧上升，最后又以一象限双曲线形式下降，符合常理认知。同时可以看出，在发博时间 2021/08/16 20:30 过去 840mins，也就是发博 16 小时后，2021/08/17 10:30 时有个极大值，why？迫于本篇推送选题的压力，我马上想到了可能是水军账号这个时候营业了，但是我分析了这个时间段发布评论的用户，肉眼可见几乎没有水军账号。于是乎，我翻开了微博的历史热搜数据，发现在这个时间点，#都美竹感谢朝阳公安和粉丝# 这个话题冲到了热搜第一，很显然，是由于该关联话题的热度扩散到了这条微博。</p><p><img src="https://s2.loli.net/2022/01/20/SYlnov7ZT8JjrMO.png" alt="历史热搜.png"></p><p>如果查证历史热搜数据该时间点无相关热搜，且几乎没有观察到该时间点附近评论营销水军内容，那么下降曲线就会是完美的一象限双曲线；否则就需要确定是相关热搜或者是营销水军，亦或者是它们共同作用的结果。</p><p>第二步，怎么大致判断评论中水军账号呢，我的做法是 group_by uid。</p><p>分析结果显示，一天之内，一个账号最多针对该微博发布了 26 条评论，发布 10 条评论以上的账号多达 30 余人，这些账号具有一定的营销号或水军嫌疑，目前只能手动点开微博主页浏览去确定，长期地，我想输出一个模型，根据 uid 判断账号是否是营销号或者水军账号，目前的想法就是根据它的发博连续性，关注粉丝之比，账号新旧程序等维度考量，大家有好想法欢迎留言。</p><p>最后可视化每分钟评论的平均文本长度如下。</p><p><img src="https://s2.loli.net/2022/01/20/gvCaqyJENzZriuj.png" alt="发博后每分钟评论平均长度.png"></p><p>处理时去除了 html 标签表情等非文本内容，但是上图依旧有很大的锯齿，应该用中值滤波处理之，不过走势应该不会变。</p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>1、微博历史热搜数据：<a href="https://www.weibotop.cn/2.0/">https://www.weibotop.cn/2.0/</a></p><p>2、研究报告 | 微博评论中的水军异常流量分析：<a href="https://zhuanlan.zhihu.com/p/436967668">https://zhuanlan.zhihu.com/p/436967668</a></p>]]></content>
      
      
      <categories>
          
          <category> 可视化 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 可视化 </tag>
            
            <tag> 微博评论 </tag>
            
            <tag> 水军 </tag>
            
            <tag> 营销号 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微博明星关系网络可视化</title>
      <link href="/blog/weibo-superstar-relation-network-visual.html"/>
      <url>/blog/weibo-superstar-relation-network-visual.html</url>
      
        <content type="html"><![CDATA[<p>抓取微博指定用户的关注信息，并做了一定的可视化工作。下面以抓取明星关注为例，阐述从抓取数据，到关系网络的构造，最后使用 gephi 可视化的全流程。</p><p>第一步，以一个<strong>给定的明星 uid 为起点，爬取它的关注，接着爬关注的关注</strong>…从形式上看是一个<strong>递归的网络</strong>，所以设计了一个<strong>递归的爬虫</strong>，可以指定抓取指定的层数，断网或其他出错可以从上次爬到的地方继续；一般来说 3 层就非常多，以一个明星关注 100 个明星为例，第一层只有起点明星，第二层有 100 个明星，第三层就有 10000 个明星了，我使用<strong>杨幂</strong>的 uid 为起点，抓取 3 层网络，实测抓到了 2w+ 明星，20w+ 对明星关注关系，最后随机抽了 5000 条关注关系，2000 余明星。</p><p>第二步，根据上一步得到的数据构造<strong>关系矩阵</strong>，方便 gephi 可视化输入。这个关系矩阵需要两个 csv 文件表示，一个节点 <strong>nodes.csv</strong> 文件，另一个边表 <strong>edges.csv</strong> 文件。</p><p>nodes.csv 四个字段，id 即该明星的微博 userId，label 是其名字，weight 是在关系网络中被关注的次数，class 是 <strong>louvain</strong> 聚类的结果。</p><p>edges.csv 三个字段：source,target,weight，分别对应边的起点、终点、权重。</p><p>gephi 最终的效果图示：</p><p><img src="https://s2.loli.net/2022/01/20/CD1jH6aoOyE5bFN.png" alt="全景图.png"></p><p><img src="https://s2.loli.net/2022/01/20/jKC7VkRoaApzu84.png" alt="网络边缘放大图.png"></p><p><img src="https://s2.loli.net/2022/01/20/Gk7P5DENsSVH9Q4.png" alt="网络中心放大图.png"></p><p>谁是十八线，谁是一线，一目了然，各位明星，如有冒犯，纯属无心之举。</p><p>动态效果可以参考视频：</p><div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">    <iframe src="//player.bilibili.com/player.html?aid=593321690&bvid=BV1dq4y1k7g8&cid=488583955&page=1"  scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"></iframe></div><p>本文首发： <a href="https://buyixiao.github.io/blog/weibo-superstar-relation-network-visual.html">BuyiXiao’s Blog</a></p><p>链接地址：<a href="https://buyixiao.github.io/blog/weibo-superstar-relation-network-visual.html">https://buyixiao.github.io/blog/weibo-superstar-relation-network-visual.html</a></p><p>转载需注明来源。</p>]]></content>
      
      
      <categories>
          
          <category> 可视化 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 可视化 </tag>
            
            <tag> 关系网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微博转发网络可视化构建</title>
      <link href="/blog/weibo-forward-network-visual.html"/>
      <url>/blog/weibo-forward-network-visual.html</url>
      
        <content type="html"><![CDATA[<p>以敲钟人李文亮英雄的最后一条微博为例子，使用 <a href="https://buyixiao.github.io/blog/weibo-super-spider.html#%E8%BD%AC%E5%8F%91%E7%88%AC%E8%99%AB">新版微博转发爬虫</a> 抓取微博的具体转发信息,，抓取到 10w+ 的转发信息。</p><p>然后使用 <strong>pyecharts</strong> 构建了该条微博的 N 层转发关系网络。</p><p>依次取 N = 1,2,3,4，构建的网络图示：</p><div class="fj-gallery"><p><img src="https://s2.loli.net/2022/01/20/6W7qFOMVakQt12G.png" alt="n1.png"><br><img src="https://s2.loli.net/2022/01/20/UbLRrJdM3uZs1KY.png" alt="n4.png"><br><img src="https://s2.loli.net/2022/01/20/bYAP5xIMSrgmkis.png" alt="n2.png"><br><img src="https://s2.loli.net/2022/01/20/x8Oaz59lwZSdJrf.png" alt="n3.png"></p>          </div><p>动态效果可以参考视频：</p><div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">    <iframe src="//player.bilibili.com/player.html?aid=550803158&bvid=BV1Yq4y1c7TU&cid=488591630&page=1"  scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"></iframe></div><p>本文首发： <a href="https://buyixiao.github.io/blog/weibo-forward-network-visual.html">BuyiXiao’s Blog</a></p><p>链接地址：<a href="https://buyixiao.github.io/blog/weibo-forward-network-visual.html">https://buyixiao.github.io/blog/weibo-forward-network-visual.html</a></p><p>转载需注明来源。</p>]]></content>
      
      
      <categories>
          
          <category> 可视化 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 可视化 </tag>
            
            <tag> 微博关系网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python 中的 pyd 和 pyc 文件</title>
      <link href="/blog/pyd-pyc-summary.html"/>
      <url>/blog/pyd-pyc-summary.html</url>
      
        <content type="html"><![CDATA[<h2 id="pyd-特点及生成方式"><a href="#pyd-特点及生成方式" class="headerlink" title="pyd 特点及生成方式"></a>pyd 特点及生成方式</h2><p>我们知道 <strong>windows 系统有许多 DLL 后缀的文件，即动态链接库，在运行时链接到调用程序</strong>。在运行时链接到 DLL 之类的库的主要优点是，它可以促进代码重用，模块化体系结构和更快的程序启动。结果，DLL 在 Windows 操作系统周围提供了许多功能。<strong>pyd 这个 d 就是取自于 DLL，只能运行在 windows 系统上</strong>。</p><p>假设我们有一个 demo.py，想要打成 demo.pyd；首先需要在 <strong>demo.py 同目录下新建个</strong> <strong>setup.py</strong> <strong>文件</strong>，内容如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> distutils.core <span class="keyword">import</span> setup</span><br><span class="line"><span class="keyword">from</span> Cython.Build <span class="keyword">import</span> cythonize</span><br><span class="line">setup(ext_modules=cythonize(<span class="string">&quot;demo.py&quot;</span>))</span><br></pre></td></tr></table></figure><p>然后在命令行或终端 cd 到这个目录下，输入一行命令之</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python setup.py build_ext --inplace</span><br></pre></td></tr></table></figure><p>当前目录下就会生成<strong>一个 build 文件夹，一个 .c 文件，还有我们的主人翁 .pyd 文件</strong>，<strong>自动生成的名字****并不是 demo.pyd</strong>，而是 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">demo.cp36-win_amd64.pyd</span><br></pre></td></tr></table></figure><p><strong>这个 cp36 和 win_amd64 视 python 版本和操作系统而定。我们需要把它改成 demo.pyd，注意，是只能改成 demo.pyd；改成其他任何名字都不行，使用时会 import error。使用该 pyd 方式如下：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import demofrom demo import &#123;&#123;类名|函数名&#125;&#125;</span><br></pre></td></tr></table></figure><h2 id="pyc-特点及生成方式"><a href="#pyc-特点及生成方式" class="headerlink" title="pyc 特点及生成方式"></a>pyc 特点及生成方式</h2><p>而我们<strong>安装的 python 目录下有许多 pyc 文件，这个 c 是编译 compile 过的意思</strong>，可以使用 python 解释器编译 py 文件 成 pyc 字节码文件。使用 pyc 可以加快程序的加载速度，而不能加快程序的实际执行速度，这就是解释为什么我们<strong>安装 python 目录很多第三方库下是 pyc 文件的原因，因为它可以使得 import 一些第三方库的速度加快</strong>。由于 .pyc 文件是编译好的字节码，<strong>它是独立于平台的，因此可以在不同体系结构的计算机之间共享</strong>。其实还有一个和 pyc 类似的字节码文件 pyo，一般 pyo 替代未经优化而创建的 pyc 文件，这里就不展开了~</p><p>使用下面一行命令就能<strong>将当前目录下的所有 py 文件打成 pyc</strong>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m compileall ./</span><br></pre></td></tr></table></figure><p><strong>pyc 的改名规则和 import 使用同 pyd !!!</strong></p><p>还有一点需要注意的是，由于 pyc 是由<strong>特定的 python 解析器生成的</strong>，它虽然能跨平台，但是不能跨版本，也<strong>只能运行在特定的 Python 版本上</strong>。如果 Python 版本不对，它会报 ImportError: bad magic number 错误。</p><h2 id="Pycharm-文件目录默认不索引-pyc"><a href="#Pycharm-文件目录默认不索引-pyc" class="headerlink" title="Pycharm 文件目录默认不索引 pyc"></a>Pycharm 文件目录默认不索引 pyc</h2><p> <strong>pyc 文件放到 Pycharm 中并不会显示它的存在？，但是确实实在存在于我们的文件夹之中的</strong>。</p><p>这是为什么呢？我猜测是 Pycharm 把 pyc exclude 排除显示了，上图 Pycharm 的 External Libraries 就是我们的 python 解析器，它有许许多多 pyc，如果全部显示。那么 index 索引将会非常大，严重会导致电脑卡死。</p><p>但是 pyd 就没有这种问题~</p><p>如不足之处欢迎批评指正~</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pyd </tag>
            
            <tag> pyc </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【稳定可用 | 持续更新】微博超级爬虫</title>
      <link href="/blog/weibo-super-spider.html"/>
      <url>/blog/weibo-super-spider.html</url>
      
        <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>本文是微博超级爬虫系列 2022 最新最全指南。</p><p>微博超级爬虫系列的仓库地址在 <a href="https://github.com/Python3Spiders/WeiboSuperSpider">https://github.com/Python3Spiders/WeiboSuperSpider</a></p><p>之前的连载全部在公众号，但是由于爬虫时常修改，公众号发文只能修改一次，故开此篇，保持更新！</p><p>相关开源代码仅为相关数据研究用，不做任何加速，没有 ip 代理，请勿用作其他用途，由此产生的法律风险本人概不承担。</p><p>相关未开源代码均为 pyd 或者 pyc 文件（不了解 pyd 或者 pyc 文件的读者 <a href="https://buyixiao.github.io/blog/pyd-pyc-summary">点击这里</a>，pyd 只兼容 win 系统，pyc 则可以兼容 win/mac/linux ，也没有任何加速或 ip 代理。</p><p><font color="red">运行本项目前，请确保已经关闭了 vpn 或者加速器，或者代理模式设置成 PAC 模式。</p><p>运行本项目的任何 py 文件，由于相关语法限制，python 版本大于等于 3.6 即可，32 bit or 64 bit 均可。</p><p>运行本项目的任何 pyd or pyc 文件，由于特有文件限制，请确保 python 环境是 python3.6.6 64 bit。</p><p>只推荐 Pycharm IDE 运行本项目。</p></font><p>还有一点，需要注意的是，微博的唯一标识 id 有两种形式。纯数字和数字+字母形式，这两者可以相互转化。转化的代码在文末，<a href="https://buyixiao.github.io/blog/weibo-super-spider.html#%E5%BE%AE%E5%8D%9A%E4%B8%A4%E7%A7%8D-id-%E7%9B%B8%E4%BA%92%E8%BD%AC%E5%8C%96%E4%BB%A3%E7%A0%81">点我直达</a>，遇到相关问题时查阅即可。</p><h2 id="更新日志"><a href="#更新日志" class="headerlink" title="更新日志"></a>更新日志</h2><h4 id="2022-08-29"><a href="#2022-08-29" class="headerlink" title="2022-08-29"></a>2022-08-29</h4><p>1、微博话题爬虫新增用户认证类型字段：verify_typ，取值范围为：没有认证、黄 V 认证、红 V 认证、蓝 V 认证。</p><p>2、修复微博话题爬虫 IndexError 等错误，提升稳定性。</p><h4 id="2023-02-11"><a href="#2023-02-11" class="headerlink" title="2023-02-11"></a>2023-02-11</h4><p>1、<a href="https://github.com/Python3Spiders/WeiboSuperSpider/blob/master/%E6%97%A0%20GUI%20%E5%8A%9F%E8%83%BD%E7%8B%AC%E7%AB%8B%E7%89%88/WeiboUserScrapy.py#L29">微博用户爬虫</a> 解决无法抓取自己微博和抓不全的 bug。</p><p>2、<a href="https://github.com/Python3Spiders/WeiboSuperSpider/blob/master/%E6%97%A0%20GUI%20%E5%8A%9F%E8%83%BD%E7%8B%AC%E7%AB%8B%E7%89%88/WeiboUserScrapy.py#L29">微博用户爬虫</a> 新增图片相册下载功能。</p><h4 id="2023-03-05"><a href="#2023-03-05" class="headerlink" title="2023-03-05"></a>2023-03-05</h4><p>1、新增开源 <a href="https://github.com/Python3Spiders/WeiboSuperSpider/blob/master/%E6%97%A0%20GUI%20%E5%8A%9F%E8%83%BD%E7%8B%AC%E7%AB%8B%E7%89%88/CommentedWeiboSpider.py">评论微博爬虫</a> 可实现某微博账号评论、转发和点赞过的微博信息。</p><h2 id="单功能微博爬虫"><a href="#单功能微博爬虫" class="headerlink" title="单功能微博爬虫"></a>单功能微博爬虫</h2><p>只需要抓取一个用户的所有微博或文章，一个关键词或者话题的特定时间段的微博，一个位置签到的最新微博，特定微博的转发，评论，点赞等功能之一的读者，可以只参考此部分。</p><h3 id="用户抓取系列"><a href="#用户抓取系列" class="headerlink" title="用户抓取系列"></a>用户抓取系列</h3><h4 id="用户微博爬虫"><a href="#用户微博爬虫" class="headerlink" title="用户微博爬虫"></a>用户微博爬虫</h4><p>见名知意，抓取一个用户的所有微博，针对 weibo.cn 站点，代码地址在 <a href="https://github.com/Python3Spiders/WeiboSuperSpider/blob/master/%E6%97%A0%20GUI%20%E5%8A%9F%E8%83%BD%E7%8B%AC%E7%AB%8B%E7%89%88/WeiboUserScrapy.py">WeiboUserScrapy.py</a></p><p>运行代码需要安装的库罗列如下：</p><blockquote><p>pip install requests</p><p>pip install lxml</p></blockquote><div class="note warning simple"><p>pip install 成功了还报错 module not found？<a href="https://buyixiao.github.io/blog/pip-install-success-import-fail.html">点击这里</a></p></div><p>csv 结果文件，保存在代码目录下的 user 文件夹中，保存字段格式如下：</p><table><thead><tr><th align="center">字段名</th><th align="center">解释</th></tr></thead><tbody><tr><td align="center">wid</td><td align="center">数字 + 字母格式的微博唯一标识，可与纯数字形式 id 互转，<a href=""></a></td></tr><tr><td align="center">publish_time</td><td align="center">发布时间</td></tr><tr><td align="center">content</td><td align="center">内容</td></tr><tr><td align="center">image_urls</td><td align="center">图片链接，以英文空格分隔多个图片链接</td></tr><tr><td align="center">weibo_link</td><td align="center">微博链接</td></tr><tr><td align="center">forward_num</td><td align="center">转发数</td></tr><tr><td align="center">comment_num</td><td align="center">评论数</td></tr><tr><td align="center">like_num</td><td align="center">点赞数</td></tr><tr><td align="center">is_origin</td><td align="center">是否是原创微博</td></tr><tr><td align="center">origin_img_urls</td><td align="center">被转发微博图片链接</td></tr></tbody></table><div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">    <iframe src="//player.bilibili.com/player.html?aid=806111483&bvid=BV1934y127ZM&cid=425810536&page=1"  scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"></iframe></div><h4 id="微博文章爬虫"><a href="#微博文章爬虫" class="headerlink" title="微博文章爬虫"></a>微博文章爬虫</h4><p>在微博上发布的内容有的短文本+图片（也就是微博），还有<strong>文章</strong>等形式，微博文章爬虫<strong>爬取用户的所有文章</strong>。有<strong>文章标题，id，内容，发布时间，阅读数，评论数，点赞数，图片链接</strong>等字段或信息。</p><p>针对 weibo.com 站点，代码地址在 <a href="https://github.com/Python3Spiders/WeiboSuperSpider/blob/master/%E6%97%A0%20GUI%20%E5%8A%9F%E8%83%BD%E7%8B%AC%E7%AB%8B%E7%89%88/WeiboComPostSpider.py">WeiboComPostSpider.py</a></p><p>cookie 获取及更多信息可以参考：<a href="https://mp.weixin.qq.com/s/2Amq-jaQPXgZluga_7kTdQ">爬取微博用户所有文章的爬虫</a></p><h4 id="用户信息爬虫"><a href="#用户信息爬虫" class="headerlink" title="用户信息爬虫"></a>用户信息爬虫</h4><p>微博用户信息爬虫指的是，根据微博用户 id，抓取用户的<strong>阳光信用、性别、地区、学校、公司等信息</strong>。</p><p>针对 weibo.com 站点，代码全部开源在 WeiboSuperSpider 的 github 仓库地址，功能独立版文件夹下，取名 <a href="https://github.com/Python3Spiders/WeiboSuperSpider/blob/master/%E6%97%A0%20GUI%20%E5%8A%9F%E8%83%BD%E7%8B%AC%E7%AB%8B%E7%89%88/WeiboUserInfoSpider.py">WeiboUserInfoSpider</a></p><p><strong>拿到代码后需要填一下 headers 里面的</strong> <strong>cookie</strong>，随便打开 weibo.com 站点里一个人的主页，比如</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://weibo.com/u/1764201374</span><br></pre></td></tr></table></figure><p>也可以是</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://weibo.com/xiena</span><br></pre></td></tr></table></figure><p>这种微博用户自定义形式，然后 F12 开始找 <strong>info</strong> 或者 <strong>detail</strong> 这两个 path 之一，复制它们的 cookie 即可。</p><p>有关该爬虫更多信息可以参考：<a href="https://mp.weixin.qq.com/s/8_1pyLs5XcA3h3lL6RXIvg">超级方便的微博用户信息爬虫</a></p><h4 id="用户搜索爬虫"><a href="#用户搜索爬虫" class="headerlink" title="用户搜索爬虫"></a>用户搜索爬虫</h4><p>微博用户信息爬虫是根据微博用户 Uid 来抓取公开的用户微博信息，但是很多时候，我们可能只知道这个用户的微博名字，并不知道 Uid，用户搜索爬虫就是完成从微博用户名到 Uid 的转换。</p><p>针对 weibo.com 站点，代码地址在 <a href="https://github.com/Python3Spiders/WeiboSuperSpider/blob/master/%E6%97%A0%20GUI%20%E5%8A%9F%E8%83%BD%E7%8B%AC%E7%AB%8B%E7%89%88/SearchUser.py">SearchUser.py</a></p><p>cookie 获取及更多信息可以参考：<a href="https://mp.weixin.qq.com/s/-ktBld4T_MyUiEF7sWfX5A">微博搜索用户爬虫</a></p><h3 id="话题关键词系列"><a href="#话题关键词系列" class="headerlink" title="话题关键词系列"></a>话题关键词系列</h3><p>首先必须搞清楚微博的关键词、话题、超话这三者的区别。</p><p>首先 <strong>#buyixiao#</strong> 这个就是话题， 而 <strong>buyixiao</strong> 是关键词；使用关键词可以同时搜到同名话题，话题却不能搜到同名关键词。</p><p>再者，在搜索时，关键词可能会被拆分，例如 <strong>北京暴雨</strong> 可能会搜索到包含 <strong>北京</strong> 或 <strong>暴雨</strong> 的微博，不仅可能没连在一起，还有可能只包含其中一个；而话题在搜索时不会被拆分~</p><p>话题和关键词区别明了，下面看 <a href="https://mp.weixin.qq.com/s/bfFa3BQPIdfo2aLlR9i0ng">关键词话题 和 超话的区别</a> 。</p><p>本爬虫只只能抓取关键词或话题（2022/03/08 更新，也支持抓取超话，只需要在 keyword 后面加个 <strong>超话</strong> 就能抓取超话微博了，<del>超话后续有精力再开发</del>）。抓取保存的结果 csv 文件字段格式如下：</p><table><thead><tr><th align="center">字段名</th><th align="center">解释</th></tr></thead><tbody><tr><td align="center">mid</td><td align="center">纯数字形式的微博唯一标识，可与字母+数字形式 id 互转</td></tr><tr><td align="center">publish_time</td><td align="center">发布时间</td></tr><tr><td align="center">user_name</td><td align="center">微博作者名</td></tr><tr><td align="center">user_link</td><td align="center">微博作者链接</td></tr><tr><td align="center">content</td><td align="center">内容</td></tr><tr><td align="center">image_urls</td><td align="center">图片链接</td></tr><tr><td align="center">weibo_link</td><td align="center">微博链接</td></tr><tr><td align="center">forward_num</td><td align="center">转发数</td></tr><tr><td align="center">comment_num</td><td align="center">评论数</td></tr><tr><td align="center">like_num</td><td align="center">点赞数</td></tr></tbody></table><p>针对 weibo.com 站点，pyd 或者 pyc 获取及相关配置过程在 <a href="https://mp.weixin.qq.com/s/eC391YSURN8BLV1Gcu0EJA">新版话题关键词爬虫发布</a> 。</p><div class="note info simple"><p>链接里相关配置流程可能更改，但是公众号文章无法多次修改，以最后获取的百度网盘链接里文件为准。</p></div><div class="note info simple"><p>在这里补充一点，如果需要设置多个关键词同时抓取，按照以下格式设置 keyword：</p><blockquote><p>“keyword”: “a b c”,</p></blockquote><p>实践证明，<strong>不需要空格</strong>也行，效果相同，爬的结果是多个关键词<strong>且</strong>的关系。</p><p>如果需要设置抓取 日本地震 或者 美国地震，可以将关键词设置为以下两种之一，结果是一样的：</p><blockquote><p>“keyword”: “(日本 or 美国) and 地震”</p></blockquote><p>或者</p><blockquote><p>“keyword”: “日本地震 or 美国地震”</p></blockquote></div><p>也可以参考视频教程：</p><div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">    <iframe src="//player.bilibili.com/player.html?aid=976177996&bvid=BV1A44y147PX&cid=427929738&page=1"  scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"></iframe></div><h3 id="转评赞系列"><a href="#转评赞系列" class="headerlink" title="转评赞系列"></a>转评赞系列</h3><p>针对指定微博的转发、评论和点赞信息抓取。</p><h4 id="评论爬虫"><a href="#评论爬虫" class="headerlink" title="评论爬虫"></a>评论爬虫</h4><p>评论数据尤为重要，先来讲讲评论抓取。</p><p>评论数据的抓取难度较大，针对一条 100w+ 评论的抓取，通常分为三个量级难度的抓取：0.1w、1w、10w。0.1w 指只能爬到几千条，10w 指的是能爬到几十万条。</p><p>本爬虫 针对 weibo.com ，能够保存的字段信息如下：</p><table><thead><tr><th align="center">字段名</th><th align="center">字段值</th></tr></thead><tbody><tr><td align="center">parent_comment_id</td><td align="center">父评论 id，为空说明该评论就是根评论</td></tr><tr><td align="center">comment_id</td><td align="center">评论 id</td></tr><tr><td align="center">comment_time</td><td align="center">评论时间</td></tr><tr><td align="center">comment_user_name</td><td align="center">评论者昵称</td></tr><tr><td align="center">comment_user_link</td><td align="center">评论者主页链接</td></tr><tr><td align="center">comment_content</td><td align="center">评论内容</td></tr><tr><td align="center">comment_like_num</td><td align="center">评论点赞数</td></tr><tr><td align="center">child_comment_num</td><td align="center">子评论数，为 0 说明该评论可能就是子评论</td></tr></tbody></table><p>抓取数据量在第二量级，单条100w+ 的评论能抓到 1w-10w，当然，如果评论总量只有 10w，抓不到 10w。pyd 或者 pyc 获取及相关配置过程在 <a href="https://mp.weixin.qq.com/s/t0S3u98HX62on3PGOnI78Q">新版评论爬虫发布</a> </p><div class="note info simple"><p>链接里相关配置流程可能更改，但是公众号文章无法多次修改，以最后获取的百度网盘链接里文件为准。</p></div><p>如果想要免费抓取最高量级的评论，可以参考 <a href="https://mp.weixin.qq.com/s/rc3S8lPyyz-tXf98CoXtLw">单机单账号抓取了单条微博的 100w+ 评论</a></p><h4 id="转发爬虫"><a href="#转发爬虫" class="headerlink" title="转发爬虫"></a>转发爬虫</h4><p>抓取指定微博的抓发信息，针对 weibo.com，抓取保存的字段如下：</p><table><thead><tr><th align="center">字段名</th><th align="center">解释</th></tr></thead><tbody><tr><td align="center">mid</td><td align="center">纯数字形式的微博唯一标识，可与字母+数字形式 id 互转</td></tr><tr><td align="center">publish_time</td><td align="center">发布时间</td></tr><tr><td align="center">user_name</td><td align="center">微博作者名</td></tr><tr><td align="center">user_link</td><td align="center">微博作者链接</td></tr><tr><td align="center">content</td><td align="center">内容</td></tr><tr><td align="center">weibo_link</td><td align="center">微博链接</td></tr><tr><td align="center">forward_num</td><td align="center">转发数</td></tr><tr><td align="center">like_num</td><td align="center">点赞数</td></tr></tbody></table><p>pyd 或者 pyc 获取及相关配置过程在 <a href="https://mp.weixin.qq.com/s/toPtFFFNKjyc5a4rrpBdwQ">新版转发爬虫发布</a> </p><div class="note info simple"><p>链接里相关配置流程可能更改，但是公众号文章无法多次修改，以最后获取的百度网盘链接里文件为准。</p></div><p>可以参考视频教程：</p><div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">    <iframe src="//player.bilibili.com/player.html?aid=976353795&bvid=BV1F44y1i7dq&cid=431462476&page=1"  scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"></iframe></div><h4 id="点赞爬虫"><a href="#点赞爬虫" class="headerlink" title="点赞爬虫"></a>点赞爬虫</h4><p>看名字以为是手动点赞机器人，其实只是抓取点赞信息信息。</p><p>针对 m.weibo.cn，只能抓到最新的几千条点赞信息。</p><p>代码地址在：<a href="https://github.com/Python3Spiders/WeiboSuperSpider/blob/master/%E6%97%A0%20GUI%20%E5%8A%9F%E8%83%BD%E7%8B%AC%E7%AB%8B%E7%89%88/WeiboLikeSpider.py">WeiboLikeSpider.py</a> 。</p><p>详细信息及配置过程可以参考：<a href="https://mp.weixin.qq.com/s/JITHQK7mVaCIu2s1nPnMnw">新版点赞爬虫</a> 。</p><h3 id="位置签到系列"><a href="#位置签到系列" class="headerlink" title="位置签到系列"></a>位置签到系列</h3><p>针对 weibo.com，微博位置签到爬虫，只能抓取到最新 1000 余条，比较稳定，不多赘述，直接查看：<a href="https://mp.weixin.qq.com/s/KYcXsrwmIDyGDz1-lPKXmw">新版位置签到爬虫</a> 。</p><div class="note warning simple"><p>2022 年 5 月更新，发布的位置签到爬虫 pyd 不稳定或者失效，需要抓取大量签到数据私聊合作。 </p></div><h3 id="超话系列"><a href="#超话系列" class="headerlink" title="超话系列"></a>超话系列</h3><p>1、抓取超话微博，同话题关键词系列，比如抓取李健超话，只需要将 keyword 设置为 <strong>李健超话</strong> 即可，其余配置一样。</p><p>2、针对 weibo.com，下载超话相册和抓取活跃粉丝，比较稳定，不多赘述，直接查看：<a href="https://mp.weixin.qq.com/s/bfFa3BQPIdfo2aLlR9i0ng">【开源】微博超话相册下载及超话活跃粉丝抓取</a> 。</p><h2 id="多功能集成爬虫"><a href="#多功能集成爬虫" class="headerlink" title="多功能集成爬虫"></a>多功能集成爬虫</h2><p>主要是针对上一步输出结果为微博信息，想要作为下一步或评论或转发输入的批量抓取，比如抓取一个微博话题下的所有评论，抓取一个用户发博的所有评论…以及其他 DIY 功能，FT 导向，本部分仍在活跃更新</p><h3 id="抓取话题下的所有评论"><a href="#抓取话题下的所有评论" class="headerlink" title="抓取话题下的所有评论"></a>抓取话题下的所有评论</h3><p>不只是话题，关键词也行，要求是输入为话题关键词爬虫的结果文件，输出为很多评论文件，也可合并之。</p><p>在上文所述[新版微博评论爬虫]中，只是针对单条微博的，如果是很多很多个微博需要爬评论，难道需要一个个输入 mid 和 uid 吗？考虑到这个问题，我特意写了个脚本，后，需要获取该话题下所有微博的评论，我们可以使用如下的 py 脚本代码自动构建视频中抓取评论所需要的 json 配置文件。</p><p>配套视频如下：</p><div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">    <iframe src="//player.bilibili.com/player.html?aid=336106792&bvid=BV13R4y1J7A7&cid=426114747&page=1"  scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"></iframe></div><p>构建评论批量抓取配置文件的脚本附在文末，<a href="https://buyixiao.github.io/blog/weibo-super-spider.html#%E7%94%9F%E6%88%90%E6%89%B9%E9%87%8F%E6%8A%93%E5%8F%96%E8%AF%84%E8%AE%BA%E7%9A%84-json-%E9%85%8D%E7%BD%AE%E4%BB%A3%E7%A0%81">点我直达</a></p><h3 id="抓取用户发布微博的所有评论"><a href="#抓取用户发布微博的所有评论" class="headerlink" title="抓取用户发布微博的所有评论"></a>抓取用户发布微博的所有评论</h3><p>可以直接参考视频：</p><div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">    <iframe src="//player.bilibili.com/player.html?aid=633890910&bvid=BV1zb4y1b7jV&cid=433966101&page=1"  scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"></iframe></div><h3 id="批量抓取转评赞"><a href="#批量抓取转评赞" class="headerlink" title="批量抓取转评赞"></a>批量抓取转评赞</h3><p>待更新…</p><h3 id="加字段"><a href="#加字段" class="headerlink" title="加字段"></a>加字段</h3><p>给一些 csv 加上学校，地区，性别等字段，总的来说还是需要上文 <a href="https://buyixiao.github.io/blog/weibo-super-spider.html#%E7%94%A8%E6%88%B7%E4%BF%A1%E6%81%AF%E7%88%AC%E8%99%AB">用户信息爬虫</a>，待更新。</p><h3 id="下载图片"><a href="#下载图片" class="headerlink" title="下载图片"></a>下载图片</h3><p>就是说，爬虫结果文件里面的图片链接怎么下载到本地，代码贴在文末，<a href="https://buyixiao.github.io/blog/weibo-super-spider.html#%E4%B8%8B%E8%BD%BD%E5%9B%BE%E7%89%87%E4%BB%A3%E7%A0%81">点我直达</a></p><h2 id="微博自助抓取网站"><a href="#微博自助抓取网站" class="headerlink" title="微博自助抓取网站"></a>微博自助抓取网站</h2><p>站点地址：<a href="https://weibo-crawl-visual.buyixiao.xyz/">https://weibo-crawl-visual.buyixiao.xyz/</a></p><p>具体介绍，见诸公众号文章合集：<a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzUzMDE5MzQ3Ng==&action=getalbum&album_id=2441746336438894594&scene=173&from_msgid=2247485809&from_itemidx=1&count=3&nolastread=1#wechat_redirect">#微博自助抓取网站</a></p><h2 id="数据分析及可视化相关"><a href="#数据分析及可视化相关" class="headerlink" title="数据分析及可视化相关"></a>数据分析及可视化相关</h2><p>可定制、一站式微博分析及可视化平台：<a href="http://buyixiao.xyz/">WB_VIS</a></p><p>中国-省-市可钻入钻出地图、世界地图、动态排序柱状图、桑基图、旭日图、关系图、树图、矩形树图、弦图等类型图表在线生成工具：<a href="https://tools.buyixiao.xyz/">https://tools.buyixiao.xyz/</a> ，可上传数据，在线编辑生成图表下载~</p><h3 id="微博评论情感分析"><a href="#微博评论情感分析" class="headerlink" title="微博评论情感分析"></a>微博评论情感分析</h3><p><code>pip install snownlp</code>；然后文末的代码随取随用：<a href="https://buyixiao.github.io/blog/weibo-super-spider.html#%E8%AF%84%E8%AE%BA%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E4%BB%A3%E7%A0%81">点我直达</a></p><h3 id="LDA"><a href="#LDA" class="headerlink" title="LDA"></a>LDA</h3><p>代码附在文末，<a href="https://buyixiao.github.io/blog/weibo-super-spider.html#LDA%20%E4%BB%A3%E7%A0%81">点我直达</a> , 自行百度相关包安装过程，可能比较麻烦</p><h3 id="时间序列可视化"><a href="#时间序列可视化" class="headerlink" title="时间序列可视化"></a>时间序列可视化</h3><p><a href="https://buyixiao.github.io/blog/weibo-super-spider.html#%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%8F%AF%E8%A7%86%E5%8C%96%E4%BB%A3%E7%A0%81">直达文末代码</a></p><h2 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h2><h3 id="为什么不做一个系统"><a href="#为什么不做一个系统" class="headerlink" title="为什么不做一个系统"></a>为什么不做一个系统</h3><p>以前尝试做过一个 GUI 系统，所有功能点击即可，后来微博改版，流程全部失效了，维护成本巨大，所以只关注基本功能。</p><h3 id="为什么有些-pyd-pyc-是付费的"><a href="#为什么有些-pyd-pyc-是付费的" class="headerlink" title="为什么有些 pyd/pyc 是付费的"></a>为什么有些 pyd/pyc 是付费的</h3><p>博主大厂全职，维护这个项目三年多，至少花费了我几百个小时的业余时间，为此熬过不少夜，废过不少食。所有设置了一些付费文章，3~9 块不等，算是对项目持续维护的激励，不是为文件付费，知悉。</p><h3 id="遇到错误怎么办"><a href="#遇到错误怎么办" class="headerlink" title="遇到错误怎么办"></a>遇到错误怎么办</h3><p><del>可以先查看下方的 <a href="https://docs.qq.com/doc/DZGhYc0ZpcnB4TFVj">常见错误汇总</a></del>（已从 qq docs 迁移至本文），没有找到答案的可以在本文文末评论。</p><h4 id="使用-pyc-时的-Python-版本必须是-Python3-6-6-64-bit"><a href="#使用-pyc-时的-Python-版本必须是-Python3-6-6-64-bit" class="headerlink" title="使用 pyc 时的 Python 版本必须是 Python3.6.6 64 bit"></a>使用 pyc 时的 Python 版本必须是 Python3.6.6 64 bit</h4><p>运行报错 <code>ImportError: bad magic number</code>，切换到 Python 3.6.6 64 bit 即可，Python 可以多版本共存，无需卸载当前 Python，多版本时，请确保你当前 Pycharm 使用的是 3.6.6 64 bit，有关于此的任何疑问，可以查询此文：<a href="https://buyixiao.github.io/blog/pip-install-success-import-fail.html#cmd-%E5%92%8C-Pycharm-%E6%8D%A2%E6%BA%90">Python 多版本共存问题</a></p><h4 id="没有关闭-VPN"><a href="#没有关闭-VPN" class="headerlink" title="没有关闭 VPN"></a>没有关闭 VPN</h4><p>运行报错 <code>requests.exceptions.SSLExcption</code>，关闭 vpn 即可。</p><h4 id="json-文件配置错误"><a href="#json-文件配置错误" class="headerlink" title="json 文件配置错误"></a>json 文件配置错误</h4><p>如果运行报错类似 <code>json.decoder.JSONDecodeError: Expecting &#39;:&#39; delimiter: line 3 column 19 (char 843)</code>，原因是 json 文件你修改时把冒号逗号引号之类的分隔符搞丢了。</p><p>如果复制 cookie 到 json 文件里时有一些双引号造成 loadConfig 错误，那是因为复制 cookie 的时候右键选择 复制 而不是 copy value。</p><h4 id="Pycharm-看不到-pyc-文件"><a href="#Pycharm-看不到-pyc-文件" class="headerlink" title="Pycharm 看不到 pyc 文件"></a>Pycharm 看不到 pyc 文件</h4><p>这不是问题，正常，pycharm 默认不会索引显示 pyc 文件。</p><h4 id="运行-id-转化-Unable-to-locate-a-Java-Runtime"><a href="#运行-id-转化-Unable-to-locate-a-Java-Runtime" class="headerlink" title="运行 id 转化 Unable to locate a Java Runtime"></a>运行 id 转化 Unable to locate a Java Runtime</h4><p>这是因为 pyexecjs 库需要 jdk，如果你电脑之前没配置过 java 环境的话，google 百度搜索 jdk配置教程配置一个即可。</p><h4 id="话题爬虫问题汇总"><a href="#话题爬虫问题汇总" class="headerlink" title="话题爬虫问题汇总"></a>话题爬虫问题汇总</h4><p><a href="https://docs.qq.com/doc/DZGhYc0ZpcnB4TFVj">原始文档</a></p><p>问题陈列如下：</p><ol><li>topic_config.json 文件设置注意点，<strong>小时前不用补足 0，月份和天前需要补足 0，注意单双引号，invalid character等</strong></li><li>为什么爬了，但是只能爬几十条？</li><li>爬取显示 data is none?</li><li>bad magic number</li><li>缺少字段 only_origin</li></ol><p>以上这些问题在 <a href="https://docs.qq.com/doc/DZGhYc0ZpcnB4TFVj">原始文档</a> 中都有详细解释。</p><h4 id="只想爬根评论"><a href="#只想爬根评论" class="headerlink" title="只想爬根评论"></a>只想爬根评论</h4><p>把 json 配置中的 child_max_page 设置为 0 即可。</p><h4 id="评论总是爬不全"><a href="#评论总是爬不全" class="headerlink" title="评论总是爬不全"></a>评论总是爬不全</h4><p>以微博 <a href="https://weibo.com/1934183965/LqvYeCdBu">https://weibo.com/1934183965/LqvYeCdBu</a> 为例子，显示有 3w 条，实际上只能抓到几百条，有以下几个原因：</p><p>1、这条微博可能开启了评论精选，博主只选出了几百条，不信的话，去 weibo.com 或者手机上手动浏览下，你会发现只能看到几百条，去 weibo.cn 可能一条都看不到。</p><p>2、微博数据水分，互联网大厂常规操作，在此不做过多解释。</p><h4 id="转发总是爬不全"><a href="#转发总是爬不全" class="headerlink" title="转发总是爬不全"></a>转发总是爬不全</h4><p>道理同上。</p><h2 id="附录代码"><a href="#附录代码" class="headerlink" title="附录代码"></a>附录代码</h2><h3 id="微博两种-id-相互转化代码"><a href="#微博两种-id-相互转化代码" class="headerlink" title="微博两种 id 相互转化代码"></a>微博两种 id 相互转化代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># author:           inspurer(月小水长)</span></span><br><span class="line"><span class="comment"># create_time:      2021/7/6 22:19</span></span><br><span class="line"><span class="comment"># 运行环境           Python3.6+</span></span><br><span class="line"><span class="comment"># github            https://github.com/inspurer</span></span><br><span class="line"><span class="comment"># 微信公众号         月小水长</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> execjs</span><br><span class="line">jspython = <span class="string">&#x27;&#x27;&#x27;str62keys = &quot;0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ&quot;;</span></span><br><span class="line"><span class="string">/**</span></span><br><span class="line"><span class="string">* 10进制值转换为62进制</span></span><br><span class="line"><span class="string">* @param &#123;String&#125; int10 10进制值</span></span><br><span class="line"><span class="string">* @return &#123;String&#125; 62进制值</span></span><br><span class="line"><span class="string">*/</span></span><br><span class="line"><span class="string">function int10to62(int10) &#123;</span></span><br><span class="line"><span class="string">    var s62 = &#x27;&#x27;;</span></span><br><span class="line"><span class="string">    var r = 0;</span></span><br><span class="line"><span class="string">    while (int10 != 0) &#123;</span></span><br><span class="line"><span class="string">            r = int10 % 62;</span></span><br><span class="line"><span class="string">            s62 = this.str62keys.charAt(r) + s62;</span></span><br><span class="line"><span class="string">            int10 = Math.floor(int10 / 62);</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    return s62;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">/**</span></span><br><span class="line"><span class="string">* 62进制值转换为10进制</span></span><br><span class="line"><span class="string">* @param &#123;String&#125; str62 62进制值</span></span><br><span class="line"><span class="string">* @return &#123;String&#125; 10进制值</span></span><br><span class="line"><span class="string">*/</span></span><br><span class="line"><span class="string">function str62to10(str62) &#123;</span></span><br><span class="line"><span class="string">    var i10 = 0;</span></span><br><span class="line"><span class="string">    for (var i = 0; i &lt; str62.length; i++) &#123;</span></span><br><span class="line"><span class="string">            var n = str62.length - i - 1;</span></span><br><span class="line"><span class="string">            var s = str62.substr(i, 1);  // str62[i]; 字符串用数组方式获取，IE下不支持为“undefined”</span></span><br><span class="line"><span class="string">            i10 += parseInt(str62keys.indexOf(s)) * Math.pow(62, n);</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    return i10;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">/**</span></span><br><span class="line"><span class="string">* id转换为mid</span></span><br><span class="line"><span class="string">* @param &#123;String&#125; id 微博id，如 &quot;201110410216293360&quot;</span></span><br><span class="line"><span class="string">* @return &#123;String&#125; 微博mid，如 &quot;wr4mOFqpbO&quot;</span></span><br><span class="line"><span class="string">*/</span></span><br><span class="line"><span class="string">function id2mid(id) &#123;</span></span><br><span class="line"><span class="string">    if (typeof (id) != &#x27;string&#x27;) &#123;</span></span><br><span class="line"><span class="string">            return false; // id数值较大，必须为字符串！</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    var mid = &#x27;&#x27;;</span></span><br><span class="line"><span class="string">    for (var i = id.length - 7; i &gt; -7; i = i - 7) //从最后往前以7字节为一组读取mid</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">            var offset1 = i &lt; 0 ? 0 : i;</span></span><br><span class="line"><span class="string">            var offset2 = i + 7;</span></span><br><span class="line"><span class="string">            var num = id.substring(offset1, offset2);</span></span><br><span class="line"><span class="string">            num = int10to62(num);</span></span><br><span class="line"><span class="string">            mid = num + mid;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    return mid;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">/**</span></span><br><span class="line"><span class="string">* mid转换为id</span></span><br><span class="line"><span class="string">* @param &#123;String&#125; mid 微博mid，如 &quot;wr4mOFqpbO&quot;</span></span><br><span class="line"><span class="string">* @return &#123;String&#125; 微博id，如 &quot;201110410216293360&quot;</span></span><br><span class="line"><span class="string">*/</span></span><br><span class="line"><span class="string">function mid2id(mid) &#123;</span></span><br><span class="line"><span class="string">    var id = &#x27;&#x27;;</span></span><br><span class="line"><span class="string">    for (var i = mid.length - 4; i &gt; -4; i = i - 4) //从最后往前以4字节为一组读取mid字符</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">            var offset1 = i &lt; 0 ? 0 : i;</span></span><br><span class="line"><span class="string">            var len = i &lt; 0 ? parseInt(mid.length % 4) : 4;</span></span><br><span class="line"><span class="string">            var str = mid.substr(offset1, len);</span></span><br><span class="line"><span class="string">            str = str62to10(str).toString();</span></span><br><span class="line"><span class="string">            if (offset1 &gt; 0) //若不是第一组，则不足7位补0</span></span><br><span class="line"><span class="string">            &#123;</span></span><br><span class="line"><span class="string">                    while (str.length &lt; 7) &#123;</span></span><br><span class="line"><span class="string">                            str = &#x27;0&#x27; + str;</span></span><br><span class="line"><span class="string">                    &#125;</span></span><br><span class="line"><span class="string">            &#125;</span></span><br><span class="line"><span class="string">            id = str + id;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    return id;</span></span><br><span class="line"><span class="string">&#125;&#x27;&#x27;&#x27;</span></span><br><span class="line">ctx = execjs.<span class="built_in">compile</span>(jspython) <span class="comment"># 编译 js</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mid2id</span>(<span class="params">mid</span>):</span></span><br><span class="line">    <span class="keyword">return</span> ctx.call(<span class="string">&#x27;mid2id&#x27;</span>, mid)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">id2mid</span>(<span class="params"><span class="built_in">id</span></span>):</span></span><br><span class="line">    <span class="keyword">return</span> ctx.call(<span class="string">&#x27;id2mid&#x27;</span>, <span class="built_in">id</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">global</span> mid</span><br><span class="line">    mid = <span class="string">&#x27;L8J4vC6m7&#x27;</span></span><br><span class="line">    <span class="built_in">id</span> = mid2id(mid)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">id</span>)</span><br><span class="line">    <span class="built_in">id</span> = <span class="string">&#x27;4655725672138197&#x27;</span></span><br><span class="line">    mid = id2mid(<span class="built_in">id</span>)</span><br><span class="line">    <span class="built_in">print</span>(mid)</span><br></pre></td></tr></table></figure><h3 id="下载图片代码"><a href="#下载图片代码" class="headerlink" title="下载图片代码"></a>下载图片代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># author:           inspurer(月小水长)</span></span><br><span class="line"><span class="comment"># create_time:      2021/11/2 20:48</span></span><br><span class="line"><span class="comment"># 运行环境           Python3.6+</span></span><br><span class="line"><span class="comment"># github            https://github.com/inspurer</span></span><br><span class="line"><span class="comment"># 微信公众号         月小水长</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;易烊千玺V公益 - 文本.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">image_folder = <span class="string">&#x27;image&#x27;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(image_folder):</span><br><span class="line">    os.mkdir(image_folder)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;authority&#x27;</span>: <span class="string">&#x27;weibo.com&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;x-requested-with&#x27;</span>: <span class="string">&#x27;XMLHttpRequest&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sec-ch-ua-mobile&#x27;</span>: <span class="string">&#x27;?0&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;content-type&#x27;</span>: <span class="string">&#x27;application/x-www-form-urlencoded&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;accept&#x27;</span>: <span class="string">&#x27;*/*&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sec-fetch-site&#x27;</span>: <span class="string">&#x27;same-origin&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sec-fetch-mode&#x27;</span>: <span class="string">&#x27;cors&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sec-fetch-dest&#x27;</span>: <span class="string">&#x27;empty&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;referer&#x27;</span>: <span class="string">&#x27;https://weibo.com/1192329374/KnnG78Yf3?filter=hot&amp;root_comment_id=0&amp;type=comment&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;accept-language&#x27;</span>: <span class="string">&#x27;zh-CN,zh;q=0.9,en-CN;q=0.8,en;q=0.7,es-MX;q=0.6,es;q=0.5&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;cookie&#x27;</span>: <span class="string">&#x27;weibo.com 登录后随便哪一个接口的 cookie&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> index, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;index: <span class="subst">&#123;index + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;df.shape[<span class="number">0</span>]&#125;</span>&#x27;</span>)</span><br><span class="line">    image_urls = row[<span class="string">&#x27;img_urls&#x27;</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">type</span>(image_urls) <span class="keyword">is</span> <span class="built_in">float</span> <span class="keyword">and</span> <span class="built_in">len</span>(image_urls) &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">if</span> image_urls == <span class="string">&#x27;无&#x27;</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;无&#x27;</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        image_url_list = image_urls.split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> image_url <span class="keyword">in</span> image_url_list:</span><br><span class="line">            <span class="built_in">print</span>(image_url)</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;?&quot;</span> <span class="keyword">in</span> image_url:</span><br><span class="line">                image_url = image_url[:image_url.rindex(<span class="string">&quot;?&quot;</span>)]</span><br><span class="line">            image_spilt = image_url.rsplit(<span class="string">&#x27;.&#x27;</span>, <span class="number">1</span>)</span><br><span class="line">            image_path = os.path.join(image_folder,</span><br><span class="line">                                      <span class="string">&#x27;&#123;&#125;.&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(hashlib.md5(image_spilt[<span class="number">0</span>].encode(<span class="string">&#x27;utf-8&#x27;</span>)).hexdigest(),</span><br><span class="line">                                                     image_spilt[<span class="number">1</span>]))</span><br><span class="line">            <span class="keyword">if</span> os.path.exists(image_path):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(image_path, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">                response = requests.get(url=image_url, headers=headers)</span><br><span class="line">                fp.write(response.content)</span><br></pre></td></tr></table></figure><h3 id="生成批量抓取评论的-json-配置代码"><a href="#生成批量抓取评论的-json-配置代码" class="headerlink" title="生成批量抓取评论的 json 配置代码"></a>生成批量抓取评论的 json 配置代码</h3><p>注意这份代码需要根据 <a href="https://buyixiao.github.io/blog/weibo-super-spider.html#%E8%AF%9D%E9%A2%98%E5%85%B3%E9%94%AE%E8%AF%8D%E7%B3%BB%E5%88%97">话题爬虫</a>（或者用户爬虫）的结果 CSV 作为前置条件，体现在代码的 data_path 这个变量处，注意修改成你电脑上结果 CSV 文件的真实路径~</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># author:           inspurer(月小水长)</span></span><br><span class="line"><span class="comment"># create_time:      2022/01/17 10:31</span></span><br><span class="line"><span class="comment"># 运行环境           Python3.6+</span></span><br><span class="line"><span class="comment"># github            https://github.com/inspurer</span></span><br><span class="line"><span class="comment"># 微信公众号         月小水长</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">limit = <span class="number">100000</span></span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line">config_path = <span class="string">&#x27;topic_comment_config.json&#x27;</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(config_path, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8-sig&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    config_json = json.loads(f.read())</span><br><span class="line">data_path = <span class="string">f&#x27;./topic/<span class="subst">&#123;config_json[<span class="string">&quot;keyword&quot;</span>]&#125;</span>.csv&#x27;</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">drop_duplicate</span>(<span class="params">path, col=<span class="string">&quot;mid&quot;</span></span>):</span></span><br><span class="line">    df = pd.read_csv(path)</span><br><span class="line">    <span class="comment"># 去除重复行数据</span></span><br><span class="line">    df.drop_duplicates(keep=<span class="string">&#x27;first&#x27;</span>, inplace=<span class="literal">True</span>, subset=[col])</span><br><span class="line">    <span class="comment"># 可能还剩下重复 header</span></span><br><span class="line">    df = df[-df[col].isin([col])]</span><br><span class="line">    df.to_csv(path, encoding=<span class="string">&#x27;utf-8-sig&#x27;</span>, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    drop_duplicate(data_path)</span><br><span class="line"></span><br><span class="line">    df = pd.read_csv(data_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 清除原有的 comments 配置，如不需要可注释</span></span><br><span class="line">    config_json[<span class="string">&#x27;comments&#x27;</span>].clear()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;index + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;df.shape[<span class="number">0</span>]&#125;</span>&#x27;</span>)</span><br><span class="line">        comment_num = row[<span class="string">&#x27;comment_num&#x27;</span>]</span><br><span class="line">        weibo_link = row[<span class="string">&#x27;weibo_link&#x27;</span>]</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            comment_num = <span class="built_in">int</span>(comment_num)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            comment_num = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> comment_num &lt;= <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;\n\n <span class="subst">&#123;weibo_link&#125;</span> 没有评论，不加入配置 json \n\n&#x27;</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;?&#x27;</span> <span class="keyword">in</span> weibo_link:</span><br><span class="line">            weibo_link = weibo_link[:weibo_link.index(<span class="string">&#x27;?&#x27;</span>)]</span><br><span class="line">        uid = weibo_link[weibo_link.index(<span class="string">&#x27;com&#x27;</span>) + <span class="number">4</span>:weibo_link.rindex(<span class="string">&#x27;/&#x27;</span>)]</span><br><span class="line">        mid = weibo_link[weibo_link.rindex(<span class="string">&#x27;/&#x27;</span>) + <span class="number">1</span>:]</span><br><span class="line">        config_json[<span class="string">&#x27;comments&#x27;</span>].append(&#123;</span><br><span class="line">            <span class="string">&#x27;index&#x27;</span>: <span class="string">f&#x27;N<span class="subst">&#123;<span class="built_in">len</span>(config_json[<span class="string">&quot;comments&quot;</span>])&#125;</span>&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;mid&#x27;</span>: mid,</span><br><span class="line">            <span class="string">&#x27;uid&#x27;</span>: uid,</span><br><span class="line">            <span class="string">&#x27;limit&#x27;</span>: limit,</span><br><span class="line">            <span class="string">&#x27;user_name&#x27;</span>: row[<span class="string">&#x27;user_name&#x27;</span>]</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">    config_json[<span class="string">&#x27;comments_pos&#x27;</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n\n\n 共计 <span class="subst">&#123;<span class="built_in">len</span>(config_json[<span class="string">&#x27;comments&#x27;</span>])&#125;</span> 条微博加入评论抓取队列...  \n\n\n&quot;</span>)</span><br><span class="line">    sleep(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(config_path, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8-sig&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(json.dumps(config_json, indent=<span class="number">2</span>, ensure_ascii=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>上述代码所需 topic_comment_config.json 文件格式如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;cookie&quot;</span>: <span class="string">&quot;话题或评论的cookie&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;keyword&quot;</span>: <span class="string">&quot;云南象2.6&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;start_time&quot;</span>: <span class="string">&quot;2020-01-25-15&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;end_time&quot;</span>: <span class="string">&quot;2020-01-25-17&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;only_origin&quot;</span>: <span class="literal">false</span>,</span><br><span class="line">  <span class="attr">&quot;comments&quot;</span>: []</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="评论情感分析代码"><a href="#评论情感分析代码" class="headerlink" title="评论情感分析代码"></a>评论情感分析代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># author:           inspurer(月小水长)</span></span><br><span class="line"><span class="comment"># create_time:      2021/11/2 9:50</span></span><br><span class="line"><span class="comment"># 运行环境           Python3.6+</span></span><br><span class="line"><span class="comment"># github            https://github.com/inspurer</span></span><br><span class="line"><span class="comment"># 微信公众号         月小水长</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">filter_html</span>(<span class="params">text</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(text) == <span class="number">0</span> <span class="keyword">or</span> text == <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line">    <span class="comment"># text为包含html标签内容</span></span><br><span class="line">    content = re.sub(<span class="string">&quot;&lt;[^&gt;]*?&gt;&quot;</span>, <span class="string">&quot;&quot;</span>, text)</span><br><span class="line">    <span class="keyword">return</span> content</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> snownlp <span class="keyword">import</span> SnowNLP</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sentiment_score</span>(<span class="params">input_file, text_col = <span class="string">&#x27;text&#x27;</span></span>):</span></span><br><span class="line">    df = pd.read_csv(input_file)</span><br><span class="line">    sentiment_score_col = <span class="string">&#x27;sentiment_score&#x27;</span></span><br><span class="line">    is_scored_col = <span class="string">&#x27;has_scored&#x27;</span></span><br><span class="line">    df[is_scored_col] = [<span class="literal">False</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(df.shape[<span class="number">0</span>])]</span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;index + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;df.shape[<span class="number">0</span>]&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> row[is_scored_col] == <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        text = row[text_col]</span><br><span class="line">        <span class="comment"># 去除 html 标签</span></span><br><span class="line">        text = filter_html(text)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(text) == <span class="number">0</span> <span class="keyword">or</span> text == <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 本行没有文本</span></span><br><span class="line">            sentiment = -<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            sentiment = SnowNLP(text).sentiments</span><br><span class="line"></span><br><span class="line">        df.loc[index, sentiment_score_col] = sentiment</span><br><span class="line">        df.loc[index, is_scored_col] = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    df.to_csv(input_file, index=<span class="literal">False</span>, encoding=<span class="string">&#x27;utf-8-sig&#x27;</span>)</span><br><span class="line">sentiment_score(<span class="string">&quot;待分析的.csv&quot;</span>,text_col=<span class="string">&#x27;文本所在 csv 的列名&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="LDA-代码"><a href="#LDA-代码" class="headerlink" title="LDA 代码"></a>LDA 代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># author:           inspurer(月小水长)</span></span><br><span class="line"><span class="comment"># pc_type           lenovo</span></span><br><span class="line"><span class="comment"># create_time:      2020/9/20 13:35</span></span><br><span class="line"><span class="comment"># file_name:        main.py</span></span><br><span class="line"><span class="comment"># github            https://github.com/inspurer</span></span><br><span class="line"><span class="comment"># qq邮箱            2391527690@qq.com</span></span><br><span class="line"><span class="comment"># 微信公众号         月小水长(ID: inspurer)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> LatentDirichletAllocation</span><br><span class="line"><span class="keyword">import</span> pyLDAvis.sklearn</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">doLDA</span>(<span class="params">content, n_features=<span class="number">1000</span>, n_topics=<span class="number">5</span>, max_df=<span class="number">5</span>, min_df=<span class="number">1</span></span>):</span></span><br><span class="line">    <span class="comment"># 向量化</span></span><br><span class="line">    n_features = n_features</span><br><span class="line"></span><br><span class="line">    tf_vectorizer = CountVectorizer(strip_accents=<span class="string">&#x27;unicode&#x27;</span>,</span><br><span class="line">                                    max_features=n_features,</span><br><span class="line">                                    stop_words=<span class="string">&#x27;english&#x27;</span>,</span><br><span class="line">                                    max_df=max_df,</span><br><span class="line">                                    min_df=min_df)</span><br><span class="line">    tf = tf_vectorizer.fit_transform(content)</span><br><span class="line"></span><br><span class="line">    n_topics = n_topics</span><br><span class="line">    <span class="comment"># LDA 处理</span></span><br><span class="line">    lda = LatentDirichletAllocation(n_components=n_topics, max_iter=<span class="number">50</span>,</span><br><span class="line">                                    learning_method=<span class="string">&#x27;online&#x27;</span>,</span><br><span class="line">                                    learning_offset=<span class="number">50.</span>,</span><br><span class="line">                                    random_state=<span class="number">0</span>)</span><br><span class="line">    lda.fit(tf)</span><br><span class="line"></span><br><span class="line">    data = pyLDAvis.sklearn.prepare(lda, tf, tf_vectorizer)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(data)</span><br><span class="line">    pyLDAvis.show(data)  <span class="comment"># 可视化主题模型</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    df = pd.read_csv(<span class="string">&#x27;comments.csv&#x27;</span>)</span><br><span class="line">    doLDA(content=df[<span class="string">&#x27;content&#x27;</span>].values.tolist(),n_topics=<span class="number">2</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><font color="red">如果没有运行报错，但是出不来图，是因为需要挂 vpn。</font></p><h3 id="时间序列可视化代码"><a href="#时间序列可视化代码" class="headerlink" title="时间序列可视化代码"></a>时间序列可视化代码</h3><p>可以使用配套的微博可视化网站：<a href="http://weibo.buyixiao.xyz/">定制可视化</a></p><h2 id="后话"><a href="#后话" class="headerlink" title="后话"></a>后话</h2><p>本文首发： <a href="https://buyixiao.github.io/blog/weibo-super-spider.html">BuyiXiao’s Blog</a></p><p>链接地址：<a href="https://buyixiao.github.io/blog/weibo-super-spider.html">https://buyixiao.github.io/blog/weibo-super-spider.html</a></p><p>转载需注明来源。</p><p>如本项目对你有很多帮助，可以点击下方打赏赞助我持续维护。或者使用爱发电：<a href="https://afdian.net/@buyixiao">https://afdian.net/@buyixiao</a></p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> weibosuperspider </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> 用户微博 </tag>
            
            <tag> 微博评论 </tag>
            
            <tag> 微博转发 </tag>
            
            <tag> 微博点赞 </tag>
            
            <tag> 微博签到 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【持续更新 | 2022最新】基于 hexo 的 butterfly 优化教程</title>
      <link href="/blog/butterfly-beauty-quick-start.html"/>
      <url>/blog/butterfly-beauty-quick-start.html</url>
      
        <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>博主 2018/06/07 配置了一个基于 hexo + next 的博客：<a href="https://inspurer.github.io/">月小水长的个人博客</a>，维护几年有余后，源码或配置暂时丢失，于 2022/01/16 新开了 <a href="https://buyixiao.github.io/">BuyiXiao’s Blog</a> ，算是新的博客旅程，兴许日后会在 <a href="https://inspurer.github.io/">月小水长的个人博客</a> 继续更新…</p><p>本站点基于 hexo 6.0 + butterfly 4.0.1，本文记述了新博客配置过程的点点滴滴，就如文章摘要所述，<strong>不是臃肿的流水教程，但是小而精的查漏补缺，以及记录常见易错点</strong>。有问题欢迎留言</p><h2 id="hexo-基础配置及-butterfly-基础美化"><a href="#hexo-基础配置及-butterfly-基础美化" class="headerlink" title="hexo 基础配置及 butterfly 基础美化"></a>hexo 基础配置及 butterfly 基础美化</h2><h3 id="官方-quick-start"><a href="#官方-quick-start" class="headerlink" title="官方 quick-start"></a>官方 quick-start</h3><p>博主第一次搭建博客时，收藏了很多 hexo + next 的教程，但是由于站点或主题的不断迭代升级，很多教程都失效了，所以建议基础部分直接看官方最新的教程。</p><div class="note default modern"><p><a href="https://hexo.io/docs/">hexo 框架官方文档</a></p></div><div class="note success simple"><p><a href="https://butterfly.js.org/">butterfly 主题官方教程</a></p></div><h3 id="hexo-常见命令"><a href="#hexo-常见命令" class="headerlink" title="hexo 常见命令"></a>hexo 常见命令</h3><p>1、 hexo init</p><p>创建一个 buyixiao 文件夹并初始化为 hexo 目录</p><blockquote><p>hexo init buyixiao<br>cd buyixiao</p></blockquote><p>2、hexo generate<br>hexo generate 命令用于生成静态文件，一般可以简写为 hexo g</p><blockquote><p>-d 选项，指定生成后部署，与 hexo d -g 等价</p></blockquote><p>3、hexo server<br>hexo server 命令用于启动本地服务器，一般可以简写为 hexo s</p><blockquote><p>-p 选项，指定服务器端口，默认为 4000</p></blockquote><blockquote><p>-i 选项，指定服务器 IP 地址，默认为 0.0.0.0</p></blockquote><blockquote><p>-s 选项，静态模式 ，仅提供 public 文件夹中的文件并禁用文件监视</p></blockquote><p>本地运行服务器前需要安装 hexo-server 插件</p><blockquote><p>npm install hexo-server –save</p></blockquote><p>4、hexo deploy<br>hexo deploy 命令用于部署网站，一般可以简写为 hexo d</p><blockquote><p>-g 选项，指定生成后部署，与 hexo g -d 等价</p></blockquote><p>5、hexo clean<br>hexo clean 命令用于清理缓存文件，是一个比较常用的命令</p><p>6、hexo –safe<br>hexo –safe 表示安全模式，用于禁用加载插件和脚本</p><p>7、hexo 新建文章</p><blockquote><p>hexo new “这里填入文章的标题”</p></blockquote><h2 id="一些-Tips"><a href="#一些-Tips" class="headerlink" title="一些 Tips"></a>一些 Tips</h2><h3 id="valine-的-placeholder-和-requiredFields-无效"><a href="#valine-的-placeholder-和-requiredFields-无效" class="headerlink" title="valine 的 placeholder 和 requiredFields 无效"></a>valine 的 placeholder 和 requiredFields 无效</h3><div class="note success simple"><p>应该是看了很早的教程，最新的 butterfly 这两个字段应该放在 option 下一级而不是和  option 平级。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">option:</span></span><br><span class="line">  <span class="attr">placeholder:</span> <span class="string">send</span> <span class="string">from</span> <span class="string">buyixiao&#x27;s</span> <span class="string">blog</span></span><br><span class="line">  <span class="attr">requiredFields:</span> [<span class="string">&#x27;nick&#x27;</span>,<span class="string">&#x27;mail&#x27;</span>]</span><br></pre></td></tr></table></figure></div><h3 id="删除-valine-垃圾评论"><a href="#删除-valine-垃圾评论" class="headerlink" title="删除 valine 垃圾评论"></a>删除 valine 垃圾评论</h3><div class="note success simple"><p>很简单，直接去 LeanCloud 后台数据库界面删除对应评论即可。</p></div><h3 id="删除文章"><a href="#删除文章" class="headerlink" title="删除文章"></a>删除文章</h3><div class="note success simple"><p>很简单，直接去站点根目录 <code>source/_posts</code> 文件夹中删除文章 md 再 再 <code>hexo clean</code> &amp;<code>hexo g -d</code>。</p></div><h3 id="文章配置多个-tag"><a href="#文章配置多个-tag" class="headerlink" title="文章配置多个 tag"></a>文章配置多个 tag</h3><div class="note success simple"><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">tags:</span> [<span class="string">butterfly</span>,<span class="string">hexo</span>,<span class="string">beauty</span>]</span><br></pre></td></tr></table></figure><p>或者</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">tags:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">butterfly</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">hexo</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">beauty</span></span><br></pre></td></tr></table></figure></div><h3 id="文章自定义-url"><a href="#文章自定义-url" class="headerlink" title="文章自定义 url"></a>文章自定义 url</h3><p>如何像 <a href="https://buyixiao.github.io/blog/butterfly-beauty-quick-start.html">https://buyixiao.github.io/blog/butterfly-beauty-quick-start.html</a> 一样，加一个前缀 blog？</p><div class="note success simple"><p>在 站点配置文件中搜 permalink</p><p>原来的是这样的，</p><blockquote><p>permalink: :year/:month/:day/:title/</p></blockquote><p>我们改成</p><blockquote><p>permalink: blog/:title_en/</p></blockquote><p>然后在写文章的 md 中加入</p><blockquote><p>title_en: my-defined-url</p></blockquote><p>就能在浏览器通过以下地址访问了</p><blockquote><p>{username}.github.io/blog/my-defined-url</p></blockquote></div><h3 id="文章修改预设-formats"><a href="#文章修改预设-formats" class="headerlink" title="文章修改预设 formats"></a>文章修改预设 formats</h3><div class="note success simple"><p>打开站点根目录下的 scaffolds 文件夹，修改里面的 post.md 即可，page formates 同理</p></div><h2 id="配置美化过程中那些拦路虎"><a href="#配置美化过程中那些拦路虎" class="headerlink" title="配置美化过程中那些拦路虎"></a>配置美化过程中那些拦路虎</h2><p>记录填坑之路，标题是错误，正文是解决办法。</p><h3 id="OpenSSL-SSL-read-Connection-was-reset-errno-10054"><a href="#OpenSSL-SSL-read-Connection-was-reset-errno-10054" class="headerlink" title="OpenSSL SSL_read: Connection was reset, errno 10054"></a>OpenSSL SSL_read: Connection was reset, errno 10054</h3><div class="note success simple"><p>在站点配置 git 仓库地址时使用 ssh 地址，不要使用 https 地址。</p></div><h3 id="本地和-github-io-访问不一致"><a href="#本地和-github-io-访问不一致" class="headerlink" title="本地和 github.io 访问不一致"></a>本地和 github.io 访问不一致</h3><div class="note success simple"><p>可能是浏览器有缓存，使用 ctrl + f5 刷新试试。</p><p>如果是本次部署没有任何文章更新，github page 没有识别到文章相关更新，也有可能导致这个问题，建议新建或修改文章时间。</p></div><h3 id="clone-主题时超时"><a href="#clone-主题时超时" class="headerlink" title="clone 主题时超时"></a>clone 主题时超时</h3><div class="note success simple"><p>原因是 github 的 dns 被污染了，打开 <code>C:\Windows\System32\drivers\etc</code> 下的 hosts 文件，配置 github 的 dns 解析。格式如下：</p></div><blockquote><p>140.82.113.3  github.com git<br>199.232.69.194 github.global.ssl.fastly.net<br>185.199.108.153 assets-cdn.github.com</p></blockquote><p>前面的 dns 地址可能需要更换，详情可以参考 <a href="https://blog.csdn.net/ygdxt/article/details/82825013">github 打开很慢的解决办法</a></p><h3 id="butterfly-主题报错-extends-includes-layout-pug-block-content-include…"><a href="#butterfly-主题报错-extends-includes-layout-pug-block-content-include…" class="headerlink" title="butterfly 主题报错 extends includes/layout.pug block content include…"></a>butterfly 主题报错 extends includes/layout.pug block content include…</h3><p>错误具体信息如下</p><div class="note warning simple"><p>extends includes/layout.pug block content include ./includes/mixins/post-ui.pug #recent-posts.recent-posts +postUI include includes/pagination.pug</p></div><p>解决办法是输入命令</p><div class="note success simple"><p>npm install –save hexo-renderer-jade hexo-generator-feed hexo-generator-sitemap hexo-browsersync hexo-generator-archive</p></div><p>再 <code>hexo clean</code> &amp;<code>hexo g -d</code> 就好了。</p><h3 id="butterfly-主题报错-if-theme-newest-comments-enable-xxx-read"><a href="#butterfly-主题报错-if-theme-newest-comments-enable-xxx-read" class="headerlink" title="butterfly 主题报错 if theme.newest_comments.enable xxx read"></a>butterfly 主题报错 if theme.newest_comments.enable xxx read</h3><div class="note warning simple"><p>if theme.newest_comments.enable xxx read…</p><p>Cannot read property ‘0’ of null…</p></div><div class="note success simple"><p>原因是，没有配置 comment 就把 newset_comment 开关打开了。</p></div><h3 id="列表页-newset-评论无法显示，文章内评论可以"><a href="#列表页-newset-评论无法显示，文章内评论可以" class="headerlink" title="列表页 newset 评论无法显示，文章内评论可以"></a>列表页 newset 评论无法显示，文章内评论可以</h3><div class="note success simple"><p>情况发生于 Valine 评论系统，解决办法是配置下 serverURLs 为 LeanCloud 提供的 RestAPI 地址。</p></div><h3 id="配置了但是-addtothis-分享系统无效"><a href="#配置了但是-addtothis-分享系统无效" class="headerlink" title="配置了但是 addtothis 分享系统无效"></a>配置了但是 addtothis 分享系统无效</h3><div class="note success simple"><p>应该是没有在 addtothis 后台新建 share_button，选择相应的分享平台并激活按钮。</p></div><h2 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h2><p>本文链接：<a href="https://buyixiao.github.io/blog/butterfly-beauty-quick-start.html">https://buyixiao.github.io/blog/butterfly-beauty-quick-start.html</a></p><p>转载或引用需要注明来源。</p>]]></content>
      
      
      <categories>
          
          <category> Butterfly </category>
          
      </categories>
      
      
        <tags>
            
            <tag> butterfly </tag>
            
            <tag> hexo </tag>
            
            <tag> beauty </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pip install 成功了，import 却出错了</title>
      <link href="/blog/pip-install-success-import-fail.html"/>
      <url>/blog/pip-install-success-import-fail.html</url>
      
        <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>可能不少人遇到这样的问题，为什么在 cmd 命令行中 <code>pip install requests</code> 成功了，在 Pycharm 中写代码 <code>import requests</code> 还是报 module not found 错误，装是装上了，又没完全装上，何哉？下面以 requests 这个库为例子，详细说明原因及解决办法。</p><h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><p>根本原因是，<strong>没有认识处理好 python 多版本共存问题，cmd 里装 requests 的 python 环境不是你 pycharm 里面运行的那个 python 环境</strong>。</p><p>在 cmd 输入 <code>pip install requests</code> 前，不妨先输入一个命令，查看有哪些 Python 环境：<code>where python</code></p><p>cmd 显示如下，可以看到，电脑有三个 python 环境，当在命令行输入 python 时，默认进入了第一个 Python36_64 环境，这样的顺序是由编辑系统环境变量的先后顺序决定的</p><blockquote><p>D:\a\b\c\Python36_64\python.exe<br>D:\c\b\a\Python388\python.exe<br>C:\x\y\z\python.exe</p></blockquote><p>然后查看有哪些 pip ：<code>where pip</code></p><blockquote><p>D:\a\b\c\Python36_64\Scripts\pip.exe<br>D:\c\b\a\Python388\Scripts\pip.exe</p></blockquote><p>在 cmd 输入 <code>pip install requests</code> 时，只会给环境变量中从上到下第一个 pip 对应的 Python 环境装的，也就是给 Python36_64 这个环境装的。</p><p>然后看下 Pycharm 中是不是也用的这个 Python 环境，点击菜单栏的 File – Settings</p><p><img src="https://s2.loli.net/2022/01/17/XOf9cv1mFn2wxGa.png" alt="Pycharm 查看 Python 环境.png"></p><p>展开 Python Interpreter，可以看到就是 cmd 里默认的 Python36_64 环境，点击上图中右上角的锯齿状设置按钮，可以给 Pycharm 切换 python 环境。然后这些增删操作看符号就知道了，不赘述。</p><p>如果选中了想要的 python 环境，可以点击上图左下角中的 + 号按钮，搜索 requests 包，点击并安装。</p><p><img src="https://s2.loli.net/2022/01/17/4f9vmuiNy1jL7hC.png" alt="Pycharm 安装库.png"></p><h2 id="cmd-和-Pycharm-换源"><a href="#cmd-和-Pycharm-换源" class="headerlink" title="cmd 和 Pycharm 换源"></a>cmd 和 Pycharm 换源</h2><p>由于某些原因 python 库默认的下载地址下载很慢，在 cmd 中可以依次输入以面命令切换成 douban 源，下载安装就起飞了</p><blockquote><p>pip install pqi<br>pqi use douban</p></blockquote><p>在 Pycharm 中也有等同操作，点击上一个图中的 Manage Repositories ，将 <a href="https://pypi.python.com/simple/">https://pypi.python.com/simple/</a> 修改成   <a href="https://pypi.douban.com/simple/">https://pypi.douban.com/simple/</a> ，并且一路 OK 确定即可。</p><p>最后再回到 cmd 中</p><blockquote><p>D:\a\b\c\Python36_64\Scripts\pip.exe<br>D:\c\b\a\Python388\Scripts\pip.exe</p></blockquote><p>如果想要快速给第二个 Python388 装 requests，该怎么办呢？我们在文件夹中打开 D:\c\b\a\Python388\Scripts 这个路径。</p><p><img src="https://s2.loli.net/2022/01/17/4GBIcQFVr7dijKU.png" alt="pip 目录"></p><p>我们可以直接在 cmd 中通过 <code>pip3.8 install requests</code> 给这个环境装 requests；</p><p>也可以复制一个 pip.exe，并粘贴命名为 pipenv.exe，<code>pipenv install requests</code>；</p><p>除了 pip3.8 是这个环境独有的，其他两个 pip.exe 和 pip3.exe 在 python36_64 那个环境也有，所以 pip/pip3 命令会被在环境变量中优先级高的 python36_64 的 pip 接管。</p><h2 id="如何避免这种问题"><a href="#如何避免这种问题" class="headerlink" title="如何避免这种问题"></a>如何避免这种问题</h2><p>在系统中只装一个版本的 Python，本着一个项目一个虚拟环境的原则，每次新建项目，用系统的 Python 复制出一个虚拟环境，起个和项目相关的环境名，然后在 Pycharm 选择虚拟环境目录下，Scripts 文件夹下的 python.exe 作为项目的解析器。</p><p>Windows 下创建虚拟环境步骤如下：</p><h4 id="安装-virtualenv"><a href="#安装-virtualenv" class="headerlink" title="安装 virtualenv"></a>安装 virtualenv</h4><blockquote><p>pip install virtualenv</p></blockquote><h4 id="在当前目录下创建虚拟环境"><a href="#在当前目录下创建虚拟环境" class="headerlink" title="在当前目录下创建虚拟环境"></a>在当前目录下创建虚拟环境</h4><blockquote><p>virtualenv env_crawl</p></blockquote><h4 id="激活、退出虚拟环境"><a href="#激活、退出虚拟环境" class="headerlink" title="激活、退出虚拟环境"></a>激活、退出虚拟环境</h4><p>在 cmd 中需要 cd 进入到虚拟环境目录下 Script 文件</p><p>夹中，使用下述命令激活</p><blockquote><p>activate</p></blockquote><p>当然，如果不在 Script 下，但在当前盘符中，使用</p><blockquote><p>./xxx/yyy activate</p></blockquote><p>这种相对路径格式也是可以的。</p><p>激活之后，cmd 会在 path 最前面显示一个 <strong>（{env_crawl})</strong> ，在当前 cmd 会话中 Python 相关的操作都是针对这个虚拟环境而言的，操作和修改不会影响其他 Python 环境。如果想要退出环境，只需要使用</p><blockquote><p>deactivate</p></blockquote><p>值得欣喜的是，<strong>如果在 Pycharm 选择中虚拟环境，那么在 Pycharm 中打开终端，就可以直接进入到了当前的并且是已经激活的虚拟环境</strong>。</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pip </tag>
            
            <tag> pycharm </tag>
            
            <tag> 换源 </tag>
            
            <tag> requests </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>写在 BuyiXiao&#39;s Blog 开始</title>
      <link href="/blog/why-buyixiao-blog-start.html"/>
      <url>/blog/why-buyixiao-blog-start.html</url>
      
        <content type="html"><![CDATA[<h2 id="who-is-buyixiao"><a href="#who-is-buyixiao" class="headerlink" title="who is buyixiao"></a>who is buyixiao</h2><p>buyixiao 行不改名，坐不改姓；江湖人称 <font color="red">肖不已</font>，或者 <font color="red">布衣肖</font>；三尺微命，一介书生，不足挂齿。<br>buyixiao 在这个互联网中还有其他两个亲兄弟，一个叫 <a href="https://inspurer.github.io/">inspurer</a>，还有一个叫 <a href="https://mp.weixin.qq.com/mp/profile_ext?action=home&__biz=MzUzMDE5MzQ3Ng==#wechat_redirect">月小水长</a>。</p><h2 id="buyixiao’s-skills"><a href="#buyixiao’s-skills" class="headerlink" title="buyixiao’s skills"></a>buyixiao’s skills</h2><p>写过数据分析可视化，会一点爬虫，前 Android 不知名工程师，上线过小程序和 Chrome 扩展，还是一个 Python 全沾工程师…</p><p>之前在某大厂干过开发，现在在家里睡大觉。</p><h2 id="buyixiao’s-blog"><a href="#buyixiao’s-blog" class="headerlink" title="buyixiao’s blog"></a>buyixiao’s blog</h2><p>关于为什么要开这个 blog，有两个原因。</p><p>第一层次的原因是，buyixiao 之前在公众号更新文章，但是该生态比较封闭，而且无法很好修改发布过的文章，还有其他各种限制，所以急切需要一个自主可控的博客系统。</p><p>另一个是因为，buyixiao 老大哥  <a href="https://inspurer.github.io/">inspurer 的个人博客</a> 源代码已经不可考了，而且网站历史包袱太重，包括样式，渲染速度等都积重难返了，所以有 <a href="https://buyixiao.github.io/">buyixiao’s blog</a> 弟承兄业。</p><p>所以这篇文章，还是有一点序的意思。</p>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> buyixiao </tag>
            
            <tag> inspurer </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
